"ID","CLASSIFIED","TYPE","TITLE","DESCRIPTION"
"HTTPCLIENT-569","BUG","BUG","HttpState.clearCookies() should be synchronized","The HttpState class has a clearCookies method that is not synchronized but
should be considering it modifies an ArrayList (which is unsynchronized). All
other methods which modify or read from the ArrayList are synchronized except
the clearCookies method. 

I stumbled upon this fact because a webapp I am working on that uses HttpClient
threw an IllegalArgumentException indicating that one of the cookies in the
array returned from HttpState.getCookies() was null, which shouldn't be
possible.  Upon further inspection and testing, the only possible option is that
the threadsafety hole left by the unsynchronized clearCookies method caused the
issue."
"HTTPCLIENT-386","BUG","BUG","Catch SocketTimeoutException not InterruptedIOException","There are a couple of places where you're catching InterruptedIOException 
that should catch SocketTimeoutException instead.  For example, from 
HttpConnection:

    protected boolean isStale() {
        boolean isStale = true;
        if (isOpen) {
            // the connection is open, but now we have to see if we can 
read it
            // assume the connection is not stale.
            isStale = false;
            try {
                if (inputStream.available() == 0) {
                    try {
                        socket.setSoTimeout(1);
                        inputStream.mark(1);
                        int byteRead = inputStream.read();
                        if (byteRead == -1) {
                            // again - if the socket is reporting all data 
read,
                            // probably stale
                            isStale = true;
                        } else {
                            inputStream.reset();
                        }
                    } finally {
                        socket.setSoTimeout(this.params.getSoTimeout());
                    }
                }
            } catch (InterruptedIOException e) {
                // aha - the connection is NOT stale - continue on!

Here the catch of InterruptedIOException is intended to happen when 
inputStream.read() terminates due to the socket.setSoTimeout() time being 
reached.  However, it could also occur because Thread.interrupt() has been 
called, in which case ""continue on"" is not what should happen, instead, the 
request should terminate.

There are legitimate reasons why someone might want to interrupt the 
httpclient code, for example, httpclient does not provide a hard timeout on 
the total length of time a request may take, including connecting, sending 
the request, and receiving the complete response, so to enforce a hard 
timeout it is necessary to run the request in a worker thread and interrupt 
it if it hasn't completed before the timeout expires (the technique used in 
your TimeoutController class).

Note that SocketTimeoutException was added in 1.4.  For compatibility with 
older jdk versions, the code can catch InterruptedIOException and use 
getClass() to see whether it is a SocketTimeoutException.

There are probably other places in the code where InterruptedIOException is 
caught and interpreted as a socket timeout, and where Thread.interrupt() 
will not have the proper effect of causing the request to terminate ASAP, 
but I'm not familiar enough with the code to find them all."
"HTTPCLIENT-302","BUG","BUG","exception during writeRequest leaves the connection un-released","The execute method has the following (simplified) flow:
1) get connection
2) write request
3) read result
4) release connection.
The release in step 4 happens when the input is completely read, which works fine.
If an exception occurs between steps 1 and 2, the connection is also released
properly.
However, if an exception occurs during step 2, the connection is never released
back and the connection manager eventually runs out of connections.

The easiest way to test this is to make a simple subclass of PostMethod that
overrides the writeRequest method:

public class TestConnectionReleaseMethod extends PostMethod
{
    protected void writeRequest(HttpState state, HttpConnection conn) throws
IOException, HttpException
    {
         throw new IOException(""for testing"");
    }
}"
"HTTPCLIENT-104","IMPROVEMENT","BUG","Incorrect debug message in HttpMethodBase","HttpMethodBase.addContentLengthRequestHeader has the wrong debug message.  See
attached patch."
"HTTPCLIENT-85","BUG","BUG","Host request header does not contain port","The Host request header is always added with just the hostname used for the 
connection.  If the port is different than 80 it needs to be included as well, 
with a colon separating it from the hostname.  This problem is especially 
apparent when you use the httpclient to connect to tomcat 4 and then use 
HttpUtils to create a full URL representing the request.  HttpUtils pulls the 
host and port from the Host header.  When commons-httpclient is used HttpUtils 
never includes the port since it was never in the Host header."
"HTTPCLIENT-196","BUG","BUG","httpClient failed to reconnect after keep-alive connection timed out","Description:

When using httpClient with https tunnelling througha proxy server, after keep-
alive connection timed out on server side.  The httpClient code was unable to 
establish the connection again.

Cause:

The HttpMethodBase.processRequest's retry loop retries the connection without 
going through the ""CONNECT"" request to the proxy server.  Our proxy server 
returns 407 error code.  In case of tunnelling connection, proper reconnect 
should be done by first doing the ""CONNECT"" sequence to get authenticated 
throught the proxy.

Temp fix and Work around:

We implemented some work around to do the retry from the application layer.  In 
order to detect the situation, we have to rely on the error message contained 
in the HttpRecoverableException.  We are checking the text ""Connection aborted 
by peer: socket write error"".  We also have to modify the HttpMethodBase code 
to throw the HttpRecoverableException out to the application."
"HTTPCLIENT-697","IMPROVEMENT","BUG","Http Client give sme message when proxy/http endpoint is down","Whether Http sever endpoint is down or the proxy server is down we get the same stack trace as:

java.net.ConnectException: Connection refused
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
	at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
	at java.net.Socket.connect(Socket.java:518)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.commons.httpclient.protocol.ReflectionSocketFactory.createSocket(ReflectionSocketFactory.java:139)
	at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:124)
	at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:706)
	at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1321)
	at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:386)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)
	at com.approuter.module.http.protocol.HttpTransportSender.perform(HttpTransportSender.java:214)
	at 


It will be good if we can get information whether the proxy was down or the Http endpoint.

"
"HTTPCLIENT-477","RFE","BUG","There is no way to specify a different auth scheme priority for host and proxy","Using HttpClient 3.0 rc2, you cannot authenticate to a site using Basic
Autentication and to a proxy server using NTLM authentication.

When you indicate a prefference to use NTLM over Basic authentication the
authentication will fail when it tries to authenticate NTML to the Proxy and to
the Site. If you indicate Basic, then NTLM authentication order the Basic
authentication will fail when used for the Proxy (since basic authentication
can't send the domain name it fails).

The email thread from the discussion group is pasted below for refference.

==============================================================
==============================================================

Hi all,
I am trying to authenticate to a server via a proxy which also requires
authentication. It seems that I can get either the proxy authentication to work
OR the site authentication to work, but not both.

Both seem to work independently when I set the credentials (or proxy
credentials) using NTCredentials (e.g. if I connect to the site from a network
not using a proxy I can get it to work, and I can authenticate to the proxy only
to get a 401 authentication failed from the server when using the proxy).

I read in the Authentication tutorial that you can't authenticate using NTLM to
both the proxy and site, so I'm trying various combinations of authentication,
but I can't find any documentation that specifically covers this case and I feel
like I'm just taking stabs in the dark right now.

If anyone can point me in the direction of the light at the end of the tunnel
I'd really appreciate it.

Thanks,
David

----------------

On Wed, Jun 29, 2005 at 09:53:07AM -0700, David Parks wrote:
> Hi all,
> I am trying to authenticate to a server via a proxy which also requires
authentication. It seems that I can get either the proxy authentication to work
OR the site authentication to work, but not both.
> 
> Both seem to work independently when I set the credentials (or proxy
credentials) using NTCredentials (e.g. if I connect to the site from a network
not using a proxy I can get it to work, and I can authenticate to the proxy only
to get a 401 authentication failed from the server when using the proxy).
> 
> I read in the Authentication tutorial that you can't authenticate using NTLM
to both the proxy and site, so I'm trying various combinations of
authentication, but I can't find any documentation that specifically covers this
case and I feel like I'm just taking stabs in the dark right now.

David,

You _really_ can't use NTLM to authenticate with the proxy and the
target host at the same, due to the nature of this authentication
scheme. Really. That was not a joke.

Please consider using one of the following combinations instead:

(1) BASIC proxy + NTLM host if both the clent and the proxy are within a
trusted network segment

(2) NTLM proxy + SSL + BASIC host

Both combinations should provide an adequate (or better in the latter case)
security

Hope this helps

Oleg

> 
> If anyone can point me in the direction of the light at the end of the tunnel
I'd really appreciate it.
> 
> Thanks,
> David
> 
> 

-------------------

Thanks for the reply Oleg. This is what I figured, but I cannot see how to use
different authentication schemes for the Proxy vs. the Site authentication
challenge.

I tried adding the code suggested in the Authentication tutorial:

        List authPrefs = new ArrayList(2);
        authPrefs.add(AuthPolicy.DIGEST);
        authPrefs.add(AuthPolicy.BASIC);
        authPrefs.add(AuthPolicy.NTLM);
         This will exclude the NTLM authentication scheme
        httpclient.getParams().setParameter(AuthPolicy.AUTH_SCHEME_PRIORITY,
authPrefs);

I got a message stating that it was attempting BASIC authentication for the
Proxy and that it failed (probably because the domain doesn't get passed I
guess). So my thought is that I need NTLM for the proxy authentication and Basic
will work for the site authentication.

The question I am then working on is how to direct the HttpClient to select that
order of authentication methods. If I let it take NTLM as the preffered
authentication method then it will try to authenticate both challenges with NTLM.

I sure there is just some little detail I'm missing here somewhere, it's just
hard to find it.

Thanks a lot!
David

------------------

David,

I see the problem. This will require a patch and a new parameter.
Luckily the preference API introduced in HttpClient 3.0 allows up to add
parameters quite easily. Please file a feature request with Bugzilla
ASAP and I'll do my best to hack up a patch before I leave for holidays
(that is Friday, July 1st)

Oleg


--------------

Hi Oleg, thanks, I'll put that request in today.
This helps a lot, at least I know I'm on the right path now.

I am attempting to devise a workaround for this by handling the authentication
manually (setDoAuthentication(false)).

When I see a 401 error I am processing a basic authentication with the site
credentials, when I see a 407 error I want to process an NTLM authentication
with the proxy credentials.

To that end I have the following code that runs after
httpclient.execute(getmethod) executes. The code below works perfectly for the
basic authentication (when the proxy is not in the picture).

In looking up the Handshake of the NTLM authentication I see that I have a
problem with the code below since the handshake includes 2 challenge and
authorization steps before the authentication succeeds. I'm not clear how I
could manually authenticate the NTLM response. I would expect the NTLMScheme
class to contain a Type 1 and Type 3 authenticate() method for processing both
challenge responses. Is there another way of processing the NTLM authentication
after receiving the initial authentication challenge from the server?

        //Check for Proxy or Site authentication
        if(getmethod.getStatusCode() == 401){
            //Authenticate to the site using Basic authentication.
            BasicScheme basicscheme = new BasicScheme();
            String basic_auth_string = basicscheme.authenticate(new
NTCredentials(""cwftp"", ""664A754c"", """", """"), getmethod);
            Header basic_auth_header = new Header(""Authorization"",
basic_auth_string);
            getmethod.addRequestHeader(basic_auth_header);
            try{
                httpclient.executeMethod(getmethod);
            }catch(Exception e){
                logger.log(Level.SEVERE, ""ack!!!!"", e);
            }
            return getmethod;
       }else if(getmethod.getStatusCode() == 407){
            //Authenticate to the site using Basic authentication
            NTLMScheme ntlmscheme = new NTLMScheme();
            String basic_auth_string = ntlmscheme.authenticate(new
NTCredentials(""00mercbac"", ""!@SAMmerc2004"", ""simproxy"", ""CFC""), getmethod);
            Header basic_auth_header = new Header(""Authorization"",
basic_auth_string);
            getmethod.addRequestHeader(basic_auth_header);
            try{
                httpclient.executeMethod(getmethod);
            }catch(Exception e){
                logger.log(Level.SEVERE, ""ack!!!!"", e);
            }
            return getmethod;
       }


Thanks,
David"
"HTTPCLIENT-1054","IMPROVEMENT","IMPROVEMENT","HTTPClient per default relentlessly spams to stderr","HTTPClient relentlessly spams to stderr when including it into a project via maven. This is not a decent default behaviour for a libary. Libaries should, per default, communicate their internal state solely and adequatly via their API and let it be up to the application to react to that state (logging it is one such reaction). From some replies to tickets in the same vain I can see that this is perhaps a sensitive topic as some see logging to be a core concern of HTTPClient. I do agree it's helpful as a debugging tool but as such it needs to be opt-in. As a standard error output, the logging of HTTPClient is absolutely useless because it does not and can not describe what the application is trying to do.

Why this improvement when there is a way to disable HTTClient logging (in fact, there seem to be many ways ... always a bad sign ..)?

Do a google search for: httpclient ""console spam""
204 hit for this harsh phrasing alone. Search this phrase for any other libary you like to use and compare the number of hits. Ask youself, how often have you seen the java standard libary write to stdout or stderr?

Personally, I tried to disable it via JDK14 getLogger(""org.apache"").setLevel(Level.OFF)  which wouldn't work and now am using a solution I found on Stackoverflow which is:

System.setProperty(""org.apache.commons.logging.Log"", ""org.apache.commons.logging.impl.NoOpLog""); }

The problem I have is that I include this lib and suddently my console is useless because httpclient is all over it (writing a system monitor ...). I have to search google to find a solution (http://hc.apache.org/httpcomponents-client-ga/logging.html does not tell you how to turn logging off ...) and the logical one ""turn of the JDK logger"" does not work right away.

It's really a matter of following the principal of least suprise (a libary is not expected to write to the console which is the observable default behaviour of HTTPClient) and the principal of separation of concerns (logging is a concern for applications and not for libaries).

Following at least one of these would substantially increase the joy of working with the HTTPClient libary.

"
"HTTPCLIENT-1030","RFE","RFE","Implement ""ignoreCookies"" CookieSpec","It would be useful to Implement an ""ignoreCookies"" CookieSpec, as was done in Commons HC 3.1

This should be registered by DefaultHttpClient.createCookieSpecRegistry().

Patch to follow."
"HTTPCLIENT-553","DOCUMENTATION","BUG","JavaDoc getConnection methods in Connection Managers","The JavaDoc for the getConnection() methods in the Simple and MultiThreaded
Connection managers is taken from the interface, and so is too generic.

The Javadoc for the doGetConnection() method in the MultiThreaded manager is
fine, but is not visible in the JavaDoc

The Simple Mangager JavaDoc could likewise be improved

[I hope to provide patches shortly]"
"HTTPCLIENT-30","RFE","BUG","should allow receiving secure cookies from non-secure chanel","Currently, httpclient will throw an exception if a secure cookie is received 
from a non-secure chanel. Although RFC doesn't specify explicitly on if the 
client should allow receiving secure cookie from non-secure channel, the 
default setting in browser seems to allow it.

Try the following link in IE:

http://www.snapfish.com

The default cookie policy in httpclient should be the same."
"HTTPCLIENT-452","BUG","BUG","DateUtil.formatDate() uses default timezone instead of GMT","DateUtil.formatDate() uses default timezone instead of GMT.  In section 3.3.1,
RFC 2616 states:  ""All HTTP date/time stamps MUST be represented in Greenwich
Mean Time (GMT), without exception.""

To reproduce, run the following snippet:

   public static void main(String[] args) {
      TimeZone tz = TimeZone.getTimeZone(""GMT"");
      GregorianCalendar gc = new GregorianCalendar(tz);
      gc.set(1900 + 104, GregorianCalendar.JANUARY, 1, 0, 0, 0);
      System.out.println(DateUtil.formatDate(gc.getTime()));
      
   }

Expected result:
Thu, 01 Jan 2004 00:00:00 GMT

Actual result (if your default timezone is PST):
Wed, 31 Dec 2003 16:00:00 PST"
"HTTPCLIENT-824","TASK","TASK","Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient","Review the use of BaiscHttpParams and HttpProtocolProcessor in HttpClient and replace with thread-safe implementations where necessary.

Oleg"
"HTTPCLIENT-286","BUG","IMPROVEMENT","Manually set 'Cookie' & 'Authorization' headers get discarded","HttpClient discards all the 'Cookie' & 'Authorization' headers including those
manually set when populating request header collection with automatically
generated headers."
"HTTPCLIENT-323","RFE","IMPROVEMENT","GetMethod.getResponseBodyAsStream() .available() could return content-length","It would be nice if the InputStream returned from
GetMethod.getResponseBodyAsStream() could override the available()
method to return the content-length of the requested URL.  This would
make things like ProgressMonitorInputStream useful for monitoring the
progress of a download.  Here is a code snippet:


/**
 * supply a hard-coded value for available() method.
 */
class FixedInputStream extends FilterInputStream {
  private int contentLength;

  public FixedInputStream(InputStream is,
              int contentLength) {
    super(is);
    this.contentLength = contentLength;
  }

  public int available() throws IOException {
    return contentLength;
  }
} 



Also, somewhat related to this request, could
GetMethod.getResponseContentLength() must be made public?  Is there a
good reason for it to be protected?  I had to extend GetMethod and
implement a public getResponseContentLength() in order to feed that
value to my FixedInputStream.

Thanks for your time."
"HTTPCLIENT-960","BUG","BUG","HttpMultipart doesn't generate Content-Type part header in mode BROWSER_COMPATIBLE","Browsers (tested with Firefox 3.6 and IE6) send a Content-Type header for file parts, what org.apache.http.entity.mime.HttpMultipart doesn't do in BROWSER_COMPATIBLE mode.


Example:

-----------------------------142889018617181602061216500409

Content-Disposition: form-data; name=""myFileFieldName2""; filename=""webtest.png""

Content-Type: image/png


In HtmlUnit we wil subclass HttpEntity and MultipartEntity to fix this problem."
"HTTPCLIENT-813","BUG","BUG","HttpClient throws NPE on Invalid Port when used with MultiThreadedHttpConnectionManager","The HttpClient throws NullPointerException in the main thread when an invalid port (like 80001) is used in the URL. An IllegalArgumentException is thrown in TimeoutGuard thread.
 
Exception in thread ""Timeout guard"" java.lang.IllegalArgumentException: port out of range:80001
	at java.net.InetSocketAddress.<init>(InetSocketAddress.java:118)
	at java.net.Socket.<init>(Socket.java:240)
	at org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory.createSocket(DefaultProtocolSocketFactory.java:80)
	at org.apache.commons.httpclient.protocol.ControllerThreadSocketFactory$1.doit(ControllerThreadSocketFactory.java:91)
	at org.apache.commons.httpclient.protocol.ControllerThreadSocketFactory$SocketTask.run(ControllerThreadSocketFactory.java:158)
	at java.lang.Thread.run(Thread.java:613)
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:721)
	at org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnectionAdapter.open(MultiThreadedHttpConnectionManager.java:1361)
	at org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:387)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:171)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:397)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:323)
	at com.aol.test.HttpTest$PoolingHttpConnector.doGet(HttpTest.java:47)
	at com.aol.test.HttpTest.main(HttpTest.java:17)

It should throw a checked exception in main thread so caller can handle the error condition more gracefully.

The test program is attached. This is caused by a race condition and it's not always reproducible. Running in debugger shows a different behavior.

package com.aol.test;

import java.io.IOException;

import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.HttpStatus;
import org.apache.commons.httpclient.MultiThreadedHttpConnectionManager;
import org.apache.commons.httpclient.methods.GetMethod;
import org.apache.commons.httpclient.params.HttpConnectionManagerParams;

public class HttpTest {
	
	public static void main(String[] args) {
		PoolingHttpConnector conn = new PoolingHttpConnector();
		
		try {
			String response = conn.doGet(""http://www.aol.com:80001"");
			System.out.println(""Response='"" + response + ""'"");
		} catch (IOException e) {
			e.printStackTrace();
		}
	}


	static class PoolingHttpConnector {
		
		public static final int MAX_TOTAL_CONNECTIONS = 16;
		public static final int MAX_CONNECTIONS_PER_HOST = 8;
		public static final int CONNECT_TIMEOUT = 5000;
		public static final int SOCKET_TIMEOUT = 5000;
		public static final boolean TCP_NO_DELAY = true;
		
	    private static MultiThreadedHttpConnectionManager poolManager;
	    private static HttpConnectionManagerParams httpParams;
	    private static HttpClient httpClient;
	    private static boolean initialized = false;
	    
		public PoolingHttpConnector() 
		{
			initialize();
		}

		public String doGet(String url) throws IOException {
			GetMethod method = new GetMethod(url);
					
			try {
	            int status = httpClient.executeMethod(method);	            
		        String response = new String(method.getResponseBody());
	            
	            if (status != HttpStatus.SC_OK)
	            	throw new IOException(""HTTP error: "" + response);
	            
	            return response;
	            
			} finally {
	            method.releaseConnection();
			}
	 	} 	
	
		private synchronized void initialize() {	
			if (initialized)
				return;
			
	        poolManager = new MultiThreadedHttpConnectionManager();
	        httpParams = new HttpConnectionManagerParams();
	        
	        httpParams.setMaxTotalConnections(MAX_TOTAL_CONNECTIONS);
	        httpParams.setDefaultMaxConnectionsPerHost(MAX_CONNECTIONS_PER_HOST);
	        httpParams.setTcpNoDelay(TCP_NO_DELAY);
	        httpParams.setSoTimeout(SOCKET_TIMEOUT);
	        httpParams.setConnectionTimeout(CONNECT_TIMEOUT);
	        
	        poolManager.setParams(httpParams);
	        httpClient = new HttpClient(poolManager);

			initialized = true;
		}
		
	}
}



"
"HTTPCLIENT-71","RFE","BUG","Add support for Digest authentication to the Authenticator class","Here's some code initially whipped up by Geza for Apache Axis, now adapted to
HTTPClient that adds support for Digest authentication to the Authenticator
class. I have tested this code against tomcat 4.0.4 with a sample code that
calls an Apache Axis Web Service. One caveat according to Geza, the code ""Right
now does not support qop-int""."
"HTTPCLIENT-530","BUG","BUG","Findbugs reports and fixes","Ran findbugs 0.94.rc1 on 3.0RC4. 
Fixed a few of the obvious ones (patches to follow) and made notes on the 
remainder - see the //TODO markers in code.
Also created a findbugs target in build.xml - see appropriate patch file"
"HTTPCLIENT-317","RFE","IMPROVEMENT","HTTP Client doesn't support multipart/related content-type","It is not possible to sent data easely as a multipart/related content-type (as 
discribed in rfc 2387) using Http Client."
"HTTPCLIENT-852","BUG","BUG","CircularRedirectException encountered when using a proxy, but not when reaching the target directly","A CircularRedirectException is encountered when using a proxy (tinyproxy on a remote machine), whereas everything is fine when using no proxy. The target is a URL such as http://www.seoconsultants.com/w3c/status-codes/301.asp which has a 301 redirection.

The issue can be fixed by using ALLOW_CIRCULAR_REDIRECTS set to true (client params), but I can't consider this a ""real"" fix.

Here is a snippet of code that exemplifies the problem (use your own proxy):

---
String proxyHost = ""xyz.webfactional.com"";
int proxyPort = 7295;

DefaultHttpClient httpclient = new DefaultHttpClient();
// without a proxy it's OK!
httpclient.getParams().setParameter(ConnRoutePNames.DEFAULT_PROXY,
        new HttpHost(proxyHost, proxyPort, ""http""));

HttpParams params = httpclient.getParams();
HttpClientParams.setRedirecting(params, true);
HttpProtocolParams.setUserAgent(params,
        ""Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10.5; en-US; rv:1.9.0.10) Gecko/2009042315 Firefox/3.0.10"");

// OK, this fixes the problem, but at what cost / other problems ?
//httpclient.getParams().setParameter(ClientPNames.ALLOW_CIRCULAR_REDIRECTS, true);

String url = ""http://www.seoconsultants.com/w3c/status-codes/301.asp"";

HttpUriRequest request;
HttpResponse response;

request = new HttpGet(url);
System.out.println(""request = "" + request.getRequestLine());
response = httpclient.execute(request);
System.out.println(""status = "" + response.getStatusLine());
System.out.println(""headers = "" + Arrays.asList(response.getAllHeaders()));
---"
"HTTPCLIENT-667","RFE","IMPROVEMENT","Provide BestMatch cookie policy","Presently HttpClient uses a single cookie policy for all target hosts, which is suboptimal for two reasons:
(1) the user needs to know beforehand what kind of HTTP cookie support the target host provides
(2) does not work well with multiple sites with different level of HTTP cookie support 

Introduce new cookie policy that dynamically picks up a CookieSpec (browser compatibility | Netscape draft | RFC2109 | RFC2965) based on properties of the response received from the target host"
"HTTPCLIENT-501","BUG","BUG","Minor RFC 2109 / 2965 violation","Hi all,

we received this bug report for the debian commons-httpclient
package:

<debian_bugreport>
The following bug is present in upstream, 2.0.2 and 3.0RC3, at least as far
as I can tell by testing.

The specification grammar for the Cookie and Cookie2 HTTP headers
(specified by RFC 2109 section 4.3.4, and RFC 2965 section 3.3.4,
respectively) require that the ordering of pairs is ""Version, NAME, path,
domain"" (and, in RFC 2965, ""port"" after ""domain""). However, HTTPClient
produces a cookie string with the domain pair appearing before, rather
than after, the path pair. The RFCs specifically *do not* use either the
grammar or the clarifying text (""can occur in any order"") that occurs in
the sections that define the Set-Cookie and Set-Cookie2 headers (4.2.2 and
3.2.2, respectively).

Since the sections in question do not, in fact, discuss the issue of pair
ordering in Set-Cookie/Set-Cookie2 at all (other than in using a grammar
that clearly expresses the requirement), and since the complimentary
header explicitly permits them to occur in any order, it seems likely
that HTTPClient is not the only client with this issue, and that most
servers will accomodate this situation (in fact, for it to have gone
unnoticed for this long, it seems likely that either I'm badly misreading
the specification, or no major server has a problem coping with this).
</debian_bugreport>

For your reference the debian bug number:
http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=329245

Regards,

Wolfgang"
"HTTPCLIENT-609","IMPROVEMENT","IMPROVEMENT","Use TRACE logging instead of DEBUG for the absolute nitty-gritties","[This is basically a copy of the Spring improvement request SPR-2873: http://opensource.atlassian.com/projects/spring/browse/SPR-2873 )

Given a developer situation: Much of the DEBUG information in the log of HttpClient is very un-interesting as long as it works. Some of these lines are however of much bigger importance than others (thus turning off DEBUG globally for HttpClient isn't good either).

TRACE and DEBUG are the two developer-centric logging levels of log4j and commons logging (the rest are ""production levels""). Since log4j-1.2.12, TRACE have existed. Clogging have always had trace, but before release 1.1 mapped Log.trace to log4j's DEBUG, but 1.1 (released May 9. 2006) now maps to log4j's TRACE.

I think that HttpClient's logging would benefit a lot by using TRACE level extensively, in that developers could turn all of httpclient's logging down to DEBUG, but still see ""major developer events"" like connections being opened, the request being sent, and e.g. the response's status line, size of headers and body, keep-alive vs. closing of connection.

Candidates for TRACE level include:
  * httpclient.wire.*
  * org.apache.commons.httpclient.params.DefaultHttpParams
  * org.apache.commons.httpclient.HttpMethodBase
  * .. and probably a bunch of others that doesn't bring the developer in the standard ""good flow mode"" any highly interesting information. 

Please note that I do NOT view these lines as worthless. It is however in _normal_ developer circumstances not valuable information, and it would ease development if it was possible to turn these ultra-verbose loglines off easily. When things just aren't working out, and your exciting REST-based query doesn't work out, or your charset encodings just doesn't give what you're expecting, you'd turn on TRACE to really get down to the hard core. You'd find the problem, fix it, and set it to DEBUG again.

In addition, the lines that were left on the DEBUG level should obviously be as informative as possible, and thus maybe somewhat more verbose than now, trying to ""aggregate"" some pieces of information that now are output over several DEBUG lines..

I do realize that I could achive a lot of this with a rather extensive log configuration, that also had to include raw text filters, but I do believe that this affects more developers than me!

PS: it wouldn't hurt either if all of httpclient's log-lines came from a common root, e.g. ""HttpClient"", or ""org.apache.commons.httpclient"", instead of having several roots. This would however be a somewhat ""backward incompatible"" change, since it now has (at least?) two roots."
"HTTPCLIENT-926","RFE","RFE","Add Amazon S3 authentication support","Add support for the the Amazon S3 authentication scheme as defined by the online document: http://docs.amazonwebservices.com/AmazonS3/latest/index.html?RESTAuthentication.html"
"HTTPCLIENT-46","RFE","IMPROVEMENT","Plug-in authentication modules","Currently only basic authentication is supported.  A Authentication interface
should be provided to allow for plug-in support for other authenticaiton
schemes, some of which may be application specific and therefore have no place
in httpclient itself, but would be required by some users."
"HTTPCLIENT-1027","DOCUMENTATION","IMPROVEMENT","Some typos in the English Manual","in section 2.8.4
Per default this implementation will create no more than than 2 concurrent connections per given route and no more 20 connections in total.
Here are 2 ""than"" in this statement.

in section 3.1
Netscape engineers used to refer to it as as a ""magic cookie"" and the name stuck.
Also, here are 2 ""as"" in the sentence.

in section 5.2 'http.protocol.handle-redirects'
If this parameter is not HttpClient will handle redirects automatically.
here, a ""set"" should be put after not

in section 6.1
In certain situations it may be necessary to customize the way HTTP messages get transmitted across
the wire beyond what is possible possible using HTTP parameters in order to be able to deal nonstandard,
non-compliant behaviours.
here are 2 ""possible""."
"HTTPCLIENT-965","BUG","BUG","cache does not honor must-revalidate or proxy-revalidate Cache-Control directives","http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4

There are a couple of missed requirements here regarding must-revalidate and proxy-revalidate (which applies only to shared caches).
1. When a cache entry with this directive is revalidated, it must be an end-to-end revalidation (meaning it must include 'max-age=0' on the request).
2. If the revalidation with the origin fails, the cache MUST NOT return a stale entry and MUST return a 504 response.
"
"HTTPCLIENT-404","BUG","BUG","SO_TIMEOUT parameter on the method level has no effect","This bug has been reported on the HttpClient user list by Ilya Kharmatsky <ilyak
-at- mainsoft.com>"
"HTTPCLIENT-384","IMPROVEMENT","BUG","3.0 not compile-time compatible with 2.0 library usage","To my surprise Oleg says this was the intent, yet the Jakarta-Slide webdavclient
libraries do not compile out of the box.  Patch for that issue to follow."
"HTTPCLIENT-972","RFE","IMPROVEMENT","caching module should use HttpParams-style configuration","The constructor for CachingHttpClient currently accepts combinations of:
* HttpCache
* HttpClient
* integer for max object size in bytes

As I started looking at being able to configure this for behaving as a non-shared cache, I realized that we actually want to be replacing that last int with an HttpParams argument, and tracking all the various options in that style. I have a patch with this update which I will upload shortly.
"
"HTTPCLIENT-1026","TASK","BUG","Properly close resources","Java has exceptions so resources must always be closed on a finally clause"
"HTTPCLIENT-165","BUG","BUG","'100-continue' response times out unexpectedly","Entity encosing methods time out (3 seconds) rather than getting the
100-continue response. Then, after it has send the body, the 100-continue
response is received and returned.

Adding

  method.setUseExpectHeader(false);

seems to fix it.

Platform 1: Jetty server on Windows XP, Sun JDK 1.4.1_01, 
Platform 2: Tomcat-4.1.18 + Turbine on Windows 2000 Pro, Sun JDK 1.3.1
Platform 3: Tomcat-4.1.18 on Linux if the connection is running over stunnel-4.00

Reported by: 
 Simon Roberts <simon.roberts@fifthweb.net>
 Aurelien Pernoud <apernoud@sopragroup.com>
 Ingo Brunberg <ib@fiz-chemie.de>"
"HTTPCLIENT-440","BUG","BUG","Exception in HttpConnection because of unchecked buffer size","From the httpclient-dev mailing list:

Date: Tue, 8 Mar 2005 19:08:35 +0100
Subject: Error with multiple connections

Hello,

 

I am having some problems while trying multiple connections over a
HttpClient object with a MultiThreadedHttpConnectionManager. I am
launching 10 threads and each thread executes some GetMethods using this
HttpClient object.

 

Some times I got an error like this:

 

java.lang.IllegalArgumentException: Buffer size <= 0

      at java.io.BufferedInputStream.<init>(Unknown Source)

      at
org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:70
3)

      at
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpCon
nectionAdapter.open(MultiThreadedHttpConnectionManager.java:1170)

      at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:6
28)

      at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:4
97)

      at Main$Hilo.run(Main.java:58)

 

Does anybody have any idea? 

 

Thanks in advance,

Jorge"
"HTTPCLIENT-510","RFE","IMPROVEMENT","User-defined ProtocolSocketFactory for secure connection through proxy","I use a custom socket implementation with HttpClient, and am having problems 
getting secure connections through a proxy working.

HttpClient requires that my SecureProtocolSocketFactory be able to create a 
secure socket layered over an existing insecure socket, but does not specify 
how that insecure socket is created. Currently, for secure proxied 
connections, the insecure connection is always created using a 
DefaultProtocolSocketFactory (HttpConnection.java, line 702). I wish to be 
able to override this behaviour, so that I can create the insecure socket 
using my own custom implementation.

The problem with the default behaviour is that my custom socket implementation 
is written in C++ using JNI, and the SSL implementation is handled at the 
native level. Hence, layering over an existing JDK socket will not work.

My proposed solution is to add an HTTP connection parameter to specify the 
socket factory to use, perhaps http.connection.insecuresocketfactory of type 
Class."
"HTTPCLIENT-985","BUG","BUG","cache module should populate Via header to capture upstream and downstream protocols","Because the cache module is currently implemented as a decorator that behaves like a transparent caching proxy, we need it to correctly populate the Via header so that we can preserve the record of which protocol versions were used upstream and downstream from the caching module.

This is a MUST per the RFC:
http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.45"
"HTTPCLIENT-1034","DOCUMENTATION","IMPROVEMENT","Add link to ""Benchmarking the HttpClient Caching Module"" article from Comcast Interactive Media","I'd like to add a link into the HttpClient docs detailing some benchmarking we did with the HttpClient Cache module."
"HTTPCLIENT-163","BUG","BUG","HttpClient does not compile 'out of the box' in IBM's VisualAge IDE","This was observed with IBM VisualAge 3.5, which runs JDK1.2.2:

Importing the HTTPClient source code into the IDE brings up a
compilation error in 

org.apache.commons.httpclient.HttpMethodBase.

The initialization of ""private ResponseConsumedWatcher m_responseWatcher""
using an anyonymous inner class seems to cause some trouble. Implicated code:

private ResponseConsumedWatcher m_responseWatcher = new ResponseConsumedWatcher
() {
	public void responseConsumed() {
		responseBodyConsumed();
	}
};

The error message is: ""Field initialization: The constructor invoked to create
org.apache.commons.httpclient.HttpMethodBase$1 with arguments () is not defined""

...but only in the context of HttpMethodBase(String uri) constructor, i.e.
the HttpMethodBase() constructor *can* be compiled, HttpMethodBase(String uri)
*cannot* be compiled with error ""Cannot create constructor due to incorrect
field initialization"".

I interpret this to mean that the compiler is looking for a parameterless
constructor for the anonymous class in the context of 
HttpMethodBase(String uri). The message did not really make sense to me. 
Checked the syntax, checked in the Language Definition whether setting up an
anonymous class like that is permitted; found nothing obviously wrong.

Fix:

The code above is equivalent to constructing the instance at the beginning
of each constructor of the enclosing class. A copy and paste of the
construction code into each of the two constructors fixes things...until
the next update."
"HTTPCLIENT-574","DESIGN_DEFECT","BUG","Subclasses do not have write access to StatusLine","HttpMethodBase provides the readStatusLine method explicitly designed for
subclasses to override. However, any attempt to do so quickly encounters issues
since the subclass does not have access to the statusLine member variable in
HttpMethodBase. The same holds true for several other member variables as well.

Recommend that all access to member variables occur through accessors and that
mutators be provided to set them. See patch below.
----------------------------------------------------------

Index: HttpMethodBase.java
===================================================================
--- HttpMethodBase.java	(revision 390815)
+++ HttpMethodBase.java	(working copy)
@@ -563,7 +563,7 @@
      * @return the status code associated with the latest response.
      */
     public int getStatusCode() {
-        return statusLine.getStatusCode();
+        return getStatusLine().getStatusCode();
     }
 
     /**
@@ -577,6 +577,13 @@
     }
 
     /**
+     * @param statusLine The statusLine to set.
+     */
+    protected final void setStatusLine(StatusLine statusLine) {
+        this.statusLine = statusLine;
+    }
+
+    /**
      * Checks if response data is available.
      * @return <tt>true</tt> if response data is available, <tt>false</tt>
otherwise.
      */
@@ -798,7 +805,7 @@
      * @return The status text.
      */
     public String getStatusText() {
-        return statusLine.getReasonPhrase();
+        return getStatusLine().getReasonPhrase();
     }
 
     /**
@@ -920,16 +927,16 @@
         }
         LOG.debug(""Resorting to protocol version default close connection policy"");
         // missing or invalid connection header, do the default
-        if (this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {
+        if (getEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {
             if (LOG.isDebugEnabled()) {
-                LOG.debug(""Should NOT close connection, using "" +
this.effectiveVersion.toString());
+                LOG.debug(""Should NOT close connection, using "" +
getEffectiveVersion().toString());
             }
         } else {
             if (LOG.isDebugEnabled()) {
-                LOG.debug(""Should close connection, using "" +
this.effectiveVersion.toString());
+                LOG.debug(""Should close connection, using "" +
getEffectiveVersion().toString());
             }
         }
-        return this.effectiveVersion.lessEquals(HttpVersion.HTTP_1_0);
+        return getEffectiveVersion().lessEquals(HttpVersion.HTTP_1_0);
     }
     
     /**
@@ -980,14 +987,14 @@
         this.responseConnection = conn;
 
         checkExecuteConditions(state, conn);
-        this.statusLine = null;
+        setStatusLine(null);
         this.connectionCloseForced = false;
 
         conn.setLastResponseInputStream(null);
 
         // determine the effective protocol version
-        if (this.effectiveVersion == null) {
-            this.effectiveVersion = this.params.getVersion(); 
+        if (getEffectiveVersion() == null) {
+            setEffectiveVersion(this.params.getVersion()); 
         }
 
         writeRequest(state, conn);
@@ -996,7 +1003,7 @@
         // the method has successfully executed
         used = true; 
 
-        return statusLine.getStatusCode();
+        return getStatusCode();
     }
 
     /**
@@ -1048,8 +1055,8 @@
         getRequestHeaderGroup().clear();
         getResponseHeaderGroup().clear();
         getResponseTrailerHeaderGroup().clear();
-        statusLine = null;
-        effectiveVersion = null;
+        setStatusLine(null);
+        setEffectiveVersion(null);
         aborted = false;
         used = false;
         params = new HttpMethodParams();
@@ -1586,18 +1593,18 @@
         ""enter HttpMethodBase.readResponse(HttpState, HttpConnection)"");
         // Status line & line may have already been received
         // if 'expect - continue' handshake has been used
-        while (this.statusLine == null) {
+        while (getStatusLine() == null) {
             readStatusLine(state, conn);
             processStatusLine(state, conn);
             readResponseHeaders(state, conn);
             processResponseHeaders(state, conn);
             
-            int status = this.statusLine.getStatusCode();
+            int status = getStatusCode(); 
             if ((status >= 100) && (status < 200)) {
                 if (LOG.isInfoEnabled()) {
-                    LOG.info(""Discarding unexpected response: "" +
this.statusLine.toString()); 
+                    LOG.info(""Discarding unexpected response: "" +
getStatusLine().toString()); 
                 }
-                this.statusLine = null;
+                setStatusLine(null);
             }
         }
         readResponseBody(state, conn);
@@ -1675,7 +1682,7 @@
         if (Wire.CONTENT_WIRE.enabled()) {
             is = new WireLogInputStream(is, Wire.CONTENT_WIRE);
         }
-        boolean canHaveBody = canResponseHaveBody(statusLine.getStatusCode());
+        boolean canHaveBody = canResponseHaveBody(getStatusCode());
         InputStream result = null;
         Header transferEncodingHeader =
responseHeaders.getFirstHeader(""Transfer-Encoding"");
         // We use Transfer-Encoding if present and ignore Content-Length.
@@ -1714,7 +1721,7 @@
         } else {
             long expectedLength = getResponseContentLength();
             if (expectedLength == -1) {
-                if (canHaveBody &&
this.effectiveVersion.greaterEquals(HttpVersion.HTTP_1_1)) {
+                if (canHaveBody &&
getEffectiveVersion().greaterEquals(HttpVersion.HTTP_1_1)) {
                     Header connectionHeader =
responseHeaders.getFirstHeader(""Connection"");
                     String connectionDirective = null;
                     if (connectionHeader != null) {
@@ -1850,19 +1857,19 @@
         } while(true);
 
         //create the status line from the status string
-        statusLine = new StatusLine(s);
+        setStatusLine(new StatusLine(s));
 
         //check for a valid HTTP-Version
-        String versionStr = statusLine.getHttpVersion();
+        String versionStr = getStatusLine().getHttpVersion();
         if (getParams().isParameterFalse(HttpMethodParams.UNAMBIGUOUS_STATUS_LINE) 
            && versionStr.equals(""HTTP"")) {
             getParams().setVersion(HttpVersion.HTTP_1_0);
             if (LOG.isWarnEnabled()) {
                 LOG.warn(""Ambiguous status line (HTTP protocol version missing):"" +
-                statusLine.toString());
+                getStatusLine().toString());
             }
         } else {
-            this.effectiveVersion = HttpVersion.parse(versionStr);
+            setEffectiveVersion(HttpVersion.parse(versionStr));
         }
 
     }
@@ -1943,9 +1950,9 @@
                     readResponseHeaders(state, conn);
                     processResponseHeaders(state, conn);
 
-                    if (this.statusLine.getStatusCode() ==
HttpStatus.SC_CONTINUE) {
+                    if (getStatusCode() == HttpStatus.SC_CONTINUE) {
                         // Discard status line
-                        this.statusLine = null;
+                        setStatusLine(null);
                         LOG.debug(""OK to continue received"");
                     } else {
                         return;
@@ -2087,7 +2094,7 @@
      */
     private String getRequestLine(HttpConnection conn) {
         return  HttpMethodBase.generateRequestLine(conn, getName(),
-                getPath(), getQueryString(), this.effectiveVersion.toString());
+                getPath(), getQueryString(), getEffectiveVersion().toString());
     }
 
     /**
@@ -2128,6 +2135,13 @@
     }
 
     /**
+     * @param effectiveVersion The effectiveVersion to set.
+     */
+    protected final void setEffectiveVersion(HttpVersion effectiveVersion) {
+        this.effectiveVersion = effectiveVersion;
+    }
+
+    /**
      * Per RFC 2616 section 4.3, some response can never contain a message
      * body.
      *
@@ -2358,7 +2372,7 @@
     ) {
         // set used so that the response can be read
         this.used = true;
-        this.statusLine = statusline;
+        setStatusLine(statusline);
         this.responseHeaders = responseheaders;
         this.responseBody = null;
         this.responseStream = responseStream;"
"HTTPCLIENT-705","BUG","BUG","Handle URIs with path component null","HttpClient does not handle URIs with path component null (e.g. http://google.com) the same as path component '/'. This results e.g. in a ProtocolException ""The server failed to respond with a valid HTTP response""."
"HTTPCLIENT-738","REFACTORING","BUG","HostnameVerifier shouldn't shadow simple name of implemented interface","public interface HostnameVerifier extends javax.net.ssl.HostnameVerifier.

As Findbugs says:

Class names shouldn't shadow simple name of implemented interface

This class/interface has a simple name that is identical to that of an implemented/extended interface, except that the interface is in a different package (e.g., alpha.Foo extends beta.Foo). This can be exceptionally confusing, create lots of situations in which you have to look at import statements to resolve references and creates many opportunities to accidently define methods that do not override methods in their superclasses. 
"
"HTTPCLIENT-99","BUG","BUG","Requests are retried 3 times unconditionaly","Using the 20020811 tarball and jdk1.4.0, a get or post will retry as soon
as it finishes sending the request. I turned on logging and verified that
as soon as the last \r\n hits the wire, it starts on the next retry. For
example:

08-10 09:53:12 [main] httpclient.wire: >> [\r\n]
08-10 09:53:12 [main] httpclient.methods.PostMethod: enter
PostMethod.writeRequestBody(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.write(byte[], int, int)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: Attempt number 3 to write
request
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.writeRequest(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.writeRequestLine(HttpState, HttpConnection)
08-10 09:53:12 [main] commons.httpclient.HttpMethod: enter
HttpMethodBase.generateRequestLine(HttpConnection, String, String, String,
String)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.print(String)
08-10 09:53:12 [main] commons.httpclient.HttpConnection: enter
HttpConnection.write(byte[])
08-10 09:53:12 [main] httpclient.wire: >> ""POST /lookup.jsp HTTP/1.1"" [\r\n]

The top line is the end of the second post and the last line is the start
of the third post.

To make sure the server really wasn't sending something back, I wrote a
quick server that would listen for a request and send a 404 as soon as it
read a post or get line (but would keep reading and dumping info). In the
httpclient log, it still shoots off 3 requests before it receives the
response and the server got all three requests. (client and server are
running on the same machine)

So why is httpclient sending three requests without waiting for a
response?"
"HTTPCLIENT-1142","BUG","BUG","Infinite loop on NTLM authentication","I got an infinite loop on NTLM authentication if the authentication failed (bad credentials).

The state FAILED of the NTLM sheme is never catched in the method authenticate of the class HttpAuthenticator (line 123).
I fix temporatily this bug by adding a case for the protocol state HANDSHAKE."
"HTTPCLIENT-1097","SPEC","BUG","BrowserCompatHostnameVerifier and StrictHostnameVerifier should handle wildcards in SSL certificates better","I ran into a problem with SSL wildcard certificates in the class BrowserCompatHostnameVerifier. It handles ""*.example.org"" fine but ""server*.example.org"" fails to work correctly. The javadoc claims that it should behave the same way as curl and FireFox. In Firefox an SSL certificate for ""server*.example.org"" works fine for the host ""server.example.org"", using HttpClient it throws an exception.

Here is an example test (JUnit4):

package org.example.hb;

import javax.net.ssl.SSLException;

import org.apache.http.conn.ssl.BrowserCompatHostnameVerifier;
import org.junit.Test;

public class BrowserCompatHostnameVerifierTest {

	/**
	 * Should not throw an exeption in the verify method.
	 * @throws SSLException
	 */
	@Test
	public void testVerifyStringStringArrayStringArray() throws SSLException
	{
		BrowserCompatHostnameVerifier hv = new BrowserCompatHostnameVerifier();
		String host = ""www.example.org"";
		String[] cns = {""www*.example.org""};
		
		hv.verify(host, cns, cns);
	}

}"
"HTTPCLIENT-552","RFE","IMPROVEMENT","Add shutdown method to SimpleHttpConnectionManager","It would be useful to be able to close the connection in the
SimpleHttpConnectionManager. This could be achieved by adding a shutdown()
method as per the MultiThreadedConnectionManager.

Ideally this would be added to the HttpConnection interface, but this could
break existing implementations.

To avoid this, perhaps consider introducing a sub-interface with the method in it.

[Could also create an AbstractConnectionManager class - this would make it
easier to add more functions later]"
"HTTPCLIENT-758","DESIGN_DEFECT","BUG","Wrong method signatures in AbstractHttpClient","The method signatures for removeRequestInterceptorByClass and removeResponseInterceptorByClass in AbstractHttpClient are wrong. Must be

public void removeRequestInterceptorByClass(Class<? extends
HttpRequestInterceptor> clazz);

and

public void removeResponseInterceptorByClass(Class<? extends
HttpRequestInterceptor> clazz);"
"HTTPCLIENT-26","RFE","IMPROVEMENT","need a way to set request body in PostMethod","Currently, there is no way for user to set the request body in PostMethod 
directly. The only way to do that is by adding parameters to PostMethod. This 
makes sense in most cases. However, there are situations that the user actually 
knows the request body and want to set it directly. adding the following method 
fixes this:

    public void setRequestBody(String requestBody)
    {
        this.requestBody = requestBody;
    }"
"HTTPCLIENT-1100","BUG","BUG","Missing Content-Length header makes cached entry invalid","A cached entry whose original response didn't carry a Content-Length header, should not be rejected for considered invalid because the length of its cached content is different from the non-existing Content-Length header value. The attached patch only verifies the lengths if the header was originally present."
"HTTPCLIENT-675","BUG","BUG","thread starving in MultiThreadedHttpConnectionManager","Hi folks,

I might have found a bug in MTHCM. It has to do with removing HostConnectionPool instances that have no more connections in them. That was a fix for a memory leak we previously had. There are two cases where the pools get deleted. One is in handleLostConnection: (excerpt)
  ...
  if (hostPool.numConnections == 0) mapHosts.remove(config);
  notifyWaitingThread(config);
  ...

Could this delete a pool in which there is still a thread waiting to get a connection? If so, the thread would remain in the global pool. But even if it is interrupted there, it would still use the old HostConnectionPool in which no connection will ever become available again.

I suggest to change the removal check in both cases to:
  if ((hostPool.numConnections < 1) && hostPool.waitingThreads.isEmpty)

What do you think?"
"HTTPCLIENT-614","RFE","IMPROVEMENT","allow different strategies when checking CN of x509 cert","We're now doing a decent job for checking the CN of the x509 cert with https:

http://issues.apache.org/jira/browse/HTTPCLIENT-613

I think the patch for HTTPCLIENT-613 should cover 99.9% of the users out there.  But there are some more esoteric possibilities, so I think Oleg is right.  We need to let the user change the strategy, or provide their own strategy if they want to. 

Some additional things to think about:

- http://wiki.cacert.org/wiki/VhostTaskForce !!!   CN is depreciated?!?!   (I am not able to find a popular website on HTTPS that isn't using CN!)

- [*.example.com] matches subdomains [a.b.example.com] on Firefox, but not IE6.  The patch for HTTPCLIENT-613 allows subdomains.

- Should we support multiple CN's in the subject?

- Should we support ""subjectAltName=DNS:www.example.com"" ?  Should we support lots of them in a single cert?

- Should we support a mix of CN and subjectAltName?


If we do create some alternate strategies for people to try, I'd probably lean towards something like this:

X509NameCheckingStrategy.SUN_JAVA_6  (default)
X509NameCheckingStrategy.FIREFOX2
X509NameCheckingStrategy.IE7
X509NameCheckingStrategy.FIRST_CN_AND_NO_WILDCARDS   (aka ""STRICT"")

"
"HTTPCLIENT-713","CLEANUP","","remove RoutedRequest from ClientRequestDirector interface","Remove the RoutedRequest from ClientRequestDirector.execute, pass the request and route/target separately."
"HTTPCLIENT-298","DOCUMENTATION","IMPROVEMENT","javadoc often has <code> without </code>","Just to mention it:
there are a lot of javadoc comments that read like
 <tt>false</ff> otherwise.
which prints the rest of the document in <tt>
can't give a complete list, it happens very often.
To check, just go to the bottom of a page and see if it appears in <tt> or 
<code>"
"HTTPCLIENT-494","IMPROVEMENT","BUG","Invalid redirects are not corrected","If a get is made to a page with a query argument containing a space, many web
servers, notably including Tomcat 5 can generate a redirect in which the space
in the query argument is not escaped correctly.  Most browsers including IE and
Firefox compensate for this by quoting any included spaces in the redirect
location.  Http client does not.  When this broken URL is presented to a
subsequent server, the GET command is interprted incorrectly resulting (usually)
in a 505.

The fix is to replace spaces in redirect locations with +'s.  This doesn't
entirely fix the problem but that is the job of the web server developers."
"HTTPCLIENT-806","BUG","BUG","ConnectException not handled in DefaultHttpMethodRetryHandler","Copied from my mailing list post, Oleg suggested I post it to JIRA for 4.0 fix.

i am using commons-httpclient.3.0.1 and I am sending some requests
through https protocol. I have a problem with a long creation of
connection if ip address of remote service is not existing. I think
problem is in the situation when https connection is not created and
ConnectException is thrown after connection timeout. This exception is
catched in HttpMethodDirector.java in method executeWithRetry. Then
the DefaultHttpMethodRetryHandler is called to recognize whether
connection creation will be repeated or not.
I think, that special handling for ConnectException is missing in
retryMethod of DefaultHttpMethodRetryHandler, because exception is not
recognized and connetions are created again.
On the other hand, ConnectTimeoutException is thrown after connection
timeout for HTTP. This exception is handled in
DefaultHttpMethodRetryHandler and call is stopped.

These lines of code handle ConnectTimeoutException in retryMethod of
DefaultHttpMethodRetryHandler:
if (exception instanceof InterruptedIOException) {
            // Timeout
            return false;
        }

Probably this is missing for ConnectException:
if (exception instanceof InterruptedIOException || exception
instanceof ConnectException) {
            // Timeout
            return false;
        }

"
"HTTPCLIENT-1177","BUG","BUG","HttpClient treats URI fragments in redirect URIs incosistently","HttpClient treats URI fragments in redirect URIs incosistently. It strips fragments from relative URIs but leaves absolute ones unchanges.  "
"HTTPCLIENT-506","BUG","BUG","Digest auth uses wrong uri in proxy authentication","I'm having a problem getting httpclient-rc1 to authenticate using
digest to our IAS server.  I've tried upgrading to rc3 without any
effect.  I also got our IT guys to upgrade IAS without luck.  I was
also able to have the GET method work under IAS and CONNECT to work
with a couple other proxy servers.  After examining ethereal logs for
my (commons) code and firefox to the same URLs I noticed that the
value for the ""uri"" setting in the ""Proxy-Authorization"" header was
the only significant difference.  After looking at RFC 2617 I noticed
that in section 3.2.2 (The Authorization Request Header) it states:

digest-uri
The URI from Request-URI of the Request-Line; duplicated here because
proxies are allowed to change the Request-Line in transit.

A re-examination of the headers showed that firefox was matching the Request-URI
with the digest-uri but that httpclient was not.  I reproduced partial headers
below.  I tried modifying the RC3 source to produce a hard-coded value for ""uri""
and demonstrated that it would successfully authenticate to that URI.  I also
checked that authentication would fail to any other URI and it did.

partial httpclient header (fails with 407):
CONNECT gmail.google.com:443 HTTP/1.1
Proxy-Authorization: Digest username=""proxytest"", realm=""Digest"",
nonce=""503902c343c8c501057a85cea6bad2734378fb44b4cbd1970bf320637871dae85373082cf70ac254"",
uri=""/"", response=""7717d0738332a3d8e83e9102b5ead6b9"", qop=""auth"", nc=00000001,
cnonce=""583aa0469b31290dc2acd7ec6cfc98f1"", algorithm=""MD5-sess"",
opaque=""bb319760fce84856e5648d3536502d81""

partial firefox header (succeeds with 200):
CONNECT mail1.combrio.local:443 HTTP/1.1
Proxy-Authorization: Digest username=""proxytest"", realm=""Digest"",
nonce=""0e61fe645ec8c5015aa3afe8cfe5219488ed473e277a8cddf8225ad66e74fd214f97d9d96ac99991"",
uri=""mail1.combrio.local:443"", algorithm=MD5-sess,
response=""bfac109287273e867531170475172ccf"",
opaque=""70cb2a1533b85882d0f1aa1e2ad1fbae"", qop=auth, nc=00000001,
cnonce=""b41aecd6e527e774"""
"HTTPCLIENT-1182","RFE","RFE","Add a constructor to org.apache.http.conn.ssl.SSLSocketFactory to allow for directly wrapping a javax.net.ssl.SSLSocketFactory socketfactory","Our application use Java Webstart for deployment.  Amoung other things, Webstart gives us the ability to access the system's (in our case, Windows) certificate system.  For instance, one of our client is using certificate based authentication to their webserver.  This is done through a hardware device they attach to their system.  Window's already has a way to interface with this device, and Webstart has a way to interface with the Windows API.

I don't think we can get by with using any SocketFactory that we create.  (We would have to check with Oracle to be sure.)  I think we need to use the one that is set as the default in HttpsURLConnection.

What I am suggesting is that another constructor be added to allow for just wrapping this one.  I was not planning on putting a dependancy on HttpsURLConnection, but rather just add the ability to wrap any javax.net.ssl.SSLSocketFactory.

This will not be a big change to the API.  I will get a patch ready soon."
"HTTPCLIENT-444","BUG","BUG","Preemptive authentication causes NTLM auth scheme to fail","The NTLM authentication scheme does not work when the preemptive authentication
is enabled.

Reported by Dave Seidel <dave at mindreef.com>"
"HTTPCLIENT-657","TEST","BUG","TestBasicCookieAttribHandlers fails on non-english Locale systems","The Test checks for written dates in the format for cookies which unfortunately includes a two character abbreviation of the day. This differs by locale, so the dateformat has to be constructed with Locale.US (as in DateUtils)"
"HTTPCLIENT-41","RFE","IMPROVEMENT","New method to add an array of parameters to PostMethod","When posting a form a web page may have many parameters to post to the 
webserver.  Currently in PostMethod, if you wanted to add multiple parameters, 
you would have to call addParameter(name, value) for each one.

A new convinence method should be added to allow for simpler client code by 
taking an array of NameValuePair objects and adding all parameters in a single 
function call.

void addParameters(NameValuePair[] parameters) 

Also, the comments for PostMethod functions that deal with parameters 
state ""Override method of HttpMethodBase ..."" which is incorrect.  More 
informative comments should be added to this public API."
"HTTPCLIENT-1057","DOCUMENTATION","IMPROVEMENT","wrong class name in statemgmt.xml","""BasicClientCookie"" should read ""BasicCookieStore"", see the patch for details"
"HTTPCLIENT-998","IMPROVEMENT","IMPROVEMENT","cache should use both Last-Modified and ETag for validations when available","This is a protocol recommendation:

""[HTTP/1.1 clients], if both an entity tag and a Last-Modified value have been provided by the origin server, SHOULD use both validators in cache-conditional requests. This allows both HTTP/1.0 and HTTP/1.1 caches to respond appropriately.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.3.4

The current implementation only uses the ETag when conditionally validating an entry, so HTTP/1.0 caches can't currently reply to us with a 304 (Not Modified), even if that would be appropriate.
"
"HTTPCLIENT-869","OTHER","BUG","Incorrect/incomplete product name in META-INF/NOTICE file","The NOTICE file in the HttpClient jars is incorrect.

It states:

=====

HttpClient
Copyright 1999-2009 Apache Software Foundation
<snip/>
======

The leading blank line should be deleted, and ""HttpClient"" should be ""Apache HttpComponents Client - HttpClient""  (or similar) as is the case for the source archive.

Similarly for HttpMime"
"HTTPCLIENT-772","DOCUMENTATION","BUG","typo in RFC reference in web site","Quoting from <http://hc.apache.org/httpcomponents-client/index.html>:

""Standards Compliance

HttpClient strives to conform to the following specifications endorsed by the Internet Engineering Task Force (IETF) and the internet at large:

    * RFC 1945 - Hypertext Transfer Protocol -- HTTP/1.0
    * RFC 2116 - Hypertext Transfer Protocol -- HTTP/1.1
    * RFC2617 HTTP Authentication: Basic and Digest Access Authentication
    * RFC2109 HTTP State Management Mechanism (Cookies)
    * RFC2965 HTTP State Management Mechanism (Cookies v2)""

Note the typo in the reference to HTTP/1.1.
"
"HTTPCLIENT-526","IMPROVEMENT","BUG","warn on invalid set-cookie header","I had a problem on a WS server that comes from some proxy misconfiguration...
resulting in this reponse beeing received by HTTPclient :
17:26:36,489 DEBUG [header] << ""HTTP/1.1 200 OK[\r][\n]""
17:26:36,489 DEBUG [header] << ""Set-Cookie: =f448bb59feedbaaabaee; path=/[\r][\n]""
17:26:36,489 DEBUG [header] << ""Date: Tue, 15 Nov 2005 16:26:36 GMT[\r][\n]""
17:26:36,489 DEBUG [header] << ""Server: Apache[\r][\n]""
17:26:36,489 DEBUG [header] << ""Connection: close[\r][\n]""
17:26:36,489 DEBUG [header] << ""Transfer-Encoding: chunked[\r][\n]""
17:26:36,489 DEBUG [header] << ""Content-Type: text/xml;charset=utf-8[\r][\n]""

The set-cookie header is malformed, as cookie has no name, so the HTTP head may
be considered invalid.

This results in an error when building the NEXT request. I'd expect httpclient
to WARN on malformed header and drop it."
"HTTPCLIENT-342","DOCUMENTATION","BUG","[API Doc] Improve the description of the preemptive authentication","HttpClient authentication guide does not reflect the fact that preemptive
authentication requires default credentials to be set. It should also mention
the security implications of preemptive authentication (default credentials sent
with EVERY request to ANY target / proxy server)"
"HTTPCLIENT-261","BUG","BUG","infinite loop on 302 redirect with different host in Location: header","Using the CVS version - 2.1 rc I think.

Trying to get the url contents for a url with followRedirects specified and 
StrictMode off and I get a 302 redirect to a different url with a different 
host in the Location header causes it to go into an infinite loop (mercifully 
aborting at 100 redirects).  An example offending url: 

http://www.snowcrest.net/mice/mice.htm

The problem lies in HttpMethodBase.java version 1.177 at line 1225.  It does 
the following:

        if (getRequestHeader(""host"") != null) {
            LOG.debug(
                ""Request to add Host header ignored: header already added"");
            return;
        }

and there is already the Host header from the previous url request so it 
endlessly loops until it aborts at the max redirects (default is 100 I guess).  
I commented this out and it worked fine."
"HTTPCLIENT-1066","BACKPORT","BUG","HTTPClient 4.1 auto slash removal","I've put the same comment as in the following issue.

https://issues.apache.org/jira/browse/HTTPCLIENT-929?focusedCommentId=13001748#comment-13001748

I am using httpclient 4.1. I had a problem with this fix. In DefaultRequestDirector.rewriteRequestURI method, for non-proxied URI and when it is a absolute URI, it will call the URIUtils.rewriteURI, which then take the ""RawPath"" from an uri and normalize it. So when I pass an uri, for example, http://www.whatever.com/1//3, it will automatically remove the extra slash and become http://www.whatever.com/1/3. I've got a REStful service to accept the uri (/{param1}/{param2}/{param3}) and it takes when there is an empty value past in. Now because of the auto slash removal, the ""3"" value shift left for a position and match to the {param2}. I wouldn't say the above solution is wrong, but I guess it should not change what value that user pass in."
"HTTPCLIENT-769","BUG","BUG","java.lang.IllegalStateException: Connection already open.","I am seeing many of the same problems noted in HTTPCLIENT-741 using the latest builds from the maven repo.

java.lang.IllegalStateException: Connection already open.
        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:150)
        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)
        at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:308)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)
        at com.hi5.os.Hi5RemoteContentFetcher.fetch(Hi5RemoteContentFetcher.java:279)
"
"HTTPCLIENT-1016","RFE","IMPROVEMENT","Adding a custom location header extractor method for RedirectStrategy.","Sometimes Web Servers respond to http requests with non-standard location response headers during a server side redirect. (302)  ADding a convenience method to over come this."
"HTTPCLIENT-689","RFE","IMPROVEMENT","stackable parameters","Implement ""stackable parameters"" to allow for a parameter hierarchy without linking params instances."
"HTTPCLIENT-903","IMPROVEMENT","IMPROVEMENT","Use ConcurrentHashMap instead of HashMap wherever thread-safe access is needed","Consider using ConcurrentHashMap instead of HashMap for any Maps that are used by multiple threads.

For example SchemeRegistry and AuthSchemeRegistry."
"HTTPCLIENT-711","BUG","BUG","bad route computed for redirected requests","BasicRouteDirector appears to miscalculate complex routes. Example to follow. "
"HTTPCLIENT-659","IMPROVEMENT","IMPROVEMENT","DateUtils should cache SimpleDateFormat","DateUtils create a SimpleDateFormat for each invocation of #formatDate and #parseDate. This can be optimized if SimpleDateFormat instances are cached. Since SimpleDateFormat is not threadsafe, the cache must be threadlocal."
"HTTPCLIENT-944","BUG","BUG","In case of SocketTimeoutException and using HttpRequestRetryHandler the execution is always +1","If my request encounter a SocketTimeoutException, the HttpRequestRetryHandler#retryRequest will be called with an executionCount with a value +1."
"HTTPCLIENT-1158","IMPROVEMENT","","Change the error message in the exception at URIUtils#rewriteURI ","The message in URIUtils#rewriteURI is misspelled - ""URI may nor be null"" should be ""URI should not be null"""
"HTTPCLIENT-227","BUG","BUG","Missing Content-Length header causes a SocketException","Essentially, we have an invalid HTTP server (Stellent CMS actually and we will file a bug with them), 
which is returning headers like:

HTTP/1.1 401 Unauthorized
WWW-Authenticate: Basic ""Secure Realm""
Connection: keep-alive

Which is clearly missing the Content-Length header.  Now, previously HttpClient handled this 
perfectly by reading until the end of the connection (ie: treating it like it was a Connection: close), 
however for some reason a socket exception is being thrown and the invalid connection is added 
back into the connection pool and then every connection to the server after that thows an 
exception.

See the thread ""SocketException with invalid server"" for the full discussion of the issue.

I'll attach a patch that fixes the problem.  The biggest thing to consider is the changes to the 
duplicate Connection header test cases which resolves around the question: if Connection: keep-
alive is present but no Content-Length is provided, should the connection be closed?  The patch 
requires the answer to be yes and I really can't see any other way to do it."
"HTTPCLIENT-729","REFACTORING","IMPROVEMENT","move HttpRoute and related classes to separate package","The route-related stuff in o.a.h.conn is detached from the rest of the connection management API.
Move HttpRoute, RouteTracker, HttpRouteDirector, HttpRoutePlanner to o.a.h.conn.route or ...routing.
Implementation classes have a dependency on Scheme and SchemeRegistry in o.a.h.conn,
but that does not introduce a recursive dependency between packages.
"
"HTTPCLIENT-914","IMPROVEMENT","IMPROVEMENT","Use Apache Codec 1.4","1.4 fixes many bugs and added some nice features: http://commons.apache.org/codec/changes-report.html

It took me a whiel to find out, that this was the main reason my tests failed (MethodNotFoundException).
"
"HTTPCLIENT-399","RFE","BUG","Connection not closed after ""Connection: close"" request","In HTTP specification at http://www.w3.org/Protocols/rfc2616/rfc2616-
sec8.html , under chapter ""Negotiation"", it is stated :
""If either the client or the server sends the close token in the Connection 
header, that request becomes the last one for the connection.""

HttpClient (v2.0.2 and v3.0 alpha2) is currently closing connection only if 
server has sent ""Connection: close"" header, and not when request contains it."
"HTTPCLIENT-390","BUG","BUG","SSL + proxy + Host auth + Keep Alive off causes an infinite loop in HttpMethodDirector","The combination of SSL tunnelling, host authentication, and disabled persistent
connection support (HTTPD KeepAlive off) causes an infinite loop in
HttpMethodDirector. 

The problem has been reported on the httpclient-dev list by Rindress MacDonald
<RMacDona at enterasys.com>"
"HTTPCLIENT-674","IMPROVEMENT","IMPROVEMENT","use VersionInfo of core","With core alpha5, a version detection scheme was introduced.
Replace the preliminary version detection of client alpha1 with that in core.
That means new version.properties files, at least one per JAR, maybe one per potential JAR.
"
"HTTPCLIENT-413","BUG","BUG","Cookie with domain .mydomain.com not sent to host mydomain.com","A cookie with for example 
  .mydomain.com 
as domain property is not sent to the host
  mydomain.com
(without www. or anything else before ""mydomain.com"")

This concern all CookieSpec as the relevant code is located in CookieSpecBase:

    public boolean domainMatch(final String host, final String domain) {
        return host.endsWith(domain);
    }

It should be changed for instance to something like:

    public boolean domainMatch(final String host, final String domain) {
        // take care of host ""myDomain.com"" and domain "".myDomain.com""
        return host.endsWith(domain)
	|| _host.equals(_domain.substring(1));
    }"
"HTTPCLIENT-672","TASK","TASK","re-sync client with changes in core alpha6 snapshot","There have been API changes in core since it's alpha5 release.
Client needs to be adapted so it's alpha2 (snapshot) builds and runs against the current core API.
"
"HTTPCLIENT-505","UNKNOWN","BUG","cipher"," "
"HTTPCLIENT-464","BUG","BUG","An HTTP ""204 NO CONTENT"" response results in dropped connection","After receiving a ""204 NO CONTENT"" response, HttpClient always closes the 
connection.

This did not happen in earlier versions and appears to have been caused by a 
recent fix to bug# 34262."
"HTTPCLIENT-1139","BUG","BUG","NTLM Authentication No Longer Working In Latest Release","Our application has been working fine using NTLM auth with HttpClient for 3 years.   We were most recently on 4.0.3.    Upon upgrading to 4.1.2, NTLM stopped working.

I tried both the new for 4.1 built-in NTLM and the ""old way"" of using JCIFS: client.getAuthSchemes().register(""ntlm"", new NTLMSchemeFactory()); 

Using wireshark I can see that NTLM auth is not even attempted using 4.1.2.    Rolling back to 4.0.3 immediately resolved this problem."
"HTTPCLIENT-243","RFE","BUG","Transfer-Encoding: identity not supported + possible patch","In HttpMethodBase.readResponseBody only chunked transfer encoding is 
supported.  Some proxy servers like Privoxy, etc send a Transfer-Encoding: 
identity header and HttpClient fails quietly and returns a null result input 
stream.  At line 2037 in HttpMethodBase.java revision 1.160 I inserted the 
following two lines and it appeared to work fine:

} else if (""identity"".equalsIgnoreCase(transferEncodingHeader.getValue())) {
   result = is;

I think it should at least throw an exception or do something when it 
encounters an unsupported Transfer-Encoding instead of returning a null input 
stream."
"HTTPCLIENT-595","BUILD_SYSTEM","IMPROVEMENT","Fix junit scope in maven pom","Please change the junit dependency to

    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>3.8.1</version>
      <url>http://www.junit.org/</url>
      <properties>
        <scope>test</scope>
      </properties>
    </dependency>

for better automatic conversion to maven 2"
"HTTPCLIENT-822","IMPROVEMENT","BUG","HttpClient throws java.net.SocketException instead of org.apache.http.conn.ConnectionTimeoutException when connection timeout occurs","When sending an http request a connection timeout occurs, the HttpClient.execute method throws a java.net.SocketException instead of a org.apache.http.conn.ConnectionTimeoutException.

java.net.SocketTimeoutException: connect timed out
        at java.net.PlainSocketImpl.socketConnect(Native Method)
        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
        at java.net.Socket.connect(Socket.java:519)
        at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:119)
        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:129)
        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:164)
        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)
        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:349)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:555)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:487)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:465)
"
"HTTPCLIENT-5","BUG","BUG","Cookie.parse exception when parsing expiry date in single quotes","A Netscape-Enterprise/3.6 SP3 server sends a cookie where the parameter expires='Thu, 05-Dec-
2002 12:07:45 GMT'. 
Cookie.parse throws an exception because none of the four built-in formats 
matches - I have tested that the parse code works OK if the single quotes are omitted from the value 
being parsed.

Resolution: If the value of the 'expires' parameter starts and ends with a 
single quote then strip the first and last character before parsing."
"HTTPCLIENT-478","BUG","BUG","HttpConnectionParams.setConnectionTimeout(int) has no effect if host unreachable","I have just modified MultiThreadedExample.java by adding
httpClient.getHttpConnectionManager().getParams().setConnectionTimeout(5000); in
order to set a connection timeout on the client side. Then I have added a LAN
url to urisToGet array. The ip of this url (""http://192.168.254.1/"") is not
assigned to any computer.

After running the client, I get the expected message ( error:
org.apache.commons.httpclient.ConnectTimeoutException: The host did not accept
the connection within timeout of 5000 ms) but only after 20 seconds.

I use java version ""1.5.0_04"". This is not a JVM bug since normal connection
procedure times out after 5 seconds as expected:
        SocketAddress addr = new InetSocketAddress(""192.168.254.1"", 80);
        try {
            
            SocketChannel channel = SocketChannel.open();
            channel.socket().connect(addr, 5000);            
            System.out.println(""connected"");
            
        } catch (Exception e) {
            e.printStackTrace();
        }"
"HTTPCLIENT-107","BUG","BUG","HttpMethodBase: Port mismatch in URL for redirect to absolute location","The CVS version of latka was failing a test ( $ ant test, not maven ), when
using the CVS version of httpclient. The message was

 [java] WARN  [main] org.apache.commons.httpclient.HttpMethod
      - Redirect from port 80 to -1 is not supported: 21 Sep 2002 00:54:32,098

The request preceding this was:

 [java] DEBUG [main] httpclient.wire - >> ""GET /commons HTTP/1.1
     [java] "" [\r\n]: 21 Sep 2002 00:54:31,262
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
[java] DEBUG [main] httpclient.wire - >> ""Host: jakarta.apache.org
     [java] "" [\r\n]: 21 Sep 2002 00:54:31,441
     [java] DEBUG [main] httpclient.wire - >> ""User-Agent: Jakarta
Commons-HttpClient/2.0M1
 [java] "" [\r\n]: 21 Sep 2002 00:54:31,442

And the response was:

 [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
HttpMethodBase.readStatusLine(HttpState, HttpConnection): 21 Sep 2002 00:54:31,444
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:31,444
[java] DEBUG [main] httpclient.wire - << ""HTTP/1.1 301 Moved Permanently""
[\r\n]: 21 Sep 2002 00:54:32,080
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
HttpMethodBase.readResponseHeaders(HttpState,HttpConnection): 21 Sep 2002
00:54:32,086
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,087
[java] DEBUG [main] httpclient.wire - << ""Date: Fri, 20 Sep 2002 23:54:30 GMT""
[\r\n]: 21 Sep 2002 00:54:32,088
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,089
[java] DEBUG [main] httpclient.wire - << ""Server: Apache/2.0.42 (Unix)"" [\r\n]:
21 Sep 2002 00:54:32,090
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,090
[java] DEBUG [main] httpclient.wire - << ""Location:
http://jakarta.apache.org/commons/"" [\r\n]: 21 Sep 2002 00:54:32,091
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,091
[java] DEBUG [main] httpclient.wire - << ""Content-Length: 319"" [\r\n]: 21 Sep
2002 00:54:32,091
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,092
[java] DEBUG [main] httpclient.wire - << ""Content-Type: text/html;
charset=iso-8859-1"" [\r\n]: 21 Sep 2002 00:54:32,092
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.readLine(): 21 Sep 2002 00:54:32,092
[java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
HttpMethodBase.processResponseHeaders(HttpState, HttpConnection): 21 Sep 2002
00:54:32,093
     [java] DEBUG [main] org.apache.commons.httpclient.methods.GetMethod - enter
GetMethod.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,093
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
HttpMethodBase.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,093
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
HttpMethodBase.readResponseBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,094
     [java] DEBUG [main] org.apache.commons.httpclient.HttpConnection - enter
HttpConnection.getRequestOutputStream(HttpMethod): 21 Sep 2002 00:54:32,094
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - enter
writeRemainingRequestBody(HttpState, HttpConnection): 21 Sep 2002 00:54:32,096
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - Redirect
required: 21 Sep 2002 00:54:32,097
     [java] DEBUG [main] org.apache.commons.httpclient.HttpMethod - Redirect
requested to location 'http://jakarta.apache.org/commons/': 21 Sep 2002 00:54:32,097
     [java] WARN  [main] org.apache.commons.httpclient.HttpMethod - Redirect
from port 80 to -1 is not supported: 21 Sep 2002 00:54:32,098


The problem appears to be in this section of code from HttpMethodBase

if (url == null) {
    //try to construct the new url based on the current url
    try {
        URL currentUrl = new URL(conn.getProtocol(),
                                 conn.getHost(),
                                 conn.getPort(), getPath());
        url = new URL(currentUrl, location);   <--- is this inheriting the port?
    } catch (Exception ex) {
        log.error(""Redirected location '""
                  + locationHeader.getValue()
                  + ""' is malformed"");
        return statusCode;
    }
}"
"HTTPCLIENT-280","BUG","BUG","Freezes w/ MultiThreadedHttpConnectionManager","My single threaded user of VFS (an HttpClient user, that uses
MultiThreadedHttpConnectionManager) hangs [I suspect indefinitely] on minor
activity.

I've turned on HttpClient debug and I see this, the last line
being the last thing I get...

2003/10/09 09:34:26:482 MDT [DEBUG] wire - -<< ""Content-Type:
text/html[\r][\n]""
2003/10/09 09:34:26:482 MDT [DEBUG] HttpMethodBase - -Resorting to protocol
version default close co
nnection policy
2003/10/09 09:34:26:492 MDT [DEBUG] HttpMethodBase - -Should NOT close
connection, using HTTP/1.1
2003/10/09 09:34:26:502 MDT [DEBUG] HttpMethodDirector - -Execute loop try 1
2003/10/09 09:34:26:512 MDT [DEBUG]
MultiThreadedHttpConnectionManager - -HttpConnectionManager.getC
onnection:  config = HostConfiguration[host=www.ibiblio.org,
protocol=http:80, port=80], timeout = 0

2003/10/09 09:34:26:522 MDT [DEBUG]
MultiThreadedHttpConnectionManager - -Unable to get a connection
, waiting..., hostConfig=HostConfiguration[host=www.ibiblio.org,
protocol=http:80, port=80]

This is pretty reproducible. When I hack VFS not to use the
MultiThreadedHttpConnectionManager I don't get the problem."
"HTTPCLIENT-347","IMPROVEMENT","BUG","MultiThreadedConnectionManager Accounting Problems","getConnectionsInPool() is certainly a more intutive name. 
At the same, as you already mentioned, certainly there need to be a connection killer method: 
MultiThreadedHttpConnectionManager.destroyIdleConnections(long idleTime) 

Also, I would recommend one method which could spit out connection statistics at any time for the 
given Connection Manager. This will be great method for testing purpose as well. 
MultiThreadedHttpConnectionManager.displayCurrentStatistics(); 
----------------------------------
Curent Connection Statistics
----------------------------------
Total connectinos in Pool = 10
Open connectinos          = 3
Close connections         = 5
Stale connections         = 2 
And, if are even more adventurous we could extend our report to: 
Average wait time for connection = 1356 ms
Maximum wait time for connectino = 1892 ms"
"HTTPCLIENT-755","BUG","BUG","Use of java.net.URI.resolve() is buggy","The use of java.net.URI.resolve() is buggy (see <http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4708535>). Affected class: org.apache.http.impl.client.DefaultRedirectHandler.

Proposed solution: Create a resolve(URI, String) method in o.a.h.client.utils.URLUtils."
"HTTPCLIENT-1154","RFE","IMPROVEMENT","org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should allow client to specify custom prefix string for keys","org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should allow client to specify custom prefix string for keys, so as to ensure collision-avoidance with other memcached keys the client may be using."
"HTTPCLIENT-582","RFE","IMPROVEMENT","Allow access to registered cookie policies","It would be useful for JMeter (and perhaps other applications) to have access to the list of registered Cookie policy names.

[If this is acceptable, let me know if you want me to provide a patch.]"
"HTTPCLIENT-653","IMPROVEMENT","IMPROVEMENT","connection wrapper prevents GC of TSCCM","Even if a connection is released back to the ThreadSafeClientConnManager, a hard reference to the connection wrapper will prevent GC of the TSCCM.
Make sure the connection wrapper is properly detached on release. Then update TestTSCCMWithServer.testConnectionManagerGC() accordingly. 
"
"HTTPCLIENT-166","IMPROVEMENT","BUG","waitForResponse is using busy wait","In HttpConnection, the method waitForResponse is using busywait, instead of 
blocking until the response is arriving.

Is this on purpose, or shouldn't it handle this by blocking instead ??"
"HTTPCLIENT-484","REFACTORING","IMPROVEMENT","Fold AuthSSLProtocolSocketFactory into HttpClient proper","Include the functionality of the AuthSSLProtocolSocketFactory class into the
main distribution of HttpClient

http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/contrib/org/apache/commons/httpclient/contrib/ssl/"
"HTTPCLIENT-226","BUG","BUG","HttpMethod#getResponseBody throws NPE","HttpMethod#getResponseBody throws an NPE if the response from the server was 
204.  Shouldn't getResponseBody return null by contract instead of throwing 
NPE?"
"HTTPCLIENT-775","OTHER","BUG","download section of website down","maybe you know this, but http://hc.apache.org/downloads.cgi (the downloads for httpcomponents and for httpclient) is broken (500 internal server error)..."
"HTTPCLIENT-48","RFE","IMPROVEMENT","User interaction for authentication","Some actions require user input.  Like forwarding to another host or retrieveing
authentication credentials.  Should have some way for clients to setup listeners
for such events so that they can be handled on the fly.  No gui, programatic
only."
"HTTPCLIENT-245","RFE","RFE","customize handling of 302 redirects","I tried this with both the beta2 2.0 release, and the nightly build.  The
following code snippet describes what I am trying to do:

httpClient.getHostConfiguration().setHost(sHost, 80, ""http"");
HttpMethod method=null;
if (sMethod.indexOf(""POST"")!=-1) {
     method=new PostMethod(sURLInfo);
} else {
     method=new GetMethod(sURLInfo);
}
method.setFollowRedirects(true);
httpClient.executeMethod(method);

After this code executes, the ""getFollowRedirects"" method still returns false,
and any redirects which are sent by the webserver are not followed.  As a
temporary workaround, since I want all redirects followed, I commented out the
following code in the HttpMethodBase class in the ""processRedirectResponse"" method:

/*if (!getFollowRedirects()) {
     LOG.info(""Redirect requested but followRedirects is ""
     + ""disabled"");
     return false;
}*/

If this bug has already been reported, I apologize...I searched for and found
nothing related to this issue."
"HTTPCLIENT-815","DOCUMENTATION","IMPROVEMENT","Quick Start guide for HttpClient 4.0","cannot determine the required jar files to compile samples/ own files

example org.apache.http.examples.client.ClientFormLogin

used

set CLASSPATH=P:\j\samples\httpClient\examples;j:\j\j5\h;P:\j\e\mysql.jar;P:\j\e\commons-logging-api-1.1.1.jar;P:\j\e\commons-logging-1.1.1.jar;P:\j\e\4\httpmime-4.0-beta2.jar;P:\j\e\4\httpclient-4.0-beta2.jar;P:\j\e\4\h\e\4\httpcore-4.0-beta3.jar;P:\j\e\4\httpcore-nio-4.0-beta3.jar

but still needs org.apache.http.*; ... where are these jars? a quick start guide / link to all jars for one version would help

- only known workaround - go back to old version 3.1"
"HTTPCLIENT-1056","BUG","BUG","Wrong creation of AuthScope object","Class Name: org.apache.http.client.protocol.RequestAuthCache
Line #: 118-119

Issue: Want to create a new Object of AuthScope by passing host name, port and scheme name but due to incorrect constructor call, Getting a object with realm name as scheme name.
Current Code: Credentials creds = credsProvider.getCredentials(new AuthScope(host.getHostName(), host.getPort(), null, schemeName));"
"HTTPCLIENT-309","RFE","IMPROVEMENT","[RFE] Allow streaming of POST methods via chunked transfer encoding.","This is an RFE with a possible implementation attached. The implementation does
not modify any existing code.

We're using HTTP POST to send a large amount of data with an unknown size. We
don't want to buffer the entire request, so we implemented a streaming POST
method. The implementation has 3 classes: StreamedPostMethod,
BufferedChunkedOutputStream and OutputStreamWriter. The bulk of the code is in
the BufferedChunkedOutputStream, which may be a good target for replacing
ChunkedOutputStream from the main distribution.

BufferedChunkedOutputStream has the following charactersitics:
1) It has an internal 2K buffer. Without the buffer, chunk sizes would be too
small in many cases (e.g. ObjectOutputStream likes to call write(byte[]) with 4
byte long arguments). 2K was chosen to minimize the chunk overhead to less than 1%.
2) If the entire entity body fits within the 2K buffer, it does not use
chunking. This implies that the headers are only sent out when the first chunk
(or the entire body) has to be written, but no sooner.
3) The chunk size is not limited to 2K: if write(byte[]) is called with a large
argument, the internal buffer and the new request are sent out as a single chunk.
4) Because of (2) it's tightly coupled to StreamedPostMethod.reallyWriteHeaders.
5) StreamedPostMethod calls BufferedChunkedOutputStream.finish() to write the
last buffer and ending chunk.

Because of 4 and 5, we didn't want to touch ChunkedOutputStream. Interestingly,
EntityEnclosingMethod is already tightly coupled to ChunkedOutputStream because
it has to call writeClosingChunk. There is probably some room for refactoring here.

The package is just a suggestion; feel free to move the files as appropirate.
This code was written against 2.0rc2. We're hoping it will get included in time
for the 2.1 release.

To use the code, you must implement OutputStreamWriter and pass it to
StreamedPostMethod's constructor. Execute the method as usual.

Caveats: StreamedPostMethod does not implement Expect/continue logic. We had no
way to test this. It is also strictly for POST. In general, the same methodology
is applicable to PUT, etc. It should be fairly simple to generalize.

Legal: Goldman, Sachs & Co. is making this code available under the Apache License."
"HTTPCLIENT-1157","IMPROVEMENT","BUG","MemcachedHttpCacheStorage should throw IOExceptions instead of Runtime Exceptions","The MemcachedHttpCacheStorage class implements HttpCacheStorage which defines that methods will throw IOExceptions, but the underlying net.spy.memcached.MemcachedClientIF throws runtime exceptions. These exceptions are not caught in the code where IOExceptions are expected causing these exception bubble up to the calling code. It seems like the MemcachedHttpCacheStorage class should treat at least some of these runtime exceptions as IOExceptions so that normal code execution paths can be followed.  

I'm proposing that MemcachedHttpCacheStorage treat a OperationTimeoutException from the memcached client as an IOException. This would allow the existing CachingHttpClient code to catch and log the exception as a warning, instead of bubbling the exception up the calling code.
"
"HTTPCLIENT-725","CLEANUP","IMPROVEMENT","TSCCM code cleanup","The ThreadSafeClientConnectionManager, or rather it's ConnPoolByRoute, needs plenty of cleanup.
- use long + TimeUnit for timeout intervals (Java 5 style)
- compute timeout end date once instead of remaining interval
- review which methods should acquire the pool lock,
  and which should expect the caller to have done that
- use factory methods to instantiate some of the helper objects
"
"HTTPCLIENT-344","IMPROVEMENT","BUG","HttpConnection.isOpen() logging is not accurate","isOpen() does not differentiate between stale and closed.  If the connection is closed isStale() will return 
true.  The logs will then indicate that the connection was stale, even though it was really just closed.  
close() is also called a second time unnecessarily.

This should be fixed for 3.0, and perhaps even 2.0.1.

<http://nagoya.apache.org/eyebrowse/ReadMsg?listName=commons-httpclient-
dev@jakarta.apache.org&msgNo=7205>"
"HTTPCLIENT-989","BUG","BUG","DefaultHttpRequestRetryHandler must not retry non-idempotent http methods (violates RFC 2616)","In DefaultHttpRequestRetryHandler, in case of NoHttpResponseException, the request is retried, without taking into account whether the http method is idempotent or not. This violates RFC 2616 section 8.1.4 which states :
{quote}
This means that clients, servers, and proxies MUST be able to recover
   from asynchronous close events. Client software SHOULD reopen the
   transport connection and retransmit the aborted sequence of requests
   without user interaction so long as the request sequence is
   idempotent (see section 9.1.2). Non-idempotent methods or sequences
   MUST NOT be automatically retried, although user agents MAY offer a
   human operator the choice of retrying the request(s).
{quote}

The fix is simple : at line 94, just remove the {{if (exception instanceof NoHttpResponseException) }} block. This way the idempotency of the method will be taken into account a bit further in the same method."
"HTTPCLIENT-1147","BUG","BUG","When HttpClient-Cache cannot open cache file, should act like miss","Set up HttpClient-Cache like this:
final String cacheDir = ""cachedir"";
HttpClient cachingHttpClient;
final CacheConfig cacheConfig = new CacheConfig();
cacheConfig.setSharedCache(false);
cacheConfig.setMaxObjectSizeBytes(262144); //256kb

if(! new File(cacheDir, ""httpclient-cache"").exists()){
	if(!new File(cacheDir, ""httpclient-cache"").mkdir()){
		throw new RuntimeException(""failed to create httpclient cache directory: "" + new File(cacheDir, ""httpclient-cache"").getAbsolutePath());
	}
}
final ResourceFactory resourceFactory = new FileResourceFactory(new File(cacheDir, ""httpclient-cache""));

final HttpCacheStorage httpCacheStorage = new ManagedHttpCacheStorage(cacheConfig);

cachingHttpClient = new CachingHttpClient(client, resourceFactory, httpCacheStorage, cacheConfig);

Then make a request:
final HttpGet get = new HttpGet(url);
final HttpResponse response = cachingHttpClient.execute(get);
final StatusLine statusLine = response.getStatusLine();
if (statusLine.getStatusCode() >= 300) {
	if(statusLine.getStatusCode() == 404)
		throw new NoResultException();
    throw new HttpResponseException(statusLine.getStatusCode(),
            statusLine.getReasonPhrase());
}
response.getEntity().getContent();

Everything worked as expected.

Now delete the cache directory (""cachedir/httpclient-cache"" in this example).

And make the same request again.

Actual:
 Caused by: java.lang.IllegalStateException: Content has been consumed
	at org.apache.http.entity.BasicHttpEntity.getContent(BasicHttpEntity.java:84)
	at org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:100)

Expected:
HttpClient shouldn't throw an exception - it should just perform the request again acting like a cache miss."
"HTTPCLIENT-715","CLEANUP","","remove RoutedRequest from API","Remove RoutedRequest from the Client API. It can be moved to impl, or dropped altogether.
HttpClient could accept separate request and target arguments instead of RoutedRequest.
No routes should be passed in the API. "
"HTTPCLIENT-242","IMPROVEMENT","BUG","Add InputStream buffering.","Currently HttpClient does not buffer the InputStream received from the socket. 
Perhaps doing so would improve performance.

Reported by Tony Bigbee."
"HTTPCLIENT-365","BUG","BUG","StatusLine IndexOutOfBounds","Reported by Sam Berlin on the developers mailing list:

I'm not sure if this problem is still on CVS HEAD, but we're seeing it  
against 2.0rc2.  In StatusLine (line 139 in my version), when it walks  
through the spaces, it is possible that the entire line was spaces (and  
thus a malformed response).  The code will throw an  
StringIndexOutOfBoundsException now instead of the correct  
HttpException.  See the following bug:

http://bugs.limewire.com/bugs/ 
searching.jsp?disp1=l&disp2=c&disp3=o&disp4=j&l=151&c=204&m=416_205

Thanks,
  Sam"
"HTTPCLIENT-1069","BUG","BUG","HttpClient 4.1 ignores request retry handler and stops retrying when a read timeout is followed by a connection refusal","I encountered an issue while writing unit tests for the RestBackup(tm) API Client Library, https://github.com/mleonhard/restbackup-java .  HttpClient 4.1 is failing to retry when it encounters a read timeout followed by a connection refusal.  This problem occurs on Windows but not on Linux.  Below is a short program that reproduces the problem.  It performs the expected 5 request attempts on Linux but only 2 on Windows.

My Windows environment is a laptop with Windows 7 Ultimate 64-bit and Oracle Java SE Development Kit Update 21 32-bit.  My Linux environment is Amazon EC2 with Ubuntu 10.04 LTS 32-bit and Oracle Java SE Development Kit Update 21 32-bit.

This is my first bug report to an Apache project.  I'd like to add that I'm a big fan of the Commons libraries and Http Components.

Sincerely,
-Michael

=== RetryBug.java ===

import java.io.IOException;
import java.net.ServerSocket;
import java.util.logging.Logger;

import org.apache.http.client.HttpRequestRetryHandler;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.impl.client.DefaultHttpClient;
import org.apache.http.params.CoreConnectionPNames;
import org.apache.http.protocol.HttpContext;

public class RetryBug {
    private static final Logger _log = Logger.getLogger(RetryBug.class.getName());

    public static void main(String[] args) throws IOException {
        ServerSocket serverSocket = new ServerSocket(0, 1);
        DefaultHttpClient httpClient = new DefaultHttpClient();
        HttpRequestRetryHandler retryHandler = new HttpRequestRetryHandler() {
                public boolean retryRequest(IOException e, int count, HttpContext context) {
                    _log.info(""count="" + count + "" "" + e.toString());
                    return count < 5;
                }
            };
        httpClient.setHttpRequestRetryHandler(retryHandler);
        httpClient.getParams().setIntParameter(CoreConnectionPNames.SO_TIMEOUT, 100);
        try {
            String url = ""http://127.0.0.1:"" + serverSocket.getLocalPort() + ""/"";
            httpClient.execute(new HttpGet(url));
        } finally {
            serverSocket.close();
        }
    }
}


=== Windows 7 ===

C:\RetryBug>md5sum httpcomponents-client-4.1-bin.zip
008ad15560249bcde42cfe34fdb4e858 *httpcomponents-client-4.1-bin.zip

C:\RetryBug>""c:\Program Files (x86)\Java\jdk1.6.0_21\bin\java.exe"" -version
java version ""1.6.0_21""
Java(TM) SE Runtime Environment (build 1.6.0_21-b06)
Java HotSpot(TM) Client VM (build 17.0-b16, mixed mode)

C:\RetryBug>""c:\Program Files (x86)\Java\jdk1.6.0_21\bin\javac.exe"" -cp httpcomponents-client-4.1\lib\commons-codec-1.4.jar;httpcomponents-client-4.1\lib\commons-logging-1.1.1.jar;httpcomponents-client-4.1\lib\httpclient-4.1.jar;httpcomponents-client-4.1\lib\httpcore-4.1.jar RetryBug.java

C:\RetryBug>""c:\Program Files (x86)\Java\jdk1.6.0_21\bin\java.exe"" -cp httpcomponents-client-4.1\lib\commons-codec-1.4.jar;httpcomponents-client-4.1\lib\commons-logging-1.1.1.jar;httpcomponents-client-4.1\lib\httpclient-4.1.jar;httpcomponents-client-4.1\lib\httpcore-4.1.jar;. RetryBug
Mar 9, 2011 9:14:36 PM RetryBug$1 retryRequest
INFO: count=1 java.net.SocketTimeoutException: Read timed out
Mar 9, 2011 9:14:36 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out
Mar 9, 2011 9:14:36 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: Retrying request
Exception in thread ""main"" org.apache.http.conn.HttpHostConnectException: Connection to http://127.0.0.1:56361 refused
        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:158)
        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:149)
        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:121)
        at org.apache.http.impl.client.DefaultRequestDirector.tryExecute(DefaultRequestDirector.java:650)
        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:454)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)
        at RetryBug.main(RetryBug.java:27)
Caused by: java.net.ConnectException: Connection refused: connect
        at java.net.PlainSocketImpl.socketConnect(Native Method)
        at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)
        at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)
        at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)
        at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)
        at java.net.Socket.connect(Socket.java:529)
        at org.apache.http.conn.scheme.PlainSocketFactory.connectSocket(PlainSocketFactory.java:120)
        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:148)
        ... 8 more

C:\RetryBug>


=== Ubuntu 10 ===

$ md5sum httpcomponents-client-4.1-bin.tar.gz
f043c1cc016cb3b720be9fb020bfa755  httpcomponents-client-4.1-bin.tar.gz
$ ~/jdk1.6.0_21/bin/java -version
java version ""1.6.0_21""
Java(TM) SE Runtime Environment (build 1.6.0_21-b06)
Java HotSpot(TM) Client VM (build 17.0-b16, mixed mode, sharing)
$ ~/jdk1.6.0_21/bin/javac -cp httpcomponents-client-4.1/lib/httpclient-cache-4.1.jar:httpcomponents-client-4.1/lib/commons-logging-1.1.1.jar:httpcomponents-client-4.1/lib/httpcore-4.1.jar:httpcomponents-client-4.1/lib/httpclient-4.1.jar:httpcomponents-client-4.1/lib/httpmime-4.1.jar:httpcomponents-client-4.1/lib/commons-codec-1.4.jar RetryBug.java
$ ~/jdk1.6.0_21/bin/java -cp httpcomponents-client-4.1/lib/httpclient-cache-4.1.jar:httpcomponents-client-4.1/lib/commons-logging-1.1.1.jar:httpcomponents-client-4.1/lib/httpcore-4.1.jar:httpcomponents-client-4.1/lib/httpclient-4.1.jar:httpcomponents-client-4.1/lib/httpmime-4.1.jar:httpcomponents-client-4.1/lib/commons-codec-1.4.jar:. RetryBug
Mar 9, 2011 1:09:42 PM RetryBug$1 retryRequest
INFO: count=1 java.net.SocketTimeoutException: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: Retrying request
Mar 9, 2011 1:09:42 PM RetryBug$1 retryRequest
INFO: count=2 java.net.SocketTimeoutException: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: Retrying request
Mar 9, 2011 1:09:42 PM RetryBug$1 retryRequest
INFO: count=3 java.net.SocketTimeoutException: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: Retrying request
Mar 9, 2011 1:09:42 PM RetryBug$1 retryRequest
INFO: count=4 java.net.SocketTimeoutException: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: I/O exception (java.net.SocketTimeoutException) caught when processing request: Read timed out
Mar 9, 2011 1:09:42 PM org.apache.http.impl.client.DefaultRequestDirector tryExecute
INFO: Retrying request
Mar 9, 2011 1:09:51 PM RetryBug$1 retryRequest
INFO: count=5 java.net.SocketTimeoutException: Read timed out
Exception in thread ""main"" java.net.SocketTimeoutException: Read timed out
        at java.net.SocketInputStream.socketRead0(Native Method)
        at java.net.SocketInputStream.read(SocketInputStream.java:129)
        at org.apache.http.impl.io.AbstractSessionInputBuffer.fillBuffer(AbstractSessionInputBuffer.java:149)
        at org.apache.http.impl.io.SocketInputBuffer.fillBuffer(SocketInputBuffer.java:110)
        at org.apache.http.impl.io.AbstractSessionInputBuffer.readLine(AbstractSessionInputBuffer.java:260)
        at org.apache.http.impl.conn.DefaultResponseParser.parseHead(DefaultResponseParser.java:98)
        at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:252)
        at org.apache.http.impl.AbstractHttpClientConnection.receiveResponseHeader(AbstractHttpClientConnection.java:281)
        at org.apache.http.impl.conn.DefaultClientConnection.receiveResponseHeader(DefaultClientConnection.java:247)
        at org.apache.http.impl.conn.AbstractClientConnAdapter.receiveResponseHeader(AbstractClientConnAdapter.java:219)
        at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:298)
        at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
        at org.apache.http.impl.client.DefaultRequestDirector.tryExecute(DefaultRequestDirector.java:622)
        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:454)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)
        at RetryBug.main(RetryBug.java:27)
$"
"HTTPCLIENT-1044","SPEC","IMPROVEMENT","DefaultHttpRequestRetryHandler is not handling PUT as an idempotent method for retries, though RFC2616 section 9.1.2 clearly defines it to be one.","See attached patch file for a fix:

Fix treats PUT requests as idempotent, marking them to be retried when their enclosed HttpEntity is either null or repeatable.

"
"HTTPCLIENT-773","BUG","BUG","Parsing expires","Seeing this very often:

 Invalid cookie header: ""Set-Cookie: _asid=011e7014f5e7718e02d893335aa5a16e; path=/; expires=Wed, 16 May 2018 17:13:32 GMT"". Unable to parse expires attribute: Wed, 16 May 2018 17:13:32 GMT"
"HTTPCLIENT-906","IMPROVEMENT","IMPROVEMENT","Minor performance improvement to IdleConnectionHandler","The attached patch does the following changes to IdleConnectionHandler
 - as it iterator over a map of connections, using a LinkedHashMap is a faster
 - rather than using an iterator over the keyset and subsequently getting the values, an iterator over the entry set is used instead for efficiency (at least according to FindBugs)

Note that the patch contains other changes to make variables final where possible. This was done automatically by Eclipse, and can be removed if desired. However I see no harm in them, other than they affect more of the code than intended by the patch."
"HTTPCLIENT-463","BUG","BUG","Occasional ""Host connection pool not found""","I'm using HttpClient with MultiThreadedHttpConnectionManager in a crawler
application. The application issues requests to many hosts, in 10-20 parallel
request threads. Each thread creates a new GetMethod, but all threads use the
same instance of HttpClient, created once with a multi-threaded manager.

The code in each thread looks like this:

GetMethod get = new GetMethod(url);
try {
  int code = getSharedHttpClient().executeMethod(get);
  // ... read response, do stuff
} finally {
  get.releaseConnection();
}


From time to time I get an error like this:

Host connection pool not found, hostConfig=HostConfiguration[host=http://a.b.c]

where the url is a random url from my fetch list. I looked into the source code
of the nightly release (MultiThreadedHttpConnectionManager.java:979), but the
comment there is not enlightening... ;-) Any help or suggestions for further
debugging would be appreciated."
"HTTPCLIENT-108","IMPROVEMENT","BUG","Cookie.java: 'bookean' typo"," "
"HTTPCLIENT-765","BUG","BUG","String.toLowerCase() / toUpperCase() should specify Locale.ENGLISH","There are quite a few instances of String.toLowerCase() - and some of toUpperCase() - method calls which don't specify the Locale.

These should probably mostly/all use Locale.ENGLISH, otherwise there may be problems in some Locales.
e.g. Turkey, where ""i"".toUpperCase() is not equal to ""I"" - and vice-versa.

The isSpecialDomain() method in NetscapeDomainHandler is one instance where the code won't always work in Turkey."
"HTTPCLIENT-383","CLEANUP","BUG","HostConfiguration handling requires cleanup","As discussed on the mailing list, the host configuration handling currently
appears faulty:

http://marc.theaimsgroup.com/?t=109644952000001&r=1&w=2

Oleg"
"HTTPCLIENT-216","BUG","BUG","Cookies with null path attribute are rejected in the compatibility mode","Weblogic sends cookies with path empty, httpclient emits a warning
and doesn't send back the cookie to server.

Maybe httpclient works in the RFC's ways but this doesn't reproduce
common web browsers behaviours. Our application works well with IE,
Opera and Netscape, httpunit also sends back the cookie to the server.

When receving the response, httpclient emits the followin warning :

[WARN] HttpMethod - -Invalid cookie header: ""JTD=O%
2FdF13CDb1W7H2GNfUTS2YQ3Zt6bCW6ZKZRvVJ9FwaadQLxXVI7rgii%2FwbxeCsqym7dcWKDxSj%
2Bg1ubJRSVRhYGb7wRLjp5c0v2R3QrCIXVhMKDjuwuXDXnjbH3LHSWG7bfzJSmS7nXk9R%
2FqMIRHb5najLQkU7WkuPGgXUnUln%2BF51TajkVmXkrLMYN7MHDT48BEHvFQFNXBlmSRejWqrd%
2Fiiao0flObOrT3HcaWI09B1vekpAcPmgvMD2oZzXQWJwjDZIX6QoVVD6U8CXPSvVQjITyaxf6AqaS%
2BAFJgRsqbZBc0%2BV5G%2FnzE87ggOVIozfPFn99ny0kxiPGBEisJIy%3D%3D; Version=1; 
Path=; Max-Age=604800"". Missing value for path attribute

That's right, maybe the http header is not correct, but I think httpclient
should handle this case without error in order to have the same behaviour
as common browsers. We have no way to give a better value to this path."
"HTTPCLIENT-352","RFE","IMPROVEMENT","Allow polymorphic use of addParameter","I have some common code (in a reverse proxy server) that uses addParameter on 
instances of both PostMethod and MultipartPostMethod

It would be great if either addParameter were made an abstract method on 
ExpectContinueMethod or both were made to implement a common base class. Here's 
my workaround:

    private void addPostParameter(ExpectContinueMethod method, String name, 
String value) {
        if (method instanceof PostMethod) {
            ((PostMethod)method).addParameter(name, value);
        } else if (method instanceof MultipartPostMethod) {
            ((MultipartPostMethod)method).addParameter(name, value);
        } else {
            throw new IllegalArgumentException(""addPostParameter is only 
defined for PostMethod and MultipartPostMethod"");
        }
        
    }
    // whoa - smells pretty bad"
"HTTPCLIENT-4","IMPROVEMENT","BUG","Chunked transfer encoding not isolated from application.","Chunked transfer encoding is not being supported transparently by the
HttpMethodBase object, causing chunk data to be embedded in response body data
and forcing the application to handle the HTTP/1.1 implementation of chunked
transfer encoding.

The included patch now properly parses chunk data as per RFC 2068 and provides
body content consistently, regardless of whether chunked transfer encoding was
used by the server or not. This relieves the application from the requirement of
implementing RFC 2068.

Patch sent to mailing list as per guidelines to address this deficiency."
"HTTPCLIENT-206","IMPROVEMENT","IMPROVEMENT","URI class constructors need revision, optimization","1. Currently there's not way to pass an escaped string as a parameter to URI
class. As a result the url parameter in HttpMethodBase#HttpMethodBase(String)
constructor gets converted into an array of char just to be converted back to
string in URI contructor called in that method. 

2. The overall design of URI class contructors does not appear very coherent (at
least to me)"
"HTTPCLIENT-1179","IMPROVEMENT","","Upgrade commons-codec 1.4 -> 1.6","commons-codec 1.4 is buggy, see for example https://issues.apache.org/jira/browse/CODEC-99"
"HTTPCLIENT-176","BUG","BUG","Unusual Http status line","The web server at http://alces.med.umn.edu/Candida.html returns the following
status line:

HTTP 200 Document follows

This page loads in the 3 browsers I tried (though Safari actually rendered the
headers).  The current version of HttpClient reads through the whole page
looking for a line that starts with HTTP/.  I don't know how big of a problem
this is, but it's a fairly easy fix.  Patch to follow."
"HTTPCLIENT-1135","SPEC","BUG","RandomAccessFile mode ""w"" is not valid","According to the Java docs for RandomAccessFile, mode must be ""r"" ""rw"" ""rws"" or ""rwd"" - anything else results in an IllegalArgumentException. It seems that Sun/Oracle/OpenJDK's don't document it, but supports ""w"" mode that is equivalent to ""rw"" Android does as the Javadocs say, and throws an IllegalArgumentException when mode ""w"" is passed as HttpClientCache does IOUtils.copyFile() (line 70-71).

This means that HttpClient Cache does not work on Android."
"HTTPCLIENT-54","IMPROVEMENT","IMPROVEMENT","Handle Null Arguments consistantly","Consider throwing a NullPointerException or InvalidArgumentException for null
argument when they are not allowed.  Be consistant and document behaviour."
"HTTPCLIENT-1086","IMPROVEMENT","IMPROVEMENT","Use Iterable<? extends UrlEncodedFormEntity> instead of List<? extends UrlEncodedFormEntity> in URLEncodedUtils.format and UrlEncodedFormEntity","UrlEncodedFormEntity requires a List<? extends UrlEncodedFormEntity> to pass it to URLEncodedUtils.format. It would be nice to use Iterable<? extends UrlEncodedFormEntity> to be able to use other collections, e.g. a Set<? extends UrlEncodedFormEntity>"
"HTTPCLIENT-1063","RFE","IMPROVEMENT","ResponseContentEncoding should also handle x-gzip, compress and x-compress","ResponseContentEncoding should also handle x-gzip, compress and x-compress encodings according to specs (http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html, 3.5 Content Codings).

Also RequestAcceptEncoding should set Accept-Encoding to ""gzip,deflate,identity"". I am not sure about x-gzip, compress and x-compress here though.

Thanks"
"HTTPCLIENT-304","CLEANUP","BUG","Cleanup use of EncodingUtil and HttpConstants","HttpConstants has become somewhat irrelevant.  Deprecate HttpConstants and move any existing 
functionality to EncodingUtil."
"HTTPCLIENT-79","BUG","BUG","Preemtive Auth fails whithout credentials","The preemtive authorization causes a HttpException to be thrown in teh
Authenticator if no credentials were provided at all. This case should be
handled quietly. A test case should be added."
"HTTPCLIENT-385","RFE","IMPROVEMENT","Access to SO_TIMEOUT for open connections","I'm trying to access a set of pages in order, for which I have a maximum delay
permissible.  The complete operation includes following all redirects and
fetching the complete page content.  What I need, which doesn't seem to be
doable right now (according to the common-users list) is to reset the SO_TIMEOUT
property of the socket before each read to the inputstream.  I'd need an access
to the HttpConnection, or a way to set the parameters for that object.

This is a simplified version of what I'm doing:
-----
HttpURL url = new HttpURL(urlString);
method.setURI(url);
method.setFollowRedirects(false);
method.getParams().setSoTimeout(remainingTime);
HostConfiguration hostConfig = new HostConfiguration();
hostConfig.setHost(url);
method.setHostConfiguration(hostConfig);
timeoutChecker.getRemainingTime());

int statusCode = client.executeMethod(hostConfig, method, state);
String pageContent;

if (isRedirect(statusCode)) {
    if (timeoutChecker.isTimeout()) {
        throw new TimeoutException(""Total execution time for fetch exceeded
timeout parameter"");
    } else {
        Header locationHeader = method.getResponseHeader(""location"");
        HttpURL nextLocation = new HttpURL(locationHeader.getValue().toCharArray());
        pageContent = fetchGet(nextLocation.getEscapedURI(), addressHolder,
timeoutChecker, state);
    }
} else if (isSuccess(statusCode)) {
    // at least 4K buffers, might be as big as the webpage
    int responseSize = Math.max(getResponseSize(method), DEFAULT_RESPONSE_SIZE);
    InputStream response = method.getResponseBodyAsStream();
    ByteArrayOutputStream outstream = new ByteArrayOutputStream(responseSize);
    byte[] buffer = new byte[responseSize];
    int len;
    do {
        // ***TODO need to reset the SO_TIMEOUT to the remaining time
        len = response.read(buffer);
        outstream.write(buffer, 0, len);
    while ((len > 0) && !timeoutChecker.isTimeout());
    outstream.close();
    pageContent = EncodingUtil.getString(outstream.toByteArray(),
method.getResponseCharSet());
    response.close();
} else {
    ...
}"
"HTTPCLIENT-239","BUG","BUG","Redirect 302 to the same URL causes max redirects exception","I noticed that if the server returns a 302 without a URL in the link, the 
HttpClient follows the empty URL up to the maximum times (100 by default).  
Instead it should check and if the URL is an empty string it shouldn't try to 
follow the redirect.

12:18:17,430 [U:          ] [main                ] ERROR 
HttpMethodBase               - Narrowly avoided an infinite loop in execute
12:18:17,430 [U:          ] [main                ] DEBUG 
URLMonitor                   - Method.execute attempt 1 failed 
http://www.stagecoach.co.uk: 
org.apache.commons.httpclient.HttpRecoverableException: Maximum redirects (100) 
exceeded
12:18:17,430 [U:          ] [main                ] DEBUG 
URLMonitor                   - HttpRecoverableException 
(http://www.stagecoach.co.uk) : 
org.apache.commons.httpclient.HttpRecoverableException: Maximum redirects (100) 
exceeded
	at org.apache.commons.httpclient.HttpMethodBase.execute
(HttpMethodBase.java:1065)
	at com.verideon.veriguard.domain.URLMonitor.monitor(URLMonitor.java:189)
	at com.verideon.veriguard.domain.URLMonitor.monitor(URLMonitor.java:101)
	at com.verideon.veriguard.domain.TestURLMonitor.getPage
(TestURLMonitor.java:58)
	at com.verideon.veriguard.domain.TestURLMonitor.monitorURL
(TestURLMonitor.java:47)
	at com.verideon.veriguard.domain.TestURLMonitor.testMonitorURLStageCoach
(TestURLMonitor.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke
(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke
(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:324)
	at junit.framework.TestCase.runTest(TestCase.java:154)
	at junit.framework.TestCase.runBare(TestCase.java:127)
	at junit.framework.TestResult$1.protect(TestResult.java:106)
	at junit.framework.TestResult.runProtected(TestResult.java:124)
	at junit.framework.TestResult.run(TestResult.java:109)
	at junit.framework.TestCase.run(TestCase.java:118)
	at junit.framework.TestSuite.runTest(TestSuite.java:208)
	at junit.framework.TestSuite.run(TestSuite.java:203)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests
(RemoteTestRunner.java:392)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run
(RemoteTestRunner.java:276)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main
(RemoteTestRunner.java:167)

Result with telnet:

GET /
HTTP/1.1 302 Object moved
Server: Microsoft-IIS/5.0
Date: Tue, 01 Jul 2003 10:05:58 GMT
X-Powered-By: ASP.NET
Location: http://www.stagecoach.co.uk
Connection: Keep-Alive
Content-Length: 121
Content-Type: text/html
Set-Cookie: ASPSESSIONIDCQCSRAAB=IFJJLEADOPDDNNGHLPFBIIIE; path=/
Cache-control: private

<head><title>Object moved</title></head>
<body><h1>Object Moved</h1>This object may be found <a HREF="""">here</a>.</body>
Connection closed by foreign host."
"HTTPCLIENT-868","DOCUMENTATION","IMPROVEMENT","Add <a name=""""> anchors to documentation sections","In all docs, sections are missing <a name> anchors. I see that the xdocs stylesheet in the repository is supposed to generate them, yet the site is missing them at this moment.

See https://svn.apache.org/repos/asf/jakarta/site/xdocs/stylesheets/site.xsl 
template match=""section"""
"HTTPCLIENT-1152","BUG","BUG","org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage should verify class of returned object before casting","org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage

Original (in getEntry function): 
  byte[] data = (byte[]) client.get(url);

Should be:
  Object obj= client.get(url);
  if (null == obj || !(objinstanceof byte[])) {
    return null;
  }
  byte[] data = (byte[])obj;


Original (in updateEntry function):
  byte[] oldBytes = (v != null) ? (byte[]) v.getValue() : null;

Should be:
  byte[] oldBytes = (v != null && (v.getValue() instanceof byte[])) ? (byte[]) v.getValue() : null;



  
"
"HTTPCLIENT-437","BUG","BUG","method.getURI()  returns escaped URIs but it shouldn't","Hi guys,

Please, consider the following imaginary and simplified code:


URI u = new URI(""http://some.host.com/%41.html"", true);
HttpClient httpClient = new HttpClient();
GetMethod method = new GetMethod();
method.setURI(u);
URI u2 = method.getURI();

System.out.println(""1. "" + u);
System.out.println(""2. "" + new String(u.getRawURI()));
System.out.println(""3. "" + u.getURI());
System.out.println(""4. "" + u2);
System.out.println(""5. "" + new String(u2.getRawURI()));
System.out.println(""6. "" + u2.getURI());


The result that you'll get is:

1. http://some.host.com/%41.html
2. http://some.host.com/%41.html
3. http://some.host.com/A.html
4. http://some.host.com/%2541.html
5. http://some.host.com/%2541.html
6. http://some.host.com/%41.html


You can see that for lines 4, 5, and 6, the URI suddenly gets escaped (the 
percent sign gets converted to %25).

Why is that? Am I doing something wrong? Is this the desired behaviour? I would 
have expected to get the SAME URI back, without any escaping.

Besides, I have another question:

After executing a method -- httpClient.executeMethod(method) -- what will 
method.getURI() return? The URI *after* all redirections or the original URI? 
It seems I get the URI *after* the redirections, which is fine, but the 
documentation doesn't say that. It only explicitly says that the getPath() 
method has that behaviour.

Best regards and thanks,
Bisser"
"HTTPCLIENT-110","UNKNOWN","BUG","Port 80 is needed to run tests","I'm trying to upgrade to Cactus 1.4.1 and StrutsTest 1.9.  My tests where 
working about fine a month ago with nightly builds of both.  Now I get the 
following error:

    [junit] Testcase: testCreate took 0.2 sec
    [junit]     Caused an ERROR
    [junit] port out of range:-1
    [junit] java.lang.IllegalArgumentException: port out of range:-1
    [junit]     at java.net.InetSocketAddress.<init>
(InetSocketAddress.java:103)
    [junit]     at java.net.Socket.<init>(Socket.java:119)
    [junit]     at org.apache.commons.httpclient.HttpConnection.open
(HttpConnection.java:260)
    [junit]     at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:255)
    [junit]     at 
org.apache.cactus.client.HttpClientConnectionHelper.dispatch24_connect
(HttpClientConnectionHelper.jav
a;org/apache/cactus/util/log/LogAspect.aj(1k):164)
    [junit]     at 
org.apache.cactus.client.HttpClientConnectionHelper.around24_connect
(HttpClientConnectionHelper.java;
org/apache/cactus/util/log/LogAspect.aj(1k):1236)
    [junit]     at org.apache.cactus.client.HttpClientConnectionHelper.connect
(HttpClientConnectionHelper.java;org/apach
e/cactus/util/log/LogAspect.aj(1k):106)
    [junit]     at org.apache.cactus.client.AbstractHttpClient.callRunTest
(AbstractHttpClient.java;org/apache/cactus/uti
l/log/LogAspect.aj(1k):186)
    [junit]     at org.apache.cactus.client.AbstractHttpClient.dispatch2_doTest
(AbstractHttpClient.java;org/apache/cactu
s/util/log/LogAspect.aj(1k):109)
    [junit]     at org.apache.cactus.client.AbstractHttpClient.around2_doTest
(AbstractHttpClient.java;org/apache/cactus/
util/log/LogAspect.aj(1k):1236)
    [junit]     at org.apache.cactus.client.AbstractHttpClient.doTest
(AbstractHttpClient.java;org/apache/cactus/util/log
/LogAspect.aj(1k):104)
    [junit]     at org.apache.cactus.AbstractWebTestCase.runGenericTest
(AbstractWebTestCase.java:260)
    [junit]     at org.apache.cactus.ServletTestCase.runTest
(ServletTestCase.java:133)
    [junit]     at org.apache.cactus.AbstractTestCase.runBare
(AbstractTestCase.java:195)

I found that I had to add port 80 (:80) get it to work with the new stuff:

cactus.properties from: cactus.contextURL = http://localhost/myApp

To: cactus.contextURL = http://localhost:80/myApp

build.xml from:

    <target name=""tomcat.navigationAction"" depends=""deploy"" if=""tomcat.home"">
        <!-- We suppose our webapp is named ""onpoint"" -->
        <runservertests testURL=""http://localhost/${webapp.name}"" 
            startTarget=""start.tomcat"" 
            stopTarget=""stop.tomcat"" 
            testTarget=""test.navigationAction""/>
    </target>

To:

    <target name=""tomcat.navigationAction"" depends=""deploy"" if=""tomcat.home"">
        <!-- We suppose our webapp is named ""onpoint"" -->
        <runservertests testURL=""http://localhost:80/
${webapp.name}/ServletRedirector?Cactus_Service=RUN_TEST"" 
            startTarget=""start.tomcat"" 
            stopTarget=""stop.tomcat"" 
            testTarget=""test.navigationAction""/>
    </target>"
"HTTPCLIENT-522","BUG","BUG","ProxyCredentials disclosed to remote host","I'm using httpclient (svn-trunk of today) to connect to a remote SSL-Host 
via a proxy. The proxy requires authorization (basic) and I want to use 
preemptive authorization. 
 
Since HTTPCLIENT-514 is fixed the preemptive authorization works, but my traces 
show that the proxy credentials are also transmitted to the remote host 
through the CONNECT-tunnel, thus disclosing sensitive information to the 
remote host. 
 
My code looks like this: 
 
HttpClient client = new HttpClient(); 
HttpMethod method = new GetMethod(""https://test""); 
 
client.getHostConfiguration().setProxy(""127.0.0.1"",3128); 
client.getState().setProxyCredentials( 
                new AuthScope(""127.0.0.1"", 3128), 
                new UsernamePasswordCredentials(""proxy"", ""test"")); 
client.getState().setAuthenticationPreemptive(true); 
client.executeMethod(method); 
 
The trace: 
 
2005/11/03 13:53:13:244 CET [DEBUG] HttpMethodDirector - Preemptively 
sending default basic credentials 
2005/11/03 13:53:13:261 CET [DEBUG] HttpMethodDirector - Authenticating 
with BASIC <any realm>@127.0.0.1:3128 
2005/11/03 13:53:13:262 CET [DEBUG] HttpMethodParams - Credential charset 
not configured, using HTTP element charset 
2005/11/03 13:53:13:266 CET [DEBUG] HttpMethodDirector - Authenticating 
with BASIC <any realm>@test:443 
2005/11/03 13:53:13:267 CET [WARN] HttpMethodDirector - Required 
credentials not available for BASIC <any realm>@test:443 
2005/11/03 13:53:13:267 CET [WARN] HttpMethodDirector - Preemptive 
authentication requested but no default credentials available 
2005/11/03 13:53:13:268 CET [DEBUG] HttpConnection - Open connection to 
127.0.0.1:3128 
2005/11/03 13:53:13:279 CET [DEBUG] HttpMethodDirector - Preemptively 
sending default basic credentials 
2005/11/03 13:53:13:280 CET [DEBUG] HttpMethodDirector - Authenticating 
with BASIC <any realm>@127.0.0.1:3128 
2005/11/03 13:53:13:280 CET [DEBUG] HttpMethodParams - Credential charset 
not configured, using HTTP element charset 
2005/11/03 13:53:13:283 CET [DEBUG] header - >> ""CONNECT test:443 HTTP/1.1"" 
2005/11/03 13:53:13:284 CET [DEBUG] HttpMethodBase - Adding Host request 
header 
2005/11/03 13:53:13:284 CET [DEBUG] header - >> ""Proxy-Authorization: 
Basic cHJveHk6dGVzdA==[\r][\n]"" 
2005/11/03 13:53:13:285 CET [DEBUG] header - >> ""User-Agent: Jakarta 
Commons-HttpClient/3.0-rc4[\r][\n]"" 
2005/11/03 13:53:13:285 CET [DEBUG] header - >> ""Host: test[\r][\n]""       
                                                                           
2005/11/03 13:53:13:286 CET [DEBUG] header - >> ""Proxy-Connection: 
Keep-Alive[\r][\n]"" 
2005/11/03 13:53:13:286 CET [DEBUG] header - >> ""[\r][\n]""                 
                                                                         
2005/11/03 13:53:13:311 CET [DEBUG] header - << ""HTTP/1.0 200 
Connection established[\r][\n]""                                            
2005/11/03 13:53:13:326 CET [DEBUG] ConnectMethod - CONNECT status code 200 
2005/11/03 13:53:13:327 CET [DEBUG] HttpConnection - Secure tunnel to 
test:443 
2005/11/03 13:53:13:418 CET [DEBUG] header - >> ""GET / HTTP/1.1[\r][\n]"" 
2005/11/03 13:53:13:420 CET [DEBUG] HttpMethodBase - Adding Host request 
header 
2005/11/03 13:53:13:423 CET [DEBUG] header - >> ""Proxy-Authorization: 
Basic cHJveHk6dGVzdA==[\r][\n]"" 
2005/11/03 13:53:13:424 CET [DEBUG] header - >> ""User-Agent: Jakarta 
Commons-HttpClient/3.0-rc4[\r][\n]"" 
2005/11/03 13:53:13:425 CET [DEBUG] header - >> ""Host: test[\r][\n]"" 
2005/11/03 13:53:13:425 CET [DEBUG] header - >> ""[\r][\n]"" 
2005/11/03 13:53:14:391 CET [DEBUG] header - << ""HTTP/1.1 200 OK[\r][\n]"" 
 
As you can see the proxy credentials are also transmitted through the 
SSL-tunnel to the remote host which is a security risk."
"HTTPCLIENT-197","BUG","BUG","Problem with redirect on HEAD when (bad, naughty) server returns body content","I've been testing/using HttpClient 2.0a3 with Resin 2.1.9. I've found that when
using a HEAD request on a JSP, Resin returns the body content along with the
headers.

In this case, something in the HttpClient breaks. Looking at the httpclient
logs, it looks like:

1) HttpClient does a HEAD against the original URL
2) Resin returns valid status line and headers
3) HttpClient parses the headers and recognizes the redirect header
4) HttpClient does a HEAD against the new URL (from the Location header)
5) HttpMethodBase calls readStatusLine, which (eventually) calles readRawLine in
HttpConnection (which reads from the internal inputStream)
6) readRawLine returns the first line in the body from the original HEAD request
in (1).

It looks like the original body content (in response to the first HEAD) is being
buffered somewhere, but I can't figure out where.

I know that this is invalid behavior on the server's part, but I would like to
be able to recover from it.



---- redir_test.jsp ----
<?xml version=""1.0""?>
<% 
  response.setStatus(response.SC_MOVED_TEMPORARILY);
  response.setHeader(""Location"", ""redirect_pass.xml"");
%>
<some>
  <dummy>
    <data attr=""yea, well""/>
  </dummy>
</some>"
"HTTPCLIENT-316","OTHER","BUG","release is not signed","there are no signatures & checksums available for your latest release"
"HTTPCLIENT-237","IMPROVEMENT","BUG","wire logger skips empty line","When logging with 
org.apache.commons.logging.simplelog.log.httpclient.wire=debug, HttpConnection 
skips one line of server output in logs -- CRLF line between headers and body."
"HTTPCLIENT-281","BUG","BUG","DefaultHttpParamsFactory violates applet sandbox","The DefaultHttpParamsFactory in nightly build 20031009 makes two calls to 
System.getProperties().  This is by default verboten in an applet.  I have 
patched the source to catch the security exceptions and set the properties to a 
default value.  My modified code block follows:

        // TODO: To be removed. Provided for backward compatibility
        try {
          String agent = System.getProperties().getProperty
(""httpclient.useragent"");
          if (agent != null) {
            params.setParameter(HttpMethodParams.USER_AGENT, agent);
          }
        }
        catch (SecurityException dontCare) { }

        // TODO: To be removed. Provided for backward compatibility
        try {
          String preemptiveDefault = System.getProperties()
              .getProperty(""httpclient.authentication.preemptive"");
          if (preemptiveDefault != null) {
            preemptiveDefault = preemptiveDefault.trim().toLowerCase();
            if (preemptiveDefault.equals(""true"")) {
              params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, ""on"");
            }
            else if (preemptiveDefault.equals(""false"")) {
              params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, ""off"");
            }
          }
        }
        catch(SecurityException dontCare) { }"
"HTTPCLIENT-615","IMPROVEMENT","IMPROVEMENT","Consider making HostConfiguration immutable","HostConfiguration class should be immutable. This should also allow methods of this class to be non-synchronized.

Oleg"
"HTTPCLIENT-842","DOCUMENTATION","IMPROVEMENT","Link javadocs of HttpClient, HttpCore and HttpMime","Presently the javadocs for HttpCore, HttpClient and HttpMime are isolated from each other.  For new users this can create a great deal of confusion and the appearance of limited functionality of HttpClient.  Please set the javadoc creation task to link the javadoc of these three projects together.  "
"HTTPCLIENT-717","BUG","BUG","NPE in SimpleHttpConnectionManager.shutdown()","SimpleHttpConnectionManager.shutdown() causes NPE if no connection has been created, whereas MultiThreadedHttpConnectionManager.shutdown() does not.

Simple test case:

	MultiThreadedHttpConnectionManager cm = new MultiThreadedHttpConnectionManager();
	cm.shutdown(); // OK
		
	SimpleHttpConnectionManager sm = new SimpleHttpConnectionManager();
	sm.shutdown(); // NPE


I came across this in JMeter - a sample was using Post with AutoRedirect, which (correctly) caused an IllegalArgumentException, and so the connection was not created. 

The JMeter code could try to keep track of this, but it would be tedious, and it seems to me that SimpleHttpConnectionManager should ignore the shutdown() if the connection is null.

The problem does not arise when using closeIdleConnections(timeout) - unless one uses the special value:

      closeIdleConnections(System.currentTimeMillis() - Long.MAX_VALUE)

but it would probably be sensible to protect against this as well."
"HTTPCLIENT-50","RFE","IMPROVEMENT","User configurable cookie policy","Some user configurable how cookies are handled.  Emulate cookie options in web
browsers."
"HTTPCLIENT-1002","BUG","BUG","Stale connections are never detected when wireLog.isDebugEnabled() == true","When wireLog.isDebugEnabled() == true SessionInputBuffer is wrapped with LoggingSessionInputBuffer which doesn't implement EofSensor that AbstractHttpClientConnection.isStale() is relying on. This causes stale connections to be never detected and attempted to use."
"HTTPCLIENT-487","BUG","BUG","ParameterParser parse method for authentication headers does not appear to deal with empty value strings","Hi, I have found an issue with HTTPClient due to the way it parses parameter 
strings.

In particular, consider the following WWW-Authenticate header:

WWW-Authenticate: Digest realm="""", algorithm=MD5, qop=""auth"", 
domain=""/content"", nonce=""0e11dcf146563c3a89e5327f0c5f5bad""
 
The realm is definitely specified, but is equal to the empty string.  It is not 
a null value.

However, the extractParams method of AuthChallengeParser which in turn calls 
ParameterParser will actually parse the value as Null  instead of an empty 
string.

This is due to parseQuotedToken getToken(true) call which essentially returns a 
null String result  as the condition i2>i1 fails :-

        String result = null;
        if (i2 > i1) {
            result = new String(chars, i1, i2 - i1);
        }
        return result;

As the processChallenge method of DigestScheme throws an exception when 
getParameter(""realm"") == null, HTTPClient is not able to process the digest 
request when an empty string realm value is present."
"HTTPCLIENT-1003","IMPROVEMENT","IMPROVEMENT","Handle conditional requests in cache","Return 304 if incoming request has ""If-None-Match"" or ""If-Modified-Since"" headers and can be served from cache.  Currently we return a 200 which is correct but not optimal."
"HTTPCLIENT-791","DOCUMENTATION","BUG","Default retry count three even if documentation says it's five","The exception handling documentation (http://hc.apache.org/httpclient-3.x/exception-handling.html) says ""HttpClient will automatically retry up to 5 times those methods..."", but in DefaultHttpMethodRetryHandler  e.g. in trunk (http://svn.apache.org/viewvc/httpcomponents/oac.hc3x/trunk/src/java/org/apache/commons/httpclient/DefaultHttpMethodRetryHandler.java?revision=608014&view=markup) you can see that the retry count is three:

    public DefaultHttpMethodRetryHandler(int retryCount, boolean requestSentRetryEnabled) {
        super();
        this.retryCount = retryCount;
        this.requestSentRetryEnabled = requestSentRetryEnabled;
    }
    
    /**
     * Creates a new DefaultHttpMethodRetryHandler that retries up to 3 times
     * but does not retry methods that have successfully sent their requests.
     */
    public DefaultHttpMethodRetryHandler() {
        this(3, false);
    }"
"HTTPCLIENT-278","RFE","IMPROVEMENT","Add the ability to disable the content-type and transfer encoding headers for Parts"," "
"HTTPCLIENT-106","RFE","BUG","Path should not be encoded in HttpMethodBase","I suggest to change the protocol or add a new method for this one

protected static String generateRequestLine(HttpConnection connection,
	String name, String reqPath,
	String qString, String protocol);
so that we can choose to use URIUtil.encode(reqPath, URIUtil.pathSafe()) or not

The reason is that after the encoding process, some server cannot recognize this
Actually, I am handling a project of the Method Propfind(for getting mail from 
Hotmail) and I find that the restriction of Hotmail server is quite high, and 
if the address is encoded, it does not work."
"HTTPCLIENT-699","IMPROVEMENT","IMPROVEMENT","Performance tuning",""
"HTTPCLIENT-221","BUG","BUG","error handling duplicate connection headers","HttpMethodBase.shouldCloseConnection() does not correctly handle the case when
more than one connection header exists.  Reported by Ross Rankin."
"HTTPCLIENT-567","BUG","BUG","EasyX509TrustManager no longer checks cert expiry","EasyX509TrustManager was made even ""easier"" by the last commit:  a socket will
now be created when talking to a server with an expired certificate.

2 commits ago it looked like this (notice ""return false"" on line 107):

102             try {
103                 certificate.checkValidity();
104             }
105             catch (CertificateException e) {
106                 LOG.error(e.toString());
107                 return false;
108             }


Now it looks like this:

102             try {
103                 certificate.checkValidity();
104             }
105             catch (CertificateException e) {
106                 LOG.error(e.toString());
107             }


I'm proposing we just do:

102             certificate.checkValidity();

Now that we're using Java 1.4 in the contrib code, we'll just let the
CertificateException fly up the stack."
"HTTPCLIENT-122","BUG","BUG","HttpMultiClient reuses closed connections","If a socket times out while sitting in the connection pool, 
HttpConnectionManager still attempts to reuse it resulting in an IOException 
being thrown when writing to the socket.  I believe this is a problem with both 
server side and client side timeouts (ie: we try to reuse a connection that we 
timed out) though am not certain of that.  At the very least server side 
timeouts cause the issue.

As yet I can't see how to fix this.  With the current code there doesn't even 
appear to be a suitable workaround because when the exception is thrown, the 
connection is added back into the pool to be reused (even though it is closed) 
which causes the next attempt to fail as well.

I can't see any reliable way to tell whether or not a connection is open, so 
would suggest the following as a fix:

1. In HttpMultiClient.executeMethod, close the connection if an exception is 
thrown (optionally, only if an IOException is thrown instead of an 
HttpException, but generally exceptions tend to leave things in an unknown 
state).

2. (optional) Add a retry loop to executeMethod to retry if an exception occurs 
(possibly only if an IOException is thrown, depending on exactly when a 
HttpException is thrown).

I'll attach a patch which does both of this to help clarify."
"HTTPCLIENT-909","IMPROVEMENT","IMPROVEMENT","Upgrade all default socket factories to use SO_REUSEADDR parameter","See HTTPCORE-209"
"HTTPCLIENT-975","RFE","RFE","add support to caching module for RFC 5861 (stale-on-error and stale-while-revalidate)","These are Cache-Control extensions that allow an origin server to specify some additional behavior for stale cache entries. Stale-on-error configurations allow a cache to continue serving stale content for a certain period of time if a revalidation fails, and stale-while-revalidate similarly allows revalidation to occur asynchronously. Some reverse proxies such as Squid can be configured to understand these headers, which means that some origin servers are probably sending them, and that we can likewise take advantage of them.
"
"HTTPCLIENT-208","BUG","BUG","Netscape proxy problem wtih POST","Description:

When using httpClient to POST to a http url through a Netscape proxy server, 
the httpClient failed due to read error when reading status line.  The log seem 
to indicate that the proxy is talking HTTP/1.0 and does not expect the POST 
data to come.  I am using a modified version of the ClientApp from examples.  I 
will attach both the test program and log files.

Workaround:

If use PostMethod.setUseExpect (true), it will work.  But in many cases, it 
would be slower.

Related issues:

In doing the test, I also found out that the httpClient PostMehtod does not 
work when the request body is NOT set (not calling setRequestBody).  It also 
does not work with empty body (setRequestBody ("""")).  The attached 
clientApp.properties file has flags to test each case and I will attach the 
logs as well.  Excuse my ignorance, I do not know for sure what the HTTP spec. 
says about the body in the POST method.  But at least if the caller/app is 
wrong in not setting the body, some exception should be thrown.  It could also 
be my server's problem, please let me know if that is the case (I am using 
weblogic server 6.1)."
"HTTPCLIENT-95","RFE","BUG","Proxy authentication does not handle multiple multiple authentication schemes","My proxy server returns the following header lines in the response:

    Proxy-Authenticate: NTLM
    Proxy-Authenticate: Basic realm=""10.105.20.201""

i.e., it returns two Proxy-Authenticate header lines. Unfortunately this does 
not work. In line 253 of class Authenticator (method: authenticate(HttpMethod, 
HttpState, Header, String)) I see this comment:

    // FIXME: Note that this won't work if there is more than one realm within 
the challenge

so it looks like this is something that isn't yet implemented. In the log, I 
can see that the Authenticator attempts to parse the realm, but it looks like
this is not being done correctly:

   411 DEBUG Attempting to authenticate challenge: Proxy-Authenticate: NTLM, 
Basic realm=""10.105.20.201""

   411 DEBUG Parsed realm ""ealm=""10.105.20.201"" from challenge ""NTLM, Basic 
realm=""10.105.20.201"""".
   421 WARN  Exception thrown authenticating
java.lang.UnsupportedOperationException: Authentication type ""NTLM,"" is not 
recognized.
    at org.apache.commons.httpclient.Authenticator.authenticate
(Authenticator.java:274)
    at org.apache.commons.httpclient.Authenticator.authenticateProxy
(Authenticator.java:178)
    at 
org.apache.commons.httpclient.HttpMethodBase.processAuthenticationResponse
(HttpMethodBase.java:580)
    at org.apache.commons.httpclient.HttpMethodBase.execute
(HttpMethodBase.java:668)
    at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:355)
    at com.cmg.httptest.Main.main(Main.java:34)

It looks wrong to me that the realm name seems to be parsed as: 
ealm=""10.105.20.201

I understand that Authenticator does not know what NTLM is but I would like it 
to use Basic authentication in this case.

If there are more authentication methods possible, how can I specify which one 
I want to use?

Jesper de Jong"
"HTTPCLIENT-18","RFE","BUG","Can't use proxy server with https","There doesn't seem to be a way to configure HttpClient to use both HTTPS and a
proxy server at the same time.  It's not clear if this was just an oversight or
if there was a deliberate decision to not support this combination for some reason.

Assuming that it was an oversight, the fix seems to just require one more
variation of startSession() in HttpClient.java which would be the following:

   public void startSession(String host, int port,
                            String proxyhost, int proxyport, boolean https) {
       connection = new HttpConnection(proxyhost,proxyport,host,port,https);
   }"
"HTTPCLIENT-195","BUG","BUG","NTLM authentication failed due to closing of connection","Description:

When dealing with a NTLM proxy server that sends response back with lines:

14:51:27:750 << HTTP/1.0 407 Proxy Authentication Required
14:51:27:796 << Date: Mon, 14 Apr 2003 19:52:43GMT[\r][\n]
14:51:27:796 << Content-Length: 257[\r][\n]
14:51:27:796 << Content-Type: text/html[\r][\n]
14:51:27:796 << Server: NetCache appliance (NetApp/5.3.1R1)[\r][\n]
14:51:27:796 << Connection: keep-alive[\r][\n]
14:51:27:796 << Proxy-Authenticate: NTLM 
TlRMTVNTUAACAAAABgAGACgAAAAGggEAtOoNy4M0g0EAAAAAAAAAAEdMT0JBTA==[\r][\n]

The httpClient code is using the ""HTTP/1.0"" as clue for closing the connection 
and ignored the ""Connection: keep-alive"".  That caused the NTLM authentication 
to fail as the NTLM requires the response to the challenge to be sent back on 
the same connection.

Proposed Fix:

Our fix is to add a flag inProxyAuthenticationRetry (in HttpMethodBase) to 
indicate that the method is doing proxy authentication retry.  When the flag is 
true, in ""HttpMethodBase.shouldCloseConnection"", check the ""Connection: keep-
alive"" before determining to close the connection."
"HTTPCLIENT-542","BUG","BUG","Explicit VirtualHosts Can Cause Issues On Redirects","If you set an explicit virtual host then a getmethod may get stuck in a redirect
loop (up to maxRedirects).

e.g. execute a get on www.google.com (with a www.google.com virtualhost).  That
redirects to www.google.co.nz (at least if you come from an NZ IP).  The current
httpclient behavior is to then connect to www.google.co.nz but pass through,
with the request, ""Host: www.google.com"".  Google will then reply with another
www.google.co.nz redirect and the loop continues.

There are probably a few ways to work around this.  It seems reasonable to drop
an explicity set virtual host in the event a redirect redirects to a different
uri authority.  The following patch works for me:


diff -Naur
../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpMethodDirector.java
src/java/org/apache/commons/httpclient/HttpMethodDirector.java
---
../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpMethodDirector.java
2005-12-22 01:06:55.000000000 +1300
+++ src/java/org/apache/commons/httpclient/HttpMethodDirector.java	2005-12-22
19:09:51.000000000 +1300
@@ -605,6 +605,27 @@
 					redirectUri = new URI(currentUri, redirectUri);
 				}
 			}
+            do {
+                // scenario we're trying to avoid:
+                // virtual host is set (e.g. google.com); a request to that
server responds
+                // with a redirect to google.co.nz; we issue a request to
google.co.nz with 
+                // a virtual host request of google.com
+                // 
+                // This code will remove any set virtual host if the redirect
is to a different 
+                // domain
+
+                if(redirectUri.isRelativeURI()) {
+                    break;
+                }
+
+                String vhost = hostConfiguration.getParams().getVirtualHost();
+                if(vhost==null)
+                    break;
+                if(redirectUri.getAuthority()!=currentUri.getAuthority()) {
+                    hostConfiguration.getParams().setVirtualHost(null);
+                }
+            } while(false);
+"
"HTTPCLIENT-1076","RFE","RFE","[GSoC 2011] Fluent API to HttpClient","Develop fluent API / facade to HttpClient based on code currently maintained by Apache Stanbol and Apache Sling projects. 

For details see 

http://markmail.org/message/mmyljtgjp3za6kyz

or contact Apache HttpComponents committers at dev@hc.apache.org"
"HTTPCLIENT-1011","BUG","IMPROVEMENT","CachingHttpClient.execute() does not catch the IOException thrown by HttpCache.getCacheEntry()","The IOException caused by the HttpCache is not caught and thus the whole http request fails. I would expect the response to be retrieved from the backend when the cache fails for some reason."
"HTTPCLIENT-410","DOCUMENTATION","BUG","Typos in MultiThreadedHttpConnectionManager","I've done a review of the MultiThreadedHttpConnectionManager class in 3.0-beta1,
especially focussing on the documentation. In general, it could use a lot of
improvement, IMHO.

This bug report only deals with some typos I found in the class, and some
minimal style improvements that are compatible with the other classes.

I will attach a proposed patch."
"HTTPCLIENT-1037","IMPROVEMENT","BUG","FormBodyPart code does not agree with ContentDescriptor Javadoc wrt nullability of mimeType and transferEncoding","The FormBodyPart does not agree with ContentDescriptor Javadoc wrt nullability of mimeType and transferEncoding:

The code in FormBodyPart explicitly allows mimeType and transferEncoding to be null, in which case the relevant header is not generated.
This is useful behaviour, as the headers are not necessaruly needed.

However the bahaviour disagrees with the Javadoc in the ContentDescriptor interface - null is not allowed.
Also, AbstractContentBody does not allow mime-type to be null."
"HTTPCLIENT-113","BUG","BUG","NullPointerException in HttpMethodBase.getResponseBodyAsString","The following code in a cocoon component, causes the NPE.
A delay seems to help sometimes.

-------------
      int htcode = httpClient.executeMethod( method );
       
      // @todo: fix-me
      // This sleep() is a temporary workaround 
      // to avoid NullPointerException in the next line.
      Thread.currentThread().sleep( 100 ); 

      String ret = method.getResponseBodyAsString();
---------------------

java.lang.NullPointerException 
at java.lang.String.<init>(String.java:399) 
at org.apache.commons.httpclient.HttpMethodBase.getResponseBodyAsString
(HttpMethodBase.java:579) 
at org.apache.cocoon.generation.WebServiceProxyGenerator.fetch
(WebServiceProxyGenerator.java:264)"
"HTTPCLIENT-236","BUG","BUG","URI.normalize() error","code:

----------------------------
import org.apache.commons.httpclient.URI;

class Main {
  publi static void main(String[] args) throws Exception {
    URI uri = new URI(""http"", null, ""host"", -1, ""/tmp/../yo"", null, null);
    uri.normalize();
    System.out.println(uri);
  }
} /// end of Main
----------------------------

prints:

http://host/tmp/../yo

instead of

http://host/yo"
"HTTPCLIENT-807","RFE","RFE","ContentBody doesn't currently have a setMimeType method.","ContentBody and therefore FileBody, StringBody and InputStreamBody do not have a setMimeType method so you can't set the Mime Type, it always defaults. 
Current workaround is to subclass and override getMimeType."
"HTTPCLIENT-43","IMPROVEMENT","IMPROVEMENT","replace the PostMethod parameters HashMap with a List","Propose to change the parameters datastructure in PostMethod from its
current HashMap to an ArrayList (or Vector) of NameValuePair objects. 
This change would lead to simpler and more robust code in the PostMethod
with more deterministic behaviour for the following reasons:

1) HashMap looses any insertion order.  If the client wants to have the
encoded parameters to show up in a particular order, they are unable.

2) Hash map requres unique keys where there is no reason that multiple
parameters with the same name cannot be POSTed.  The current
implementation replaces the string value with a List if there is a
addParameter with a repeated name key.  Every get from the HashMap then
has to do an instanceOf to see if the value is a String or a List.

3) Hash maps are no faster than a Vector for typical operations.  They
both have O(1) insertions and both do O(n) removal operations to
genPropose to change the parameters datastructure in PostMethod from its
current HashMap to an ArrayList (or Vector) of NameValuePair objects. 
This change would lead to simpler and more robust code in the PostMethod
with more deterministic behaviour for the following reasons:

1) HashMap looses any insertion order.  If the client wants to have the
encoded parameters to show up in a particular order, they are unable.

2) Hash map requres unique keys where there is no reason that multiple
parameters with the same name cannot be POSTed.  The current
implementation replaces the string value with a List if there is a
addParameter with a repeated name key.  Every get from the HashMap then
has to do an instanceOf to see if the value is a String or a List.

3) Hash maps are no faster than a Vector for typical operations.  They
both have O(1) insertions and both do O(n) removal operations to
generate the body.  HashMap is only faster when a search is required,
such as for getParameter(String), setParameter(String, String) and
removeParameter(String) which should rarely be called.

I would also move to depricate setParameter(String, String) as it is
confusing in the API.  (setParameter overwrites any existing parameter
of the same name where addParameter accumulates to the list of
parameters).  The setParameter functionality can also be effected by
calling removeParameter then addParameter already.

erate the body.  HashMap is only faster when a search is required,
such as for getParameter(String), setParameter(String, String) and
removeParameter(String) which should rarely be called.

I would also move to depricate setParameter(String, String) as it is
confusing in the API.  (setParameter overwrites any existing parameter
of the same name where addParameter accumulates to the list of
parameters).  The setParameter functionality can also be effected by
calling removeParameter then addParameter already."
"HTTPCLIENT-1051","BUG","BUG","SSL connections cannot be established using resolvable IP address","HttpClient 4.1 introduced a regression in establishing SSL connections to remote peers (it seems this is a common regression for major httpclient updates, see HTTPCLIENT-803).
The new SSLSocketFactory.connectSocket method calls the X509HostnameVerifier with InetSocketAddress.getHostName() parameter. When the selected IP address has a reverse lookup name, the verifier is called with the resolved name, and so the IP check fails.
4.0 release checked for original ip/hostname, but this cannot be done with the new connectSocket() method. 
The TestHostnameVerifier.java only checks 127.0.0.1/.2 and so masked the issue, because the matching certificate has both ""localhost"" and ""127.0.0.1"", but actually only ""localhost"" is matched. A test case with 8.8.8.8 would be better."
"HTTPCLIENT-591","REFACTORING","","Apply the supplied patch. Sets 2 variable in the base class to protected","The patch attached to the main task contains minimal changes to allow the HttpMethodBase class to be overloaded by base class."
"HTTPCLIENT-570","BUG","BUG","Failed CONNECT leaves connection in an inconsistent state","Opening a HTTPS Connection over an authenticating Proxy (Basic auth. scheme) 
fails, if proxy credentials are not provided at the first try. 

The following example code will fail:

HttpClient client = new HttpClient(new MultiThreadedHttpConnectionManager());
URL url = new URL(""https://examplehttpsurl"");
  
//first try 
GetMethod get = new GetMethod(url.toExternalForm());
HostConfiguration hc = new HostConfiguration();
hc.setHost(url.getHost(), 443, ""https"");
hc.setProxy(""proxyhost"", 4711);

try {
  client.executeMethod(hc, get);
} catch (Exception e){
  LOG.error("""",e);
} finally {
  get.releaseConnection();
}

//returns 407 (expected)
LOG.debug(""Answer: "" + get.getStatusLine().toString()); 

//retry with credentials (normally requested from the user)
client.getState().setProxyCredentials(new AuthScope(""proxyhost"",4711),
      new NTCredentials(""USER"", ""PASS"", """", """"));

get = new GetMethod(url.toExternalForm());

try {
  client.executeMethod(hc, get);
} catch (Exception e) {
  e.printStackTrace();
} finally {
  get.releaseConnection();
}
//should be 200 but is 407
LOG.debug(""Answer: "" + get.getStatusLine().toString());



----------


From what I see from HttpMethodDirector.executeWithRetry(final
HttpMethod method), the cause is, that the connection is kept open, and
thus the connect is never retried:


if (!this.conn.isOpen()) {
  // this connection must be opened before it can be used
  // This has nothing to do with opening a secure tunnel
  this.conn.open();
  if (this.conn.isProxied() && this.conn.isSecure() 
      && !(method instanceof ConnectMethod)) {
    // we need to create a secure tunnel before we can execute the real method
    if (!executeConnect()) {
      // abort, the connect method failed
      return;
    }
  }
}


If I add a conn.close() before returning on !executeConnect(), the
above code will work, the CONNECT is reattempted."
"HTTPCLIENT-723","RFE","RFE","HttpRoutePlanner based on ProxySelector","Since we now require Java 5, we should have a route planner that uses the standard Java ProxySelector. That would allow us to automatically pick up proxy settings from system properties or the browser running an applet.
"
"HTTPCLIENT-1078","BUG","BUG","DecompressingEntity not calling close on InputStream retrieved by getContent","The method DecompressingEntity.writeTo(OutputStream outstream) does not close the InputStream retrieved by getContent().
According to the documentation of HttpEntity.writeTo:
IMPORTANT: Please note all entity implementations must ensure that
all allocated resources are properly deallocated when this method
returns.

-> imho this is not satisfied in DecompressingEntity.writeTo "
"HTTPCLIENT-1013","DOCUMENTATION","BUG","website: 404 for several documentation pages","There are several 404 Not Found pages linked from hc.apache.org.
Please fix them as it's important documentation for HttpClient.

Specifically:

linked from http://hc.apache.org/user-docs.html

not found:
http://hc.apache.org/httpcomponents-client/primer.html
http://hc.apache.org/httpcomponents-client-4.0.1/httpclient/apidocs/index.html
http://hc.apache.org/httpcomponents-client-4.0.1/httpmime/apidocs/index.html"
"HTTPCLIENT-130","IMPROVEMENT","BUG","HttpMethodBase does not compile on JDK prior to 1.3","reason is the use of URL.getPath() and URL.getQuery() within method
processRedirectResponse.

should use URIUtil.getPath and URIUtil.getQuery instead.

so, HttpMethodBase around line 952:

//update the current location with the redirect location
setPath(URIUtil.getPath(redirectUrl.toString()));
setQueryString(URIUtil.getQuery(redirectUrl.toString()));

thanks,

marius"
"HTTPCLIENT-718","BUG","BUG","SSL verification occurs before setSoTimeout, which can lead to hangs","partial thread dump:

       at java.net.SocketInputStream.socketRead0(Native Method)
       at java.net.SocketInputStream.read(SocketInputStream.java:129)
       at com.sun.net.ssl.internal.ssl.InputRecord.readFully(InputRecord.java:293)
       at com.sun.net.ssl.internal.ssl.InputRecord.read(InputRecord.java:331)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:723)
       - locked <0x00002aaab87d9de0> (a java.lang.Object)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1030)
       - locked <0x00002aaab87d9dc0> (a java.lang.Object)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1057)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.getSession(SSLSocketImpl.java:1757)
       at org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:87)
       at org.apache.http.conn.ssl.SSLSocketFactory.connectSocket(SSLSocketFactory.java:295)
       at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:131)
       at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:143)
       at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:120)
       at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:286)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:452)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:406)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:365)


... this is because in DefaultClientConnectionOperator, prepareSocket (which sets any configured timeouts) isn't called until after SocketFactory.connectSocket. When using SSLSocketFactory, the default behavior is to verify the hostname, which opens a connection, and can block indefinitely.

Simple workaround is to use the AllowAllHostnameVerifier which doesn't do any verification."
"HTTPCLIENT-784","BUG","BUG","Multipart post is broken","I tried to do HttpPost request with MultipartEntity, this request was encoded to wire with 3 line separators after header and not processed correctly by http server.
MultipartEntry add 1 extra line separator before write itself to wire. I'm not sure about standards, but it is at least not ""browser compatible"".

"
"HTTPCLIENT-644","BUG","BUG","Bad request vulnerability ","The HttpParser.readRawLine() method below has no guard code against a post without a end-of-line.  A large post of data without ""\n"" will be read into the ByteArray.  If this post is large enough, it will deplete the system of free memory.  A DOS attack could easily be played out by submitting several of these post at once.   readRawLine should decide that its not reading character data (basically because character data should never show up over something like a megabyte a line) and report an error.  

   /**
     * Return byte array from an (unchunked) input stream.
     * Stop reading when <tt>""\n""</tt> terminator encountered 
     * If the stream ends before the line terminator is found,
     * the last part of the string will still be returned. 
     * If no input data available, <code>null</code> is returned.
     *
     * @param inputStream the stream to read from
     *
     * @throws IOException if an I/O problem occurs
     * @return a byte array from the stream
     */
    public static byte[] readRawLine(InputStream inputStream) throws IOException {
        LOG.trace(""enter HttpParser.readRawLine()"");

        ByteArrayOutputStream buf = new ByteArrayOutputStream();
        int ch;
        while ((ch = inputStream.read()) >= 0) {
            buf.write(ch);
            if (ch == '\n') { // be tolerant (RFC-2616 Section 19.3)
                break;
            }
        }
        if (buf.size() == 0) {
            return null;
        }
        return buf.toByteArray();
    }"
"HTTPCLIENT-640","IMPROVEMENT","IMPROVEMENT","contrib.ssl.HostConfigurationWithHostFactory","I'd like to contribute an example specialized HostConfiguration, to replace the one I contributed in HTTPCLIENT-634."
"HTTPCLIENT-1128","RFE","IMPROVEMENT","Provide factory method to create DefaultHttpClient instances pre-configured based on JSSE and networking system properties","Provide factory method or a factory class intended to create DefaultHttpClient instances pre-configured based on JSSE [1] and networking [2] system properties.

[1] http://download.oracle.com/javase/1,5.0/docs/guide/security/jsse/JSSERefGuide.html
[2] http://download.oracle.com/javase/1.5.0/docs/guide/net/properties.html"
"HTTPCLIENT-123","IMPROVEMENT","IMPROVEMENT","MultipartPostMethod does not check for error messages","If a MultipartPost request is sent to a server which requires authentication, 
the server may respond to the request with an unauthorized header and close the 
connection before all of the data is sent.  HttpClient should monitor the 
incoming stream and cease transmitting the body if an error message is received 
(section 8.2.2 of rfc2616, see below).

At the very least HttpClient should check for a response when catching the 
HttpRecoverableException and retrying.  This probably should be done in 
HttpMethodBase so that we are in a known state when starting to retry the 
connection (ie: there isn't an existing response in the socket buffer to cause 
problems).

Ideally, HttpClient should also implement the 100 (Continue) status as 
specified in section 8.2.3 of rfc2616.

Finally, PostMethod should be tested to ensure that it does not exhibit this 
bug as well.

-------------
8.2.2 Monitoring Connections for Error Status Messages

   An HTTP/1.1 (or later) client sending a message-body SHOULD monitor
   the network connection for an error status while it is transmitting
   the request. If the client sees an error status, it SHOULD
   immediately cease transmitting the body. If the body is being sent
   using a ""chunked"" encoding (section 3.6), a zero length chunk and
   empty trailer MAY be used to prematurely mark the end of the message.
   If the body was preceded by a Content-Length header, the client MUST
   close the connection."
"HTTPCLIENT-149","BUG","BUG","303 Redirects are not handled properly","When the server spits back a 303 (See Other), the redirect is not handled. 
Looking at the code, I saw that the processRedirectResponse method in
HttpMethodBase does not check for SC_SEE_OTHER in the case statement. 
SC_SEE_OTHER is a redirect and should be handled appropriately.

Here is a trace from the output of the client and server.

GET http://172.30.229.75/CGI/Screenshot HTTP/1.1 
Authorization: Basic c3VwZXJ1c2VyOnJvb3Q= 
Host: 172.30.229.75 
User-Agent: Jakarta Commons-HttpClient/2.0M1 

HTTP/1.1 303 See Other 
Location: http://172.30.229.75/FS/CIP_0_5842
Content-Length: 0 
Server: *snip*"
"HTTPCLIENT-979","IMPROVEMENT","IMPROVEMENT","cache entry resource management should be extracted from CachingHttpClient","As we have built in support for stream-based management of cached response bodies, the CachingHttpClient class has its fingers in too many pies and is involved in resource management but not storage of the actual HttpCacheEntries.

I have a patch forthcoming. :)
"
"HTTPCLIENT-1072","BUILD_SYSTEM","IMPROVEMENT","Inline nested jars in OSGi bundles","Eclipse doesn't support bundles with nested jars (https://bugs.eclipse.org/bugs/show_bug.cgi?id=111238). The workaround is to inline the contents of the nested jars. This is a simple fix that shouldn't impact non-Eclipse users:

pom.xml
===================================================================
- <Embed-Dependency>*;scope=compile|runtime;inline=false</Embed-Dependency>
+ <Embed-Dependency>*;scope=compile|runtime;inline=true</Embed-Dependency>
"
"HTTPCLIENT-649","RFE","RFE","Support multiple proxies","HttpClient supports one proxy currently.
Our requirement is to suppport more than one proxy. We may need to connect more than one proxies before connects to target resource. 
I found that HttpMethodDirector creates tunnelled socket and there is no easy way to plugin our custom HttpMethodDirector class with HttpClient other than extending HttpClient to override ""public int executeMethod(HostConfiguration hostconfig, final HttpMethod method, final HttpState state"" method.


"
"HTTPCLIENT-747","BUG","BUG","No entry created for this pool.","Followup to https://issues.apache.org/jira/browse/HTTPCLIENT-741, as reported by Sam Berlin:

java.lang.IllegalStateException: No entry created for this pool. HttpRoute[{}->http://74.160.66.42:14561]
    at org.apache.http.impl.conn.tsccm.RouteSpecificPool.freeEntry(RouteSpecificPool.java:137)
    at org.apache.http.impl.conn.tsccm.ConnPoolByRoute.freeEntry(ConnPoolByRoute.java:337)
    at org.apache.http.impl.conn.tsccm.ThreadSafeClientConnManager.releaseConnection(ThreadSafeClientConnManager.java:230)
    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:427)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:500)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:455)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:421)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)
    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:139)
    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)
    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)
    at java.lang.Thread.run(Thread.java:613)
---

DefaultHttpExecutor$MultiRequestor basically is just a Runnable / Cancellable [exposes a cancel() method] that can be cancelled from any thread. cancel just calls abort() on the current AbortableHttpRequest, but is called on a thread other than the one that's doing the client.execute(request).

The last one is the most common exception, and seems to happen with some regularity. The other two we've only seen once, so may just be a memory quirk (we've seen some crazy bugs, including recursive NPEs while constructing an NPE.)
"
"HTTPCLIENT-634","BUG","IMPROVEMENT","HostConfiguration socketFactory is ignored","HostConfiguration doesn't use its host.protocol to execute an HttpMethod with an absolute URL.  It should, if the Protocol's scheme is the same as the method's URL scheme.

This bug makes it difficult to integrate a specialized SSL connection algorithm (in a SecureProtocolSocketFactory) with a module implemented on top of HttpClient.  The latter module must not execute methods with absolute URLs.  Of course, this is difficult when one doesn't control that module.  For example, I recently tried to integrate SSL certificate-based client authentication with XFire.  XFire provides a reasonable API for replacing its HttpClient, but one must hack its source code to prevent it from executing methods with absolute URLs.

Protocol.registerProtocol is a possible answer, but it can't support two or more SSL connection algorithms for one HTTPS host and port."
"HTTPCLIENT-668","TASK","IMPROVEMENT","make sure no static loggers are used","Review all loggers used in the component, make sure they are stored in non-static attributes only.
http://wiki.apache.org/jakarta-commons/Logging/StaticLog
"
"HTTPCLIENT-948","BUG","BUG","IdleConnectionHandler can leave closed connections in a inconsistent state","IdleConnectionHandler when shutting down 'stale' connection does not update the state of AbstractPoolEntry thus causing an inconsistency between the state of the connection (closed) and that of the pool entry (still assumed open). The problem is mitigated by the fact that the pooling manager usually evicts closed connections almost immediately. There is a small window of time in the ThreadSafeClientConnManager#closeIdleConnection method, at which a connection can be closed by the IdleConnectionHandler and immediately leased from the pool by another thread in an inconsistent state before the main thread gets a chance to re-acquire the pool lock and clean out closed connections.

For 4.0.x the problem can be worked around by retaining the pool lock for the entire span of the #closeIdleConnection. For the 4.1 branch a better solution should be devised. This probably means a complete rewrite or deprecation of IdleConnectionHandler."
"HTTPCLIENT-786","TASK","IMPROVEMENT","variables should be accessed through getters","Some attention should be placed on classes who shared their variables directly (as opposed to through a getter). This is sometimes OK for subclasses, but rarely good for other classes that use the objects. There's a small number of classes that have non-private variables, especially in the impl.conn & impl.conn.tsccm packages.

See HTTPCLIENT-745 ."
"HTTPCLIENT-610","RFE","","HttpMethodBase.getResponseBodyAsString(long limit)","Currently HttpMethodBase.getResponseBodyAsString() prints warning in log, and suggests using getResponseStream(). However getResponseBodyAsString() is extremely useful (as it is easy to use). So my wish is to have method

getResponseBodyAsString(long limit)

that should throw HttpException if response size exceeds specified limit.

Same things with getResponseBody(long limit) .

Original methods should be deprecated because of danger, explained in javadoc."
"HTTPCLIENT-341","BUG","BUG","HttpUrl does not accept unescaped passwords","- Taken from an email from Gustav Munkby posted to the HttpClient dev mailing list -

If I do:

HTTPUrl url = new HTTPUrl(""kurt"", ""nicepass#"", hostname, 80, path);

throws a URIException with message ""port number invalid"".

First of all the message is wrong...

Next attempt was to urlencode the password, which resulted in the above line working, but the 
password was sent url-encoded to the destination, which can hardly be the desired behaviour?"
"HTTPCLIENT-429","BUG","BUG","Problem getting the HTTPClient to use HTTP 1.0 with a proxy server","I am using HTTPClient 3.0-rc1.
I am connecting to an HTTPS site through a proxy.

I used HTTPLook to see the HTTP messages between the Proxy and the HTTPClient.
I noticed that it always used HTTP/1.1 and setVersion() on either the 
httpclient and the method do not help. I could not find how to get 
the HTTPClient to use HTTP/1.0 with the proxy.

Looking at the ConnectMethod class, the HTTP1.1 was indeed hardcoded.

Thanks
riad"
"HTTPCLIENT-911","IMPROVEMENT","IMPROVEMENT","Support underscore in domain name, or provide better exception","
When calling on HttpClient.execute with a url that contain underscore ('_'), you get NullPointerException.
Tracing it down show that java.net.Uri complains that it is illegal name. Which is true according to the RFC.
But it seems that most browser allow it, and some companies support it.

I think HttpClient should either support underscores, or atleast provide a better exception.

"
"HTTPCLIENT-753","REFACTORING","IMPROVEMENT","move class Scheme and friends to a separate package","We currently have a recursive dependency between packages o.a.h.conn and o.a.h.conn.routing, because routing depends on Scheme/SchemeRegistry. While these classes are used throughout the connection management code, they are not really part of the connection management itself and would therefore fit nicely into a separate package.

preliminary list of classes and interfaces to move:
- Scheme
- SchemeRegistry
- SocketFactory
- LayeredSocketFactory
- PlainSocketFactory

suggested package name: o.a.h.conn.scheme

Package o.a.h.conn.ssl can stay where it is, it only changes its dependency from conn to the new package.

cheers,
  Roland
"
"HTTPCLIENT-695","DOCUMENTATION","BUG","broken link to the release notes","On http://jakarta.apache.org/httpcomponents/httpclient-3.x/downloads.html
the link to the release notes is broken"
"HTTPCLIENT-259","BUILD_SYSTEM","BUG","[Maven] Migrate checkstyle.properties to XML","Newer Checkstyle versions (used with latest Maven builds) can not use the old
properties configuration file. They work with XML configuration files.
checkstyle.properties must be migrated in order to use a current version of Maven."
"HTTPCLIENT-117","RFE","BUG","Move to the new URIUtil class","Depricate httpclient.URIUtil class and methods
Move all URIUtil calls to httpclient.util.URIUtil"
"HTTPCLIENT-748","IMPROVEMENT","IMPROVEMENT","make SchemeRegistry friendlier for DI frameworks","Scheme's in SchemeRegistry are registered via 'register' method, but there is no way to pass it a set of schemes so those can be registered in one step. This way it can be externally configured and 'spring/guice friendly'... something like this is sufficient...

public void setSchemes (final Set <Scheme> schemes) {
    for (final Scheme scheme : schemes) 
        register(scheme);    
}
"
"HTTPCLIENT-742","REFACTORING","IMPROVEMENT","common interface for HttpRoute and RouteTracker","Classes HttpRoute and RouteTracker have many identical getters. There should be a common interface, for example RouteInfo, to define these getters and a toRoute() method that returns an unmodifiable representation. Some portions of the API may then accept the interface instead of the specific class HttpRoute.
"
"HTTPCLIENT-265","BUG","BUG","Error releasing chunked connections with no response body.","HttpMethodBase.releaseConnection() does not successfully release the connection
if closing the response stream throws an exception."
"HTTPCLIENT-1153","IMPROVEMENT","BUG","org.apache.http.impl.client.cache.memcached.MemcachedHttpCacheStorage uses URL as cache key - shouldn't.","Spy memcached has 250 defined as max key length:
http://dustin.github.com/java-memcached-client/apidocs/constant-values.html#net.spy.memcached.MemcachedClientIF.MAX_KEY_LENGTH

URLs can be (and often are) much longer than 250 characters.

URLs should be hashed before being used as keys."
"HTTPCLIENT-214","IMPROVEMENT","IMPROVEMENT","HttpClient drops connection to the proxy when an invalid 'connection: close' directive is encountered in 'connection established' response","One of our customer is using our application to connect to our servlet using 
https.  We are using httpClient for http protocol handling.  The customer has a 
IBM proxy (see log file).  The connect failed with a null pointer exception.

The log seem to indicate that the proxy server is returning 200 for ""CONNECT"", 
but the proxy also sends a ""Connection:close"" header.  The httpClient closed 
the connection and then tried to create the SSL socket.  If the proxy server is 
incorrect in sending 200 with ""Connection:close"", then httpClient should throw 
exception for invalid state (IllegalStateException ?).

I will attach the log file."
"HTTPCLIENT-999","TEST","TEST","need tests to guarantee transparency of caching module on end-to-end headers","""A transparent proxy SHOULD NOT modify an end-to-end header unless the definition of that header requires or specifically allows that.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.5.2

This is already true of our implementation, but we should have tests to preserve that behavior.
"
"HTTPCLIENT-633","BUG","BUG","MultiThreadedHttpConnectionManager does not properly respond to thread interrupts","MultiThreadedHttpConnectionManager uses interrupts to notify waiting threads when a connection is ready for them. Issues arise if the threads are interrupted by someone else while they are still waiting on a thread, because doGetConnection does not remove the threads from the queue of waiting threads when they are interrupted:

                        connectionPool.wait(timeToWait);

                        // we have not been interrupted so we need to remove ourselves from the 
                        // wait queue
                        hostPool.waitingThreads.remove(waitingThread);                        connectionPool.waitingThreads.remove(waitingThread);
                    } catch (InterruptedException e) {
                        // do nothing                    } finally {
                        if (useTimeout) {
                            endWait = System.currentTimeMillis();
                            timeToWait -= (endWait - startWait);                        }                    }

Under ordinary circumstances, the queue maintenance is done by the notifyWaitingThread method. However, if the thread is interrupted by any other part of the system, it will (1) not actually be released, since the loop in doGetConnection will force it back to the wait, and (2) will be added the waiting thread to the queue repeatedly, which basically means that the thread will eventually receive the interrupt from notifyWaitingThread at some later point, when it is no longer actually waiting for a connection.

This code could probably be re-architected to make it less error-prone, but the fundamental issue seems to be the use of interrupts to signal waiting threads, as opposed to something like a notify. "
"HTTPCLIENT-1065","DOCUMENTATION","TASK","Documentation on SingleClientConnManager(SchemeRegistry schreg) constructor is wrong","Seems that the documentation for single-arg constructor SingleClientConnManager(SchemeRegistry schreg) is wrong.

Documentation says that incoming SchemeRegistry parameter can be null:
    schreg - the scheme registry, or null for the default registry

However, the constructor throws an exception in incoming schreg param is null:

    /**
     * Creates a new simple connection manager.
     *
     * @param params    the parameters for this manager
     * @param schreg    the scheme registry, or
     *                  <code>null</code> for the default registry
     */
    public SingleClientConnManager(HttpParams params,
                                   SchemeRegistry schreg) {
        if (schreg == null) {
            throw new IllegalArgumentException
                (""Scheme registry must not be null."");
        }


So this is likely a documentation bug..."
"HTTPCLIENT-1079","BUG","BUG","Kerberos cross-realm support is broken","This issue is basically based on the same facts as this issue https://issues.sonatype.org/browse/AHC-71?focusedCommentId=129559#action_129559 
Since the Kerberos code looks the same, I assume that AHC used your code. The same patch can be applied to fix [this http://hc.apache.org/httpcomponents-client-ga/httpclient/xref/org/apache/http/impl/auth/NegotiateScheme.html#200] defective code."
"HTTPCLIENT-981","BUG","BUG","CachingHttpClient returns a 411 respones when executing a POST (HttpPost) request ","The CachingHttpClient validates requests prior executing them, by calling RequestProtocolCompliance.requestIsFatallyNonCompliant(..).

When executing an HttpPost, this method considers the request is invalid because it does not contain (yet) a content-length header. Indeed, I observed that this header is generated at the time the DefaultHttpClient fires the request.

NB: i'm using the Cache 4.1-alpha2 plugged over the HttpClient 4.0.1-final. I can't use the latest version for both because I need to rely on a stable version if there's any. I would be curious to know if we get the same behaviour in 4.1...

Anyway, I would see two fixes for that issue:
- make HttpPost set the content-length at the time the entity is set,
- or remove the validation step on the CachingHttpClient side.
"
"HTTPCLIENT-735","RFE","IMPROVEMENT","allow unsetting of DEFAULT_PROXY and FORCED_ROUTE parameters in the client stack","Since we don't want to delay client alpha3 until HTTPCORE-139 is solved in beta2, we need a parameter specific solution for unsetting these client parameters on the request level.
"
"HTTPCLIENT-128","BUG","BUG","Redirection of a POST method","I execute a PostMethod to an URL which redirects me to a HTML page. If I set 
follow redirects to true the HttpClient wants to execute once more a POST. Of 
course a POST is not allowed to HTML pages. I think the HttpClient should 
exectue a GET method instead. That's also what is in the RFC2616:

10.3 Redirection 3xx

   This class of status code indicates that further action needs to be
   taken by the user agent in order to fulfill the request.  The action
   required MAY be carried out by the user agent without interaction
   with the user if and only if the method used in the second request is
   GET or HEAD. A client SHOULD detect infinite redirection loops, since
   such loops generate network traffic for each redirection.

      Note: previous versions of this specification recommended a
      maximum of five redirections. Content developers should be aware
      that there might be clients that implement such a fixed
      limitation."
"HTTPCLIENT-427","RFE","IMPROVEMENT","Implement a cache to perform real request only when needed","Browsers may cache received content according to the values of different
response headers. It would be great if HttpClient could do the same."
"HTTPCLIENT-412","DOCUMENTATION","IMPROVEMENT","Document SINGLE_COOKIE_HEADER param in the cookie guide","Included is some sample code that shows the behaviour when loading pages from a phpBB powered 
site. Here are the results as i see them on my machine:

==== start results

==================================
Policy: rfc2109
==================================


        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str
        Response status code: 200
        Present cookies: 
                ForumSetCookie=str
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6

        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6
                ForumSetCookie=str

        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6
                ForumSetCookie=str

        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=c8da590cc4b1683b9079da3d82f4efa6
                ForumSetCookie=str

==================================
Policy: netscape
==================================


        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_sid=e2604334a0022283333153f6879feb70

        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_sid=e2604334a0022283333153f6879feb70

        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_sid=e2604334a0022283333153f6879feb70

        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_sid=e2604334a0022283333153f6879feb70

==================================
Policy: compatibility
==================================


        URL: http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str
        Response status code: 200
        Present cookies: 
                ForumSetCookie=str
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=d156f6dbfa605320b5a250129fa0b22e

        URL: http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str
        Response status code: 200
        Present cookies: 
                ForumSetCookie=str
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=d5d5a46fd27fd783cdb4e324992bc9d2

        URL: http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str
        Response status code: 200
        Present cookies: 
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=b4312fee4250f767cd1b34b11afadb3d
                ForumSetCookie=str

        URL: http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str
        Response status code: 200
        Present cookies: 
                ForumSetCookie=str
                phpbb_str_data=a%3A0%3A%7B%7D
                phpbb_str_sid=daf72685d35d851c3eec68b6b3bc3705

==== end results

As you can see the only cookie policy that ISN'T successfully tracking sessions is the COMPATIBILITY 
setting. There are a lot of these phpBB sites around, so that's where I've noticed the behaviour most. 
Trying another random php powered site I see that all policies work as expected.

It would be nice to know what's messing up the cookie handing on these phpBB sites. If you can't rely 
on the compatibility setting to reliably maintain session variables (and hence truly imitate a browser) 
then life get's a little complicated.

Both 3.0beta1 and the CVS version show the same behaviour.

Many thanks,

Garry

Example code below.

====== begin code
import org.apache.commons.httpclient.Cookie;
import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.HttpState;
import org.apache.commons.httpclient.cookie.CookiePolicy;
import org.apache.commons.httpclient.methods.GetMethod;


public class CookieProbe {
	static final String[] urls = {
		""http://www.sgboards.com/forums/viewtopic.php?t=12&view=next&mforum=str"",
		""http://www.sgboards.com/forums/viewtopic.php?p=24&mforum=str"",
		""http://www.sgboards.com/forums/posting.php?mode=quote&p=24&mforum=str"",
		""http://www.sgboards.com/forums/viewtopic.php?p=25&mforum=str""
	};
	static final String[] urls2 = {
		""http://www.virginmobilelouder.com/live/index.php"",
		""http://www.virginmobilelouder.com/live/index.php?page_id=214"",
		""http://www.virginmobilelouder.com/live/index.php?page_id=3"",
		""http://www.virginmobilelouder.com/live/index.php?page_id=116""
	};
	
	static final String[] policies = {
		CookiePolicy.RFC_2109, 
		CookiePolicy.NETSCAPE, 
		CookiePolicy.BROWSER_COMPATIBILITY, 
	};
	
	
	public static void main(String[] args) {
		try {
			for (int i = 0; i < policies.length; i++) {
				System.out.println(""\n=================================="");
				System.out.println(""Policy: "" + policies[i]);
				System.out.println(""==================================\n"");
				tryPolicy(policies[i]);
			}
		} catch (Exception e) {
			e.printStackTrace(System.err);
		}
	}
	
	public static void tryPolicy(String policy) throws Exception {
		HttpState initialState = new HttpState();
		HttpClient httpclient = new HttpClient();
		httpclient.getHttpConnectionManager().
			getParams().setConnectionTimeout(30000);
		httpclient.setState(initialState);
		
		httpclient.getParams().setCookiePolicy(policy);
		for (int i = 0; i < urls.length; i++) {
			System.out.println(""\n\tURL: "" + urls[i]);
			tryURL(httpclient, urls[i]);
			Thread.sleep(1000); // give server a break
		}
			
	}

	public static void tryURL(HttpClient httpclient, String strURL) throws Exception {
		GetMethod httpget = new GetMethod(strURL);
		int result = httpclient.executeMethod(httpget);
		System.out.println(""\tResponse status code: "" + result);
		// Get all the cookies
		Cookie[] cookies = httpclient.getState().getCookies();
		System.out.println(""\tPresent cookies: "");
		for (int i = 0; i < cookies.length; i++) {
			System.out.println(""\t\t"" + cookies[i].toExternalForm());
		}
		// Release current connection to the connection pool once you are done
		httpget.releaseConnection();
	}
}
====== end code"
"HTTPCLIENT-1140","BUG","BUG","Infinite loop on basic authentication","Class org.apache.http.impl.client.DefaultRequestDirector has a bug whereby when Authentication fails if the log is not warnEnabled then you will receive a retry request and end up in an infinite loop retrying requests.. This occurred for me when SL4J was being picked up as the implementation but not properly configured.

In 4.1.2 the line number of the offending code is in the handleResponse method, line 1126, the return null statement requires moving outside of the if statement that checkes if the log is warn enabled."
"HTTPCLIENT-47","RFE","IMPROVEMENT","User definable default headers support","Provide the ability to set default headers to be sent on every request.  Should
be used whenever an object is created or recycled.  Needs to be user
configurable."
"HTTPCLIENT-964","BUG","BUG","no-cache directives with field names are transmitted downstream","""Field names MUST NOT be included with the no-cache directive in a request.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4

Currently, the cache implementation allows a request containing something like:
    Cache-Control: no-cache=""Content-Location""
to be passed downstream towards the origin.

This is another one of those tricky situations where our client has passed us a non-compliant request.
"
"HTTPCLIENT-268","BUG","BUG","Socket streams are closed in the incorrect order.","HttpConnection should close the streams/socket in the following order:

OutputStream
InputStream
Socket

<http://java.sun.com/docs/books/tutorial/networking/sockets/readingWriting.html>"
"HTTPCLIENT-131","RFE","IMPROVEMENT","[HttpClient] Authenticator() - ability to perform alternate authentication","My post to the user group.  The developer replied suggesting I enter an 
enhancement request.

-----Original Message-----
From: Gustafson, Vicki [mailto:vicki.gustafson@us.didata.com]
Sent: Thursday, 12 December 2002 5:03 AM
To: Jakarta Commons Users List
Subject: [HttpClient] Authentication using Basic

Is there a way to specify which authentication scheme you would like the client 
to use if several schemes are returned in the www-auth header?

I'm performing a simple post using the httpClient.  The server returns a 401 at 
which point the httpClient tries to authenticate with the server.  The 
following header is received:

Attempting to parse authenticate header: 'WWW-Authenticate: Negotiate, NTLM, 
Basic realm=""XXXwhateverXXX""

I need to authenticate using Basic, but the Authenticator class will only try 
the most secure scheme:  NTLM.  Is there a setting or parameter I can set to 
force the httpClient to use Basic?

thanks,
Vicki

// determine the most secure request header to add
Header requestHeader = null;
if (challengeMap.containsKey(""ntlm"")) {
    String challenge = (String) challengeMap.get(""ntlm"");
    requestHeader = Authenticator.ntlm(challenge, method, state,
    responseHeader);
} else if (challengeMap.containsKey(""digest"")) {
    String challenge = (String) challengeMap.get(""digest"");
    String realm = parseRealmFromChallenge(challenge);
    requestHeader = Authenticator.digest(realm, method, state,
    responseHeader);
} else if (challengeMap.containsKey(""basic"")) {
    String challenge = (String) challengeMap.get(""basic"");
    String realm = parseRealmFromChallenge(challenge);
    requestHeader = Authenticator.basic(realm, state, responseHeader);
} else if (challengeMap.size() == 0) {
    throw new HttpException(""No authentication scheme found in '""
    + authenticateHeader + ""'"");
} else {
    throw new UnsupportedOperationException(
    ""Requested authentication scheme "" + challengeMap.keySet()
    + "" is unsupported"");
}

--
To unsubscribe, e-mail:   <mailto:commons-user-unsubscribe@jakarta.apache.org>
For additional commands, e-mail: <mailto:commons-user-help@jakarta.apache.org>


--
To unsubscribe, e-mail:   <mailto:commons-user-unsubscribe@jakarta.apache.org>
For additional commands, e-mail: <mailto:commons-user-help@jakarta.apache.org>

**********developer response**********************************



Currently there isn't, however we probably should be more intelligent about 
falling back to other authentication schemes based on the type of credentials 
provided.  Having said this I'm not sure it conforms to the HTTP spec strictly 
(which states that the client must use the strongest authentication scheme it 
supports, there's a grey area here because if your application doesn't provide 
a dialog or similar for the user to enter NTLM credentials it can only support 
basic or digest authentication, despite HTTPClient supporting NTLM).

What I'd like to see happen is:

When NTLM authentication is requested as top priority but only 
UsernamePasswordCredentials are available instead of NTLMCredentials we fall 
back to one of the other schemes.  In general this would mean that:

if an authentication scheme is requested and a credentials object of the wrong 
type is provided, HTTPClient should assume (probably optionally or only in non-
strict mode) that the requested authentication scheme is not supported and fall 
through to other options.

Achieving this would require a reasonably amount of refactoring of the 
Authenticator class but shouldn't be impossible.  Unfortunately I don't have 
time to do it myself at the moment but I'd be happy to help out if you felt 
like doing it, otherwise logging an enhancement bug in Bugzilla would be a good 
way to record this request until someone has time to actually implement it.

Adrian Sutton, Software Engineer
Ephox Corporation
www.ephox.com"
"HTTPCLIENT-373","RFE","IMPROVEMENT","Allow configuration of SO_LINGER","There is currently no way to configure the SO_LINGER option on a socket.

Please change the HttpClient class to allow the configuration of the SO_LINGER
option on a socket, similar to the way the SO_TIMEOUT can be configured.

Suggested extension to the interface of the HttpClient class:
- Add method setSoLinger() to set the current setting for SO_LINGER. The method
could accept one argument. A negative value could indicate that the SO_LINGER
should be disabled.
- Add method getSoLinger() that returns the current setting for SO_LINGER. A
negative value would indicate that the SO_LINGER option is disabled.

See:
http://java.sun.com/j2se/1.4.2/docs/api/java/net/Socket.html#setSoLinger(boolean,%20int)"
"HTTPCLIENT-307","BUG","BUG","An IOException or RuntimeException leaves the underlying socket in an undetermined state","If an application level IOException or RuntimeException occurs, the underlying
socket will be in an undetermined state. In many cases, this will lead to zombie
connections in the pool that do not respond properly.

Simple example: uploading a file via POST. If we promise the server 1MB of data.
Shortly after starting the transfer an IOException occurs (e.g. the NFS server
the file was residing on stops responding). The connection is returned to the
pool (see HTTPCLIENT-302) but the the server is still expecting close to 1MB of data
on that socket. The next request on that socket (e.g. a GET) will send the HTTP
header but  the server thinks the header is part of the old stream and doesn't
respond."
"HTTPCLIENT-34","IMPROVEMENT","IMPROVEMENT","optimization in sending request","By doing network sniffering, I noticed that httpclient send the request line 
and headers as separate packages. All other httpclient, including IE, Netscape, 
Java's URLConnection all send it as one package. This can be easily fixed using 
some buffering in HttpMethodBase."
"HTTPCLIENT-228","BUG","BUG","Request with DIGEST authentication fails when redirected","Request with DIGEST authentication fails when redirected due to invalid URI
parameter.

-- Client side log ----------------------------------------------------------

[DEBUG] HttpClient - -Java version: 1.2.2
[DEBUG] HttpClient - -Java vendor: Sun Microsystems Inc.
[DEBUG] HttpClient - -Operating system name: Linux
[DEBUG] HttpClient - -Operating system architecture: i386
[DEBUG] HttpClient - -Operating system version: 2.4.20-13.9-ok
[DEBUG] HttpClient - -SUN 1.2: SUN (DSA key/parameter generation; DSA signing;
SHA-1, MD5 digests; SecureRandom; X.509 certificates; JKS keystore)
[DEBUG] HttpClient - -SunJSSE 1.0301: Sun JSSE provider(implements RSA
Signatures, PKCS12, SunX509 key/trust factories, SSLv3, TLSv1)
[DEBUG] HttpConnection - -Creating connection for localhost using protocol http:80
[DEBUG] HttpConnection - -HttpConnection.setSoTimeout(0)
[DEBUG] HttpMethod - -Execute loop try 1
[DEBUG] wire - ->> ""GET /transfer HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Adding Host request header
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 401 Authorization Required[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""WWW-Authenticate: Digest realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", algorithm=MD5,
domain=""/transfer"", qop=""auth""[\r][\n]""
[DEBUG] wire - -<< ""Vary: accept-language[\r][\n]""
[DEBUG] wire - -<< ""Accept-Ranges: bytes[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 1285[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=ISO-8859-1[\r][\n]""
[DEBUG] HttpMethod - -Authorization required
[DEBUG] HttpAuthenticator - -Using 'guest realm' authentication realm
[DEBUG] HttpMethod - -HttpMethodBase.execute(): Server demanded authentication
credentials, will try again.
...
[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy
[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.
[DEBUG] HttpMethod - -Execute loop try 2
[DEBUG] wire - ->> ""GET /transfer HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Request to add Host header ignored: header already added
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""Authorization: Digest username=""guest"", realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", uri=""/transfer"",
qop=""auth"", algorithm=""MD5"", nc=00000001,
cnonce=""81d4b905a4e9def944beaed8daf79283"",
response=""71394edcddf4bcee6237ea4bb50cfaa5""[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 301 Moved Permanently[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""Location: http://localhost/transfer/[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 302[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=iso-8859-1[\r][\n]""
[DEBUG] HttpMethod - -Redirect required
[DEBUG] HttpMethod - -Redirect requested to location 'http://localhost/transfer/'
[DEBUG] HttpMethod - -Redirecting from 'http://localhost:80/transfer' to
'http://localhost/transfer/
...
[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy
[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.
[DEBUG] HttpMethod - -Execute loop try 3
[DEBUG] wire - ->> ""GET /transfer/ HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Request to add Host header ignored: header already added
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""Authorization: Digest username=""guest"", realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", uri=""/transfer"",
qop=""auth"", algorithm=""MD5"", nc=00000001,
cnonce=""81d4b905a4e9def944beaed8daf79283"",
response=""71394edcddf4bcee6237ea4bb50cfaa5""[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 400 Bad Request[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""Vary: accept-language[\r][\n]""
[DEBUG] wire - -<< ""Accept-Ranges: bytes[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 973[\r][\n]""
[DEBUG] wire - -<< ""Connection: close[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=ISO-8859-1[\r][\n]""

-- End of client side log -----------------------------------------------------


-- Server side log ------------------------------------------------------------

[Fri Jun 20 10:30:06 2003] [error] [client 127.0.0.1] Digest: uri mismatch -
</transfer> does not match request-uri </transfer/>

-- End of server side log -----------------------------------------------------"
"HTTPCLIENT-967","RFE","IMPROVEMENT","allow cache to be configured as a non-shared (private) cache","Currently the CachingHttpClient only behaves as a shared cache, which is a safe and conservative assumption. However, in some settings, it would be appropriate to be able to configure the CachingHttpClient as a non-shared cache, which would make more responses cacheable, including:
* responses to requests with Authorization headers
* responses with 'Cache-Control: private'
* ability to serve stale responses when invalidation fails for 'Cache-Control: proxy-revalidate'
"
"HTTPCLIENT-923","IMPROVEMENT","BUG","NetscapeDraftSpec is too strict about cookie expires date format","The Netscape Draft specification (http://curl.haxx.se/rfc/cookie_spec.html) specifies clearly that the date format for Set-Cookie expires is ""Wdy, DD-Mon-YYYY HH:MM:SS GMT"". But on the other hand, in the examples section of the same document, the only example header that contains ""Expires"" is the following:

Set-Cookie: CUSTOMER=WILE_E_COYOTE; path=/; expires=Wednesday, 09-Nov-99 23:12:40 GMT

Note that the weekday is fully spelled out and that the year is written as two digits only. I would say that the specification therefore makes the 2 or 4 digit year optional. I think NetscapeDraftSpec should reflect this. An example of a product that uses the 2 digit version is jetty 6 and 7. When using httpclient 4 talking to a jetty server, any Set-Cookie headers for persistent cookies will be interpreted as a 4 digit year in the date and the cookie will immediately be disregarded as expired by some 2,000 years or so. Httpclient 3 on the other hand had no problem understanding the persistent cookies from jetty. I filed a bug report https://bugs.eclipse.org/bugs/show_bug.cgi?id=304698 on jetty to change their date format, but on the other hand I also think httpclient 4 is too strict about the date format when even the original specification uses two alternatives.

Workaround is easy by setting CookieSpecPNames.DATE_PATTERNS, but I really think that projects like jetty and httpclient should be compatible by default. Also, since the date format used by jetty is parsable but misinterpreted and disregarded by httpclient makes it especially hard to detect the first time on encounters the problem."
"HTTPCLIENT-187","RFE","IMPROVEMENT","Provide general HTTP date parsing","Add generally accessible support for parsing HTTP dates as used in headers/cookies.

Initially submitted to HttpClient dev by Chris Brown."
"HTTPCLIENT-862","RFE","IMPROVEMENT","Extend the client's redirect handling interface to allow control of the content of the redirect","The existing RedirectHandler interface provides the ability influence which situations cause redirects, but gives you no control over the content of the redirect itself.  For example, if you want the client follow the redirect of a POST request with a POST request to the new location, you can't do it.  DefaultRequestDirector decides what method will be used on the redirect request and as of the most recent patch, it's always either a HEAD or a GET.

One option for resolving this might be extending the RedirectHandler interface to be a factory for creating the redirect request object.  The the DefaultRequestDirector could then be changed to ask the RedirectHandler to create the appropriate request for the situation.

Thanks,
Ben"
"HTTPCLIENT-38","BUG","BUG","Header Connection Close - Closes the Connection","If the connectionHeader equals Close the conection imediateley closes, without 
waiting for the responce back from the server. 

If the client is pulling data from a CGI script which has not sent the Content 
Length - most servers will send a Connection Close header. For example 

-----------------------------------------
HTTP/1.1 200 OK
Date: Fri, 21 Jun 2002 17:08:46 GMT
Server: Apache/1.3.14 (Unix)
Connection: close
Content-Type: text/html
 
<html>
      <head>
            <title>thegumtree.com - London's online community for Aussies, Kiwis
 and South Africans</title>
                           <meta http-equiv=""Content-Type"" content=""text/html; c
harset=iso-8859-1"">
                   </head>

--------------------------------

I do not yet have a work arround apart from commenting out the the following 
code in 

Header connectionHeader = getResponseHeader(""connection""); etc

in HttpMethodBase"
"HTTPCLIENT-119","BUG","BUG","[PATCH] FilePart fails to send data on second call to send","When using a FilePart with the MultipartPostMethod and a server that requires 
authentication, the first call to FilePart.send() sends the data correctly and 
HttpClient receives an unauthorized response from the server.  If HttpClient is 
set to automatically handle authentication attempts it then attempts to send 
the FilePart again at which time the InputStream FilePart reads from is empty 
so it doesn't send any data.

Due to this, the data actually sent by HttpClient doesn't match the content 
length specified so the server continues to wait for the data and doesn't 
respond, leaving HttpClient to timeout while waiting for a response.

This occurs with the latest source from CVS as of 16 October 2002."
"HTTPCLIENT-295","BUG","IMPROVEMENT","HttpClient loops endlessly while trying to retrieve status line","When fed with the wrong URL, for example http://localhost:19/ (chargen port),
HttpClient will loop endlessly while attempting to read the status line.

This is caused by a bug in HttpMethodBase.readStatusLine(HttpState, HttpConnection)

(while loop without any exceptional abort condition).

wire log excerpt:

2003/11/10 12:33:04:085 CET [DEBUG] HttpMethodDirector - -Execute loop try 1
2003/11/10 12:33:04:312 CET [DEBUG] wire - ->> ""GET / HTTP/1.1[\r][\n]""
2003/11/10 12:33:04:351 CET [DEBUG] HttpMethodBase - -Adding Host request header
2003/11/10 12:33:04:532 CET [DEBUG] wire - ->> ""User-Agent: Jakarta
Commons-HttpClient[\r][\n]""
2003/11/10 12:33:04:554 CET [DEBUG] wire - ->> ""Host: localhost:19[\r][\n]""
2003/11/10 12:33:04:559 CET [DEBUG] wire - ->> ""[\r][\n]""
2003/11/10 12:33:04:639 CET [DEBUG] wire - -<<
""!""#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefgh[\r][\n]""
2003/11/10 12:33:04:669 CET [DEBUG] wire - -<<
""""#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghi[\r][\n]""
2003/11/10 12:33:04:673 CET [DEBUG] wire - -<<
""#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghij[\r][\n]""
2003/11/10 12:33:04:692 CET [DEBUG] wire - -<<
""$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijk[\r][\n]""
2003/11/10 12:33:04:698 CET [DEBUG] wire - -<<
""%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijkl[\r][\n]""
2003/11/10 12:33:04:703 CET [DEBUG] wire - -<<
""&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklm[\r][\n]""
<snip>"
"HTTPCLIENT-406","IMPROVEMENT","IMPROVEMENT","Releasing a connection is unconfirmed","When a connection is attempted to be released using
HttpConnection.releaseConnection(), it is unclear whether this is actually done.
The implementation for the method is as follows in 3.0-beta1:

    /**
     * Release the connection.
     */
    public void releaseConnection() {
        LOG.trace(""enter HttpConnection.releaseConnection()"");
        if (locked) {
            LOG.debug(""Connection is locked.  Call to releaseConnection() ignore
        } else if (httpConnectionManager != null) {
            LOG.debug(""Releasing connection back to connection manager."");
            httpConnectionManager.releaseConnection(this);
        } else {
            LOG.warn(""HttpConnectionManager is null.  Connection cannot be relea
        }
    }

Silently ignoring a request (to release the connection, in this case) is hardly
ever the right thing to do, in my opinion. Instead, I suggest the method
indicates whether the connection was actually closed or not.

I see at least 2 alternatives:

1) throw an exception to indicate the connection could not be released;
2) return a flag indicating whether the connection could actually be released."
"HTTPCLIENT-326","RFE","IMPROVEMENT","MultiThreadedConnectionManager should provide a shutdown","MultiThreadedConnectionManager should provide a shutdown() method to release 
all its resources, it is currently using daemon threads that cannot be stopped 
and HTTP connections that cannot be released.
This is annoying when the pool of connection is created within a web 
application that is undeployed and re-deployed (i.e. the JVM is not restarted) 
consuming resources on local and remote servers."
"HTTPCLIENT-788","RFE","RFE","Public Suffix List","Hi,

I just found this useful list: http://publicsuffix.org/
and thought it would be nice to validate cookie domains against it, basically serving as a black list of domain for which never to set any cookies. What do you think about the attached patch? The download/parsing of the list is of course not part of the implementation.

Ortwin"
"HTTPCLIENT-296","BUG","BUG","Basic Authentification fails with non-ASCII username/password characters","http://marc.theaimsgroup.com/?t=106866959500001&r=1&w=2"
"HTTPCLIENT-379","BUG","BUG","JVM bug 4949631 causes BufferOverflowException in HttpMethodBase.getResponseBodyAsString","ava.nio.BufferOverflowException
        at java.nio.charset.CoderResult.throwException(CoderResult.java:259)
        at java.lang.StringCoding$CharsetSD.decode(StringCoding.java:188)
        at java.lang.StringCoding.decode(StringCoding.java:224)
        at java.lang.String.<init>(String.java:320)
        at
org.apache.commons.httpclient.HttpConstants.getContentString(HttpConstants.java:199)
        at
org.apache.commons.httpclient.HttpConstants.getContentString(HttpConstants.java:233)
        at
org.apache.commons.httpclient.HttpMethodBase.getResponseBodyAsString(HttpMethodBase.java:735)


This seems to be caused by a known JVM bug:
http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4949631

Strings over 16Mb can cause the problem.   Some workarounds are listed, the
essence being to split the string and call getBytes on each piece and reassemble
with a ByteBuffer."
"HTTPCLIENT-848","BUG","BUG","HttpClient:- Connections not released when SSL Tunneling fails.","Trying to use HTTPS, and SSL tunneling fails as expected because the host is not accepted by the squid proxy, so squid proxy return 403. 

The problem I am seeing is that, when ever this happens the connections are not released to the pool. I traced the code and it appears that in 
HttpMethidDirector.java:  executeWithRetry()
when executeConnect() return false and there is no retry, the connections are not released.

Is this expected? Or am I doing something wrong."
"HTTPCLIENT-874","RFE","BUG","Override method MultipartEntity.addPart so that applications may use FormBodyPart","FormBodyPart is similar to Part in HttpClient 3.x in that it couples the form name with the value.  Some applications may find this useful, but cannot really utilize these objects since there is only MultipartEntity.addPart(String name,ContentBody) and FormBodyPart does not have a getContent method:

  entity.addPart(part.getName(), part.getContent()); // Almost but there is no getContent method

How about overriding addPart to take a FormBodyPart object:

  entity.addPart(part);"
"HTTPCLIENT-1143","BUG","BUG","CachingHttpClient leaks connections with stale-if-error","If you are using the ""stale-if-error"" Cache-control header and CachingHttpClient decides to use a stale cached response it does not clean up the existing backend response.

This bug causes connections to leak from the connection pool each time the stale-if-error flow is executed.
"
"HTTPCLIENT-306","REFACTORING","IMPROVEMENT","Redesign of HTTP authentication framework","The existing HTTP authentication framework has got a few glaring deficiencies:
- Authentication headers management evolved (or degraded) into a some sort of
black art and proved very error-prone.
- Existing logic intended to deal with authentication failures and
authentication failure recovery is flawed. The resolution of the HTTPCLIENT-213 did
appear possible without a better approach than the one based on AuthScheme#getID.

On top of that authentication logic got quite messy with the series of attempts
to fix breakages in complex authentication schemes (the latest being NTLM proxy
+ basic host fix) 

The patch I am about to attach is an attempt to address all the shortcomings
mentioned above. It builds upon my previous patch that enabled authentication
schemes to maintain authentication state and presents a complete redesign of the
existing HTTP authentication framework.

Basically there's no authentication code left untouched, so please do take a
closer look. Critique, comments, suggestions welcome.

Oleg"
"HTTPCLIENT-230","RFE","BUG","Contributed utility for determing content type from file type extension","/*
 * ====================================================================
 *
 * The Apache Software License, Version 1.1
 *
 * Copyright (c) 2002-2003 The Apache Software Foundation.  All rights
 * reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in
 *    the documentation and/or other materials provided with the
 *    distribution.
 *
 * 3. The end-user documentation included with the redistribution, if
 *    any, must include the following acknowlegement:
 *       ""This product includes software developed by the
 *        Apache Software Foundation (http://www.apache.org/).""
 *    Alternately, this acknowlegement may appear in the software itself,
 *    if and wherever such third-party acknowlegements normally appear.
 *
 * 4. The names ""The Jakarta Project"", ""Commons"", and ""Apache Software
 *    Foundation"" must not be used to endorse or promote products derived
 *    from this software without prior written permission. For written
 *    permission, please contact apache@apache.org.
 *
 * 5. Products derived from this software may not be called ""Apache""
 *    nor may ""Apache"" appear in their names without prior written
 *    permission of the Apache Group.
 *
 * THIS SOFTWARE IS PROVIDED ``AS IS'' AND ANY EXPRESSED OR IMPLIED
 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
 * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 * DISCLAIMED.  IN NO EVENT SHALL THE APACHE SOFTWARE FOUNDATION OR
 * ITS CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
 * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF
 * USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
 * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 * ====================================================================
 *
 * This software consists of voluntary contributions made by many
 * individuals on behalf of the Apache Software Foundation.  For more
 * information on the Apache Software Foundation, please see
 * <http://www.apache.org/>.
 *
 * [Additional notices, if required by prior licensing conditions]
 *
 */

package org.apache.commons.httpclient.contrib.utils;

import java.io.File;
import java.io.IOException;

/**
 * This class provides mappings from file name extensions to content types.
 *
 * @author <a href=""mailto:emdevlin@charter.net"">Eric Devlin</a>
 * 
 * DISCLAIMER: HttpClient developers DO NOT actively support this component.
 * The component is provided as a reference material, which may be inappropriate
 * to be used without additional customization.
 */

public class ContentType {

	/** Mime Type mappings 'liberated' from Tomcat4.1.18/conf/web.xml*/
	public static final String[][] MIME_TYPE_MAPPINGS =	
		{	{ ""abs"",		""audio/x-mpeg"" },
			{ ""ai"",			""application/postscript"" },
			{ ""aif"",		""audio/x-aiff"" },
			{ ""aifc"",		""audio/x-aiff"" },
			{ ""aiff"",		""audio/x-aiff"" },
			{ ""aim"",		""application/x-aim"" },
			{ ""art"",		""image/x-jg"" },
			{ ""asf"",		""video/x-ms-asf"" },
			{ ""asx"",		""video/x-ms-asf"" },
			{ ""au"",			""audio/basic"" },
			{ ""avi"",		""video/x-msvideo"" },
			{ ""avx"",		""video/x-rad-screenplay"" },
			{ ""bcpio"",		""application/x-bcpio"" },
			{ ""bin"",		""application/octet-stream"" },
			{ ""bmp"",		""image/bmp"" },
			{ ""body"",		""text/html"" },
			{ ""cdf"",		""application/x-cdf"" },
			{ ""cer"",		""application/x-x509-ca-cert"" },
			{ ""class"",		""application/java"" },
			{ ""cpio"",		""application/x-cpio"" },
			{ ""csh"",		""application/x-csh"" },
			{ ""css"",		""text/css"" },
			{ ""dib"",		""image/bmp"" },
			{ ""doc"",		""application/msword"" },
			{ ""dtd"",		""text/plain"" },
			{ ""dv"",			""video/x-dv"" },
			{ ""dvi"",		""application/x-dvi"" },
			{ ""eps"",		""application/postscript"" },
			{ ""etx"",		""text/x-setext"" },
			{ ""exe"",		""application/octet-stream"" },
			{ ""gif"",		""image/gif"" },
			{ ""gtar"",		""application/x-gtar"" },
			{ ""gz"",			""application/x-gzip"" },
			{ ""hdf"",		""application/x-hdf"" },
			{ ""hqx"",		""application/mac-binhex40"" },
			{ ""htc"",		""text/x-component"" },
			{ ""htm"",		""text/html"" },
			{ ""html"",		""text/html"" },
			{ ""hqx"",		""application/mac-binhex40"" },
			{ ""ief"",		""image/ief"" },
			{ ""jad"",		""text/vnd.sun.j2me.app-
descriptor"" },
			{ ""jar"",		""application/java-archive"" },
			{ ""java"",		""text/plain"" },
			{ ""jnlp"",		""application/x-java-jnlp-
file"" },
			{ ""jpe"",		""image/jpeg"" },
			{ ""jpeg"",		""image/jpeg"" },
			{ ""jpg"",		""image/jpeg"" },
			{ ""js"",			""text/javascript"" },
			{ ""jsf"",		""text/plain"" },
			{ ""jspf"",		""text/plain"" },
			{ ""kar"",		""audio/x-midi"" },
			{ ""latex"",		""application/x-latex"" },
			{ ""m3u"",		""audio/x-mpegurl"" },
			{ ""mac"",		""image/x-macpaint"" },
			{ ""man"",		""application/x-troff-man"" },
			{ ""me"",			""application/x-troff-me"" },
			{ ""mid"",		""audio/x-midi"" },
			{ ""midi"",		""audio/x-midi"" },
			{ ""mif"",		""application/x-mif"" },
			{ ""mov"",		""video/quicktime"" },
			{ ""movie"",		""video/x-sgi-movie"" },
			{ ""mp1"",		""audio/x-mpeg"" },
			{ ""mp2"",		""audio/x-mpeg"" },
			{ ""mp3"",		""audio/x-mpeg"" },
			{ ""mpa"",		""audio/x-mpeg"" },
			{ ""mpe"",		""video/mpeg"" },
			{ ""mpeg"",		""video/mpeg"" },
			{ ""mpega"",		""audio/x-mpeg"" },
			{ ""mpg"",		""video/mpeg"" },
			{ ""mpv2"",		""video/mpeg2"" },
			{ ""ms"",			""application/x-wais-source"" },
			{ ""nc"",			""application/x-netcdf"" },
			{ ""oda"",		""application/oda"" },
			{ ""pbm"",		""image/x-portable-bitmap"" },
			{ ""pct"",		""image/pict"" },
			{ ""pdf"",		""application/pdf"" },
			{ ""pgm"",		""image/x-portable-graymap"" },
			{ ""pic"",		""image/pict"" },
			{ ""pict"",		""image/pict"" },
			{ ""pls"",		""audio/x-scpls"" },
			{ ""png"",		""image/png"" },
			{ ""pnm"",		""image/x-portable-anymap"" },
			{ ""pnt"",		""image/x-macpaint"" },
			{ ""ppm"",		""image/x-portable-pixmap"" },
			{ ""ps"",			""application/postscript"" },
			{ ""psd"",		""image/x-photoshop"" },
			{ ""qt"",			""video/quicktime"" },
			{ ""qti"",		""image/x-quicktime"" },
			{ ""qtif"",		""image/x-quicktime"" },
			{ ""ras"",		""image/x-cmu-raster"" },
			{ ""rgb"",		""image/x-rgb"" },
			{ ""rm"",			""application/vnd.rn-
realmedia"" },
			{ ""roff"",		""application/x-troff"" },
			{ ""rtf"",		""application/rtf"" },
			{ ""rtx"",		""text/richtext"" },
			{ ""sh"",			""application/x-sh"" },
			{ ""shar"",		""application/x-shar"" },
			{ ""smf"",		""audio/x-midi"" },
			{ ""snd"",		""audio/basic"" },
			{ ""src"",		""application/x-wais-source"" },
			{ ""sv4cpio"",	""application/x-sv4cpio"" },
			{ ""sv4crc"",		""application/x-sv4crc"" },
			{ ""swf"",		""application/x-shockwave-
flash"" },
			{ ""t"",			""application/x-troff"" },
			{ ""tar"",		""application/x-tar"" },
			{ ""tcl"",		""application/x-tcl"" },
			{ ""tex"",		""application/x-tex"" },
			{ ""texi"",		""application/x-texinfo"" },
			{ ""texinfo"",	""application/x-texinfo"" },
			{ ""tif"",		""image/tiff"" },
			{ ""tiff"",		""image/tiff"" },
			{ ""tr"",			""application/x-troff"" },
			{ ""tsv"",		""text/tab-separated-values"" },
			{ ""txt"",		""text/plain"" },
			{ ""ulw"",		""audio/basic"" },
			{ ""ustar"",		""application/x-ustar"" },
			{ ""xbm"",		""image/x-xbitmap"" },
			{ ""xml"",		""text/xml"" },
			{ ""xpm"",		""image/x-xpixmap"" },
			{ ""xsl"",		""text/xml"" },
			{ ""xwd"",		""image/x-xwindowdump"" },
			{ ""wav"",		""audio/x-wav"" },
			{ ""svg"",		""image/svg+xml"" },
			{ ""svgz"",		""image/svg+xml"" },
			{ ""wbmp"",		""image/vnd.wap.wbmp"" },
			{ ""wml"",		""text/vnd.wap.wml"" },
			{ ""wmlc"",		""application/vnd.wap.wmlc"" },
			{ ""wmls"",		""text/vnd.wap.wmlscript"" },
			{ ""wmlscriptc"",	""application/vnd.wap.wmlscriptc"" },
			{ ""wrl"",		""x-world/x-vrml"" },
			{ ""Z"",			""application/x-compress"" },
			{ ""z"",			""application/x-compress"" },
			{ ""zip"",		""application/zip"" } };

    /**
     * Get the content type based on the extension of the file name<br>
     *
     * @param fileName for which the content type is to be determined.
     *
     * @return the content type for the file or null if no mapping was
     * possible.
     */
	public static String get( String fileName  ) {
		String contentType = null;

		if ( fileName != null ) {
			int extensionIndex = fileName.lastIndexOf( '.' );
			if ( extensionIndex != -1 ) {
				if ( extensionIndex + 1 < fileName.length() ) {
					String extension = fileName.substring( 
extensionIndex + 1 );
					for( int i = 0; i < 
MIME_TYPE_MAPPINGS.length; i++ ) {
						if ( extension.equals( 
MIME_TYPE_MAPPINGS[i][0] ) ) {
							contentType = 
MIME_TYPE_MAPPINGS[i][1];
							break;
						}
					}
				}
			}
		}

		return contentType;
	}

    /**
     * Get the content type based on the extension of the file name<br>
     *
     * @param file for which the content type is to be determined.
     *
     * @return the content type for the file or null if no mapping was
     * possible.
     *
     * @throws IOException if the construction of the canonical path for 
	 * the file fails.
     */
	public static String get( File file ) 
		throws IOException
	{
		String contentType = null;

		if ( file != null ) {

			contentType = get( file.getCanonicalPath() );
		}

		return contentType;
	}
}"
"HTTPCLIENT-520","BUG","BUG","MultipartEntity incorrectly computes unknown length","If any Part of a MultipartEntity reports an unknown length (-1), MultipartEntity
reports an erroneous length value. It should report an unknown length (-1) if
any of the parts is of unknown length, that would cause the POST to be chunked.

See
http://mail-archives.apache.org/mod_mbox/jakarta-httpclient-user/200510.mbox/ajax/%3ceb3d689c0510250851t2eb78462tbf701135bbf718c9@mail.gmail.com%3e"
"HTTPCLIENT-884","BUG","BUG","Charset omitted from UrlEncodedFormEntity Content-Type header","UrlEncodedFormEntity sets the Content-Type header to:
   ""application/x-www-form-urlencoded""

It should set the header to:
   ""application/x-www-form-urlencoded; charset="" + charset

As a result, content can be misinterpreted by the recipient (e.g. if the entity content includes multibyte Unicode characters encoded with the ""UTF-8"" charset).

For a correct example of specifying the charset in the Content-Type header, see StringEntity.java.

Here's the fix:

    public UrlEncodedFormEntity (
        final List <? extends NameValuePair> parameters, 
        final String encoding) throws UnsupportedEncodingException {
        super(URLEncodedUtils.format(parameters, encoding),  encoding);
-        setContentType(URLEncodedUtils.CONTENT_TYPE);
+        setContentType(URLEncodedUtils.CONTENT_TYPE + HTTP.CHARSET_PARAM +
+            (encoding != null ? encoding : HTTP.DEFAULT_CONTENT_CHARSET));
    }

    public UrlEncodedFormEntity (
        final List <? extends NameValuePair> parameters) throws UnsupportedEncodingException {
-        super(URLEncodedUtils.format(parameters, HTTP.DEFAULT_CONTENT_CHARSET), 
-            HTTP.DEFAULT_CONTENT_CHARSET);
-        setContentType(URLEncodedUtils.CONTENT_TYPE);
+        this(parameters, HTTP.DEFAULT_CONTENT_CHARSET);
    }
"
"HTTPCLIENT-871","RFE","IMPROVEMENT","Add FileBody constructor with explicit filename","FileBody does not allow the filename field in the Content-Disposition header to be overriden, the filename taken from the File object - I have software that creates temporary files and needs to assign an implicit logical filename."
"HTTPCLIENT-1015","RFE","IMPROVEMENT","Support only-if-cached directive","Add support for only-if-cached Cache-Control directive- If the request is not servable from the cache, return a 504 Gateway Timeout.  See http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.4"
"HTTPCLIENT-143","DOCUMENTATION","BUG","Better integration of the TestWebApp-HowTo into the documentation","The excellent webapp howto written by Olegolas needs to be integrated better
into httpclient documentation.  Currently it is in the docs directory as a html
file, but it would be better if it was in the xdocs directory as an xml file."
"HTTPCLIENT-969","BUG","BUG","BasicCookieStore.getCookies() returns non-threadsafe collection","BasicCookieStore.getCookies() is a simple method.  It's synchronized, and it returns an unmodifiable wrapper around the underlying cookie list.  If the caller were to then iterate over it as another thread were to manipulate the cookie list via BasicCookieStore, this would create a thread un-safe situation because both threads aren't doing their reading/writing with the same lock (the reader doesn't even have a lock).

I suggest fixing this by using CopyOnWriteArrayList, or by making a defensive copy in getCookies()

This issue might apply to some of the other basic implementations of some of the interfaces but I haven't checked."
"HTTPCLIENT-129","IMPROVEMENT","BUG","multipart feedback","never got a reply on this from 10/20/02 mailing to email address in ""author"" tag, so posting here.
-----------------------
Matt and Jeff,

Excuse me for writing directly to the addresses found in the code as authors.  Please feel free to forward this to any list that is more appropriate.

Thank you very much for your efforts in making an HTTP client for Java.  It will find great use.  Below are some aspects of the org.apache.commons.httpclient.methods.multipart package that I'd like you to consider.  

First, consider making the encoding a parameter.  Currently, the content disposition and other general-purpose headers are written with a String.getBytes () call, which will use the default encoding on whatever client is being used by the customer.  Does the RFC and for HTTP post specify an encoding for these lines?  Perhaps the header information and disposition information should be a standard UTF-8 encoding, and an additional parameter could specify encoding for anything supplied by the users of the library, most notably the StringPart.

Second, consider that the content length header may not be important for many contexts.  When you receive a post on the server side, can you depend on the content length header?  Some browsers do not supplied this header, and even if all of them did, would you be wise to believe it on the server side?  In fact, common libraries for handling post, most notably http://www.servlets.com/cos/index.html , ignore any content length header that is supplied by the client.  On the server side, content length is calculated from the actual bytes that are received.

Why do I mention this?  Because it appears that a trade-off has been made in this alpha code such that the content length calculation was more important than polymorphism in Part.java:

    /* The following 2 methods don't need to be final, but they DO need
     * to be overridden as a pair, and the only way to make sure of that
     * is to make sure they AREN'T overridden. 
     */

    final public void send(OutputStream out) throws IOException {
        sendStart(out);
        sendHeader(out);
        sendEndOfHeader(out);
        sendData(out);
        sendEnd(out);
    }
    
    final public long length() throws IOException {
        return lengthOfStart() + 
               lengthOfHeader() + 
               lengthOfEndOfHeader() +
               lengthOfData() + 
               lengthOfEnd();
    }

The method send() seems like an important method to be able to override.  For example, consider a situation where the post content is zipped on-the-fly.  The content length is not known when writing the headers.  Further, it would be handy to override certain methods like send() in order to manipulate the output stream. 

Basically, since your library will be very general purpose and used widely, the more you can do for easy polymorphism, the more your customers will appreciate your library. Is there a way to make the content length calculation and header writing more flexible, so that it may be avoided when it is not known a priori?

Third, consider making the content type a parameter for a FilePart.  In the example above, the content type for the zipped file should be ""application/x-zip-compressed"" rather than ""application/octet-stream"".

Again, I was very happy to find your excellent work on this library. Thank you for your contributions to apache jakarta.

larry hamel"
"HTTPCLIENT-676","BUG","BUG","memory leak in MultiThreadedHttpConnectionManager","MultiThreadedHttpConnectionManager.getConnectionsInPool(hostConfiguration) will create HostConnectionPool entries that will not be cleaned up unless they are later used for communication. This should be changed to not create pools in that method, but rather return 0 for a non-existent pool.
"
"HTTPCLIENT-1020","BUILD_SYSTEM","","Please add maven-notice-plugin to gump-trunk","Hi,

the httpclient build currently fails in Gump because it cannot find the maven-notice-plugin.  We could grab it from http://svn.apache.org/repos/asf/httpcomponents/maven-notice-plugin/trunk/ but since you have a directory with externals just for Gump it would be a lot easier if you added an external for it as well.

Thanks

Stefan"
"HTTPCLIENT-102","RFE","BUG","Unable to get the status line from a http method object","The status line (typically the first line returned from a http connection read)
is hidden inside httpclient with no way for client code to retrieve it intact.
readStatusLine() in HttpMethodBase is where the status line is
read, but it is never stored and is not available outside the method.

We could store the status line as a string and add a getStatusLine
method to the HttpMethod interface and HttpMethodBase class.  Alternatively, we
could create a header for it with the name StatusLine (or perhaps just null) so
that it could be retrieved with getHeader(""StatusLine"").  This would preserve
the interface but would be a bit of a kludge."
"HTTPCLIENT-618","CLEANUP","IMPROVEMENT","Eliminate class HostConfiguration","Remove the target host attribute from the HostConfiguration class. This will allow one HostConfiguration object to be used for different targets.
The problem is that currently MultiThreadedHttpConnectionManager uses HostConfiguration objects as cache keys, which needs to be changed.

This is a followup to HTTPCLIENT-615.

cheers,
  Roland
"
"HTTPCLIENT-790","BUG","BUG","Protocol interceptors not called when executing CONNECT methods","When the DefaultRequestDirector tries to establish a route via a proxy to a https target, registered protocol interceptors aren't being called in the createTunnelToTarget method. "
"HTTPCLIENT-601","RFE","RFE","SecureProtocolFactoryWrapper class for using the socket factory created by Java Web Start","As smartcards and SSL are becoming more and more prevelant, Java Web Start has started to become better equiped to handle these situations.  When running an app within webstart, it can access the browser's keystore, which (at least in our case) accessed the users smartcard to make the SSL connection.

I wanted to start using HttpClient, but needed a way to do so while still mainaining access to the browser's keystore.

My initial tests show that getting the default socket factory from the java.net.HttpURLConnection and wrapping it in a class that implements org.apache.commons.httpclient.protocol.SecureProtocolSocketFactory is sufficient."
"HTTPCLIENT-238","IMPROVEMENT","BUG","HeaderElement#parse(String) implementation is not optimal","The cookie setted by the LocalDirector 416 Version 4.2.3 has a bug.
It sets for Tuesday and Thursday ""Tues"" and ""Thur"" instead of the 
canonical ""Tue"" and ""Thu"". This break the parsing stage and stop HttpClient to 
work for 2 days a week. Of course I modified the parse method in HeaderElement 
class, but everytime I download a new version, I have to remake the jar....
It's possible to include this into the CVS files ?"
"HTTPCLIENT-719","RFE","IMPROVEMENT","Clone support","It would be nice to have a clone method for some of the classes that don't have getters & setters exposed for all of their fields. Where relevant, the clone method could be in the interface, so that it doesn't matter which implementing class is being used. The main interfaces that I would like to clone are HttpRequest and Cookie. I know that HttpRequest is technically part of HttpCore, but the primary implementations of it are in HttpClient, so I thought I would post it here. 

Thanks,
David Byrne"
"HTTPCLIENT-266","RFE","IMPROVEMENT","[patch] Support for digest auth MD5-sess","I was attempting to access a device that requires Digest authentication using
MD5-sess, which does not seem to be supported."
"HTTPCLIENT-835","IMPROVEMENT","IMPROVEMENT","Thread safety and visibility Improvements","AbstractAuthenticationHandler.DEFAULT_SCHEME_PRIORITY is not protected against external changes.

Although the field is private, subclasses can obtain a reference to it and so may be able to change it.

Consider making the list read-only, or returning a copy instead."
"HTTPCLIENT-524","RFE","BUG","Provide feedback mechanism to CredentialsProvider","If the remote server is using BASIC or NT authentication and you pass in 
invalid credentials you get stuck in an infinite for loop, repeatedly sending 
the same authentication request again and again to the server.  The for loop is 
in the executeMethod method of the HttpMethodDirector class.

Sample code:
=================================================================


import org.apache.commons.httpclient.Credentials;
import org.apache.commons.httpclient.NTCredentials;
import org.apache.commons.httpclient.UsernamePasswordCredentials;
import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.methods.GetMethod;
import org.apache.commons.httpclient.auth.*;

import java.io.IOException;
import java.io.BufferedInputStream;
import java.io.ByteArrayOutputStream;

/**
 * Created by IntelliJ IDEA.
 * User: dmartineau
 * Date: Nov 8, 2005
 * Time: 1:43:21 PM
 */
public class ShowProblem
{

    private String location;
    private String user;
    private String pass;
    private String domain;

    public ShowProblem(String location, String user, String pass, String domain)
    {
        this.location = location;
        this.user=user;
        this.pass=pass;
        this.domain=domain;

    }

    public int getFile()
    {
        int status = 500;
        HttpClient client = new HttpClient();
        client.getParams().setParameter(
            CredentialsProvider.PROVIDER, new CProvider(user,pass,domain));
        GetMethod httpget = new GetMethod(location);
        httpget.setDoAuthentication(true);

        try
        {
            // execute the GET
            status = client.executeMethod(httpget);
            if (status==200)
            {
                BufferedInputStream bin = new BufferedInputStream
(httpget.getResponseBodyAsStream());

                ByteArrayOutputStream bos = new ByteArrayOutputStream();
                int bytesRead = 0;
                byte[] buff = new byte[16384];

                while ( (bytesRead = bin.read(buff)) != -1) {
                    bos.write(buff, 0, bytesRead);
                }

                // display the results.
                System.out.println(new String(bos.toByteArray()));
            }
        }
        catch (Throwable t)
        {
            t.printStackTrace();
        }
        finally
        {
            // release any connection resources used by the method
            httpget.releaseConnection();
        }
        return status;

    }

    public static void main(String[] args)
    {
        ShowProblem showProblem = new ShowProblem(args[0],args[1],args[2],args
[3]);
        int response = showProblem.getFile();
        
    }



    class CProvider implements CredentialsProvider
    {
        private String user;
        private String password;
        private String domain;

        public CProvider(String user, String password, String domain)
        {
            super();
            this.user = user;
            this.password = password;
            this.domain = domain;
        }

        public Credentials getCredentials(final AuthScheme authscheme,final 
String host,int port,boolean proxy)
        throws CredentialsNotAvailableException
        {
            if (authscheme == null)
            {
                return null;
            }
            try
            {
                if (authscheme instanceof NTLMScheme)
                {
                    return new NTCredentials(user, password, host, domain);
                }
                else if (authscheme instanceof RFC2617Scheme)
                {
                    return new UsernamePasswordCredentials(user, password);
                }
                else
                {
                    throw new CredentialsNotAvailableException(""Unsupported 
authentication scheme: "" +
                        authscheme.getSchemeName());
                }
            }
            catch (IOException e)
            {
                throw new CredentialsNotAvailableException(e.getMessage(), e);
            }
        }

    }
}"
"HTTPCLIENT-402","BUG","BUG","DefaultMethodRetryHandler bug","DefaultMethodRetryHandler does not seem to test correctly for the number of
attempts to retry a given method. It seems to bail out one attempt too early:

if (executionCount >= this.retryCount) {
  // Do not retry if over max retry count
  return false;
}

For example, if I set the retryCount to 1, HttpClient does not retry the method
at all. At least that's what I'm seeing when I step through it with a debugger."
"HTTPCLIENT-210","BUG","BUG","Exception handling in HttpClient requires redesign","When I use httpclient2.0-alpha3 and setTimeout(60000), after the specified 
time, I would like to see InterruptedIOException thrown, but I got 
HttpRecoverableException instead, which is pretty general. I would like to see 
the original exception. Thanks"
"HTTPCLIENT-345","RFE","IMPROVEMENT","[CONTRIB] SSL authenticating protocol socket factory","Here's the long promised SSL client/server authenticating socket factory. This
socket factory can be used to enforce client/server authentication during the
SSL context negotiation. Let me know what you think. Please, please someone
proof-read the accompanying javadocs and let me know if the text is comprehensible 

I have also tweaked EasySSLProtocolSocketFactory a little

The patch is against HTTPCLIENT_2_0_BRANCH

Oleg"
"HTTPCLIENT-536","DOCUMENTATION","BUG","misleading lack of javadoc in StringRequestEntity","When using httpclient2, we were doing the following:

	// Add the Content-type header.  This sets the charset to UTF-8.
	method.setRequestHeader( ""Content-type"", ""text/xml; charset=UTF-8"" );
	// The given string is converted internally by the post method into
	// a UTF-8 encoded byte array.
	method.setRequestBody( xmlstring );

The comments show that this was the way we used to obtain a UTF-8 encoded XML
document (if this was wrong, that may be the origin of the problem?).


When upgrading to httpclient3 and killing deprecated code, this was converted to:

	// Add the Content-type header.  This sets the charset to UTF-8.
	method.setRequestHeader( ""Content-type"", ""text/xml; charset=UTF-8"" );
	// The given string is converted internally by the post method into
	// a UTF-8 encoded byte array.
        method.setRequestEntity( new StringRequestEntity( xmlstring ) );

which went without problem during the tests on my machine and on test production
machine.. because platforms charset were UTF-8, which is not the case for
production machines :(

I think the javadoc of the used StringRequestEntity constructor should strongly
state that it uses String#getBytes for the content, which uses the platform
charset. Also, I didn't notice any ""upgrade to 3.x"" documentation which would
have helped me :/"
"HTTPCLIENT-789","RFE","IMPROVEMENT","Support for passing an SSLContext to the SSLSocketFactory of HttpClient","Would it be possible to use an existing instance of SSLContext to initialise an SSLSocketFactory? This would allow using SSLContexts configured with more options, such as CRLs.

(This follows the thread of the httpclient-commons-dev list: http://marc.info/?l=httpclient-commons-dev&m=121737017814116&w=2 )."
"HTTPCLIENT-255","IMPROVEMENT","BUG","In J2SDK 1.5.0 (Tiger) enum is a keyword","Hi!

Tiger adds extensions to the Java Programming Language (JSR201). One is
""Enumerations"", which required to add the new keyword enum.

I just made a grep (grep -lrw) over some sources and found some Apache projects
using enum as a word.

To be compliant with the new specification, please check that enum is not used
as a variable, field or method name.

Regards,
Robert"
"HTTPCLIENT-324","DOCUMENTATION","IMPROVEMENT","[API Doc] Document exceptions thrown on execute methods","There should be more detailed documentation on HttpClient::executeMethod and
HttpMethod::execute about exceptions thrown in which cases."
"HTTPCLIENT-739","RFE","IMPROVEMENT","CookieIdentityComparator and CookiePathComparator could/should implement Serializable","CookieIdentityComparator and CookiePathComparator could/should implement Serializable

As Findbugs suggests:

""Comparator doesn't implement Serializable

This class implements the Comparator interface. You should consider whether or not it should also implement the Serializable interface. If a comparator is used to construct an ordered collection such as a TreeMap, then the TreeMap will be serializable only if the comparator is also serializable. As most comparators have little or no state, making them serializable is generally easy and good defensive programming. ""

Neither class has any state, so implementing Serializable would be trivial.

"
"HTTPCLIENT-1166","BUG","BUG","URIUtils.extractHost(...) throws a NumberFormatException line 310","Original Jboss-seam-wicket-booking application in Jboss-4.2.3.GA started, post a login request thanks httpclient, then NumberFormatException.



regarding this page :
http://hc.apache.org/httpcomponents-client-dev/httpclient/clover/org/apache/http/client/utils/URIUtils.html

305 	   	// Extract the port suffix, if present
306 	   	if (host != null) {
307 	  	   int colon = host.indexOf(':');
308 	   	   if (colon >= 0) {
309 	   	      if (colon+1 < host.length()) {
310 	   	          port = Integer.parseInt(host.substring(colon+1));
311 	   	      }
312 	  	   host = host.substring(0,colon);
313 	   	   }
314 	   	}

resolving the port throw a NumberFormatException

java.lang.NumberFormatException: For input string: ""8080;jsessionid=9E9EDA0B6E1CDD499A0A15C4A8F212D8""
	at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)
	at java.lang.Integer.parseInt(Integer.java:458)
	at java.lang.Integer.parseInt(Integer.java:499)
	at org.apache.http.client.utils.URIUtils.extractHost(URIUtils.java:310)
	at org.apache.http.impl.client.AbstractHttpClient.determineTarget(AbstractHttpClient.java:764)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)
	at org.tagbrowser.api.TagBrowser.request(TagBrowser.java:109)


another case of this problem canbe found hier :
https://gitorious.org/yacy/rc1/commit/8b0920b0b5eb67ae17eec24c1bf3a059543cb6e8/diffs"
"HTTPCLIENT-1164","RFE","BUG","Compressed entities are not being cached properly","org.apache.http.impl.client.cache.CacheValidityPolicy.contentLengthHeaderMatchesActualLength() returns false for entities decompressed by ContentEncodingHttpClient, because the length of decompressed entity stored in cache will be different from the length specified in the response header.
Consequently, gzipped/deflated entities will never be satisfied from the cache.

Proposed fix: introduce new field in HttpCacheEntry() - actualContentLength, and populate it with the actual content length rigth before the cache entry is stored in the cache. Change the org.apache.http.impl.client.cache.CacheValidityPolicy.contentLengthHeaderMatchesActualLength() method to compare
entry.getResource().length() with entry.getActualContentLength()
"
"HTTPCLIENT-179","BUG","BUG","HTTPS Post Does Not Work","Using Java 1.4.1_01 on Windows 2000. An HTTPS Post results in HTTP/100-Continue 
messages. The same code posting to a non HTTPS URL works. The code populates 
the request body using a NameValuePair array."
"HTTPCLIENT-546","BUG","BUG","MultiThreadedHttpConnectionManager setMaxTotalConnections() method doesn't work","The deprecated setMaxTotalConnections() method in the
MultiThreadedHttpConnectionManager seems like it has no effect:

Here is the source code in the current version:

    public void setMaxTotalConnections(int maxTotalConnections) {
        this.params.getMaxTotalConnections();
    }

Shouldn't it look more like this?

    public void setMaxTotalConnections(int maxTotalConnections) {
        this.params.setMaxTotalConnections(maxTotalConnections);
    }"
"HTTPCLIENT-368","RFE","BUG","[PATCH]character encoding handling is invalid at multipart","Hi,

Commons-Httpclient handle character encoding incorrect at multipart. This is 
significant problem for other than English people like me. Multipart has two 
encoding. First is header encoding which specify header of each part. Second 
is it's body encoding. Body encoding works well but header encoding is fixed 
as 'asc-ii'. This problem user following situation.

* upload file which file name is described by other than ""asc-ii"".
* use parameter which include other than ""asc-ii"" character.

Unfortunately , It seems RFC doesn't define header encoding for multipart but 
a lot of people needs set header encoding for thier own laungage. I attached
the patch. Please fix this problem.

regards,

Takashi Okamoto"
"HTTPCLIENT-460","RFE","IMPROVEMENT","Windows specific implementation of the Digest auth scheme","Microsoft Windows 2003 implementation of digest auth scheme is essentially a
superset of RFC 2617 with Windows specific aspects:
http://www.microsoft.com/technet/prodtechnol/windowsserver2003/library/TechRef/717b450c-f4a0-4cc9-86f4-cc0633aae5f9.mspx

Provide a super class of DigestScheme with Windows 2003 specific extensions,
which can be plugged in instead of the standard Digest impl

For details see PR #34909"
"HTTPCLIENT-29","RFE","BUG","shouldn't throw exception on bad cookies","Currently, HttpClient throws Exception on bad cookie. This is not expected. The 
user will expect HttpClient to ignore such cookies, but not getting an 
exception. Once exception is throw, user has no way to know if he can continue."
"HTTPCLIENT-616","BUG","BUG","HttpMethodDirector.executeWithRetry method fails to close the underlying connection if a RuntimeException is thrown","The following code snippet is from the end of the HttpMethodDirector.executeWithRetry method:

        } catch (IOException e) {
            if (this.conn.isOpen()) {
                LOG.debug(""Closing the connection."");
                this.conn.close();
            }
            releaseConnection = true;
            throw e;
        } catch (RuntimeException e) {
            if (this.conn.isOpen) {                                             <<<===========================   BAD!  :-)
                LOG.debug(""Closing the connection."");
                this.conn.close();
            }
            releaseConnection = true;
            throw e;
        }

When an IOException is caught, you can see that the ""open"" status of the connection is accurately checked by calling the ""isOpen()"" method.

When a RuntimeException is caught, however, the code mistakenly checks only the ""isOpen"" member field.  In the case where ""conn"" is, for example, a MultiThreadedHttpConnectionManager, the ""isOpen()"" method is overridden to check for a wrapped connection and returns the ""isOpen"" status of that connection.  In cases like that checking the ""isOpen"" member field is obviously wrong and we end up not calling ""close()"" and the connection is not cleaned up.  This causes issues with later calls.

A very difficult bug to diagnose and <steps up on soapbox> one that could have been easily avoided by making member variables private! <steps down>  thank you.  :-)


"
"HTTPCLIENT-314","BUG","BUG","New socket timeout value wont have effect if connection is reused","Reported by Teemu Tingander <Teemu.Tingander at tecnomen.fi> on The Jakarta
Commons HttpClient Developer List:

<snip>
Changing read timeout ()wont affect after successful method execution using
same connection.. 

This seems to be a bug in HttpClient class method
executeMethod(HostConfiguration ...)..

The problematic section seems to be if section checking if connection is
open
	
		method.setStrictMode(strictMode);
        		        
            if (!connection.isOpen()) {                
                connection.setConnectionTimeout(connectionTimeout);
-->		    connection.setSoTimeout(soTimeout);
                connection.open();
                if (connection.isProxied() && connection.isSecure()) {
                    method = new ConnectMethod(method);
                }
            }
 
Problem can be solved by moving the line out of if section

		method.setStrictMode(strictMode);

		connection.setSoTimeout(soTimeout);	
        		        
            if (!connection.isOpen()) {                
                connection.setConnectionTimeout(connectionTimeout);
                connection.open();
                if (connection.isProxied() && connection.isSecure()) {
                    method = new ConnectMethod(method);
                }
            }
</snip>"
"HTTPCLIENT-701","DOCUMENTATION","BUG","Cookie guide lists RFC 2965 as unsupported","HttpClient 3.1 added support for RFC 2965 (port-sensitive cookies), but the Cookie guide on the 3.x website still lists that as unsupported.
http://jakarta.apache.org/httpcomponents/httpclient-3.x/cookies.html

cheers,
  Roland
 "
"HTTPCLIENT-162","RFE","BUG","Realm from authentication challenge unavailable","There is currently no way to extract the authentication realm from HttpClient 
except to extract the authentication challenge header and parse it manually.

Either the realm needs to be available to the client or a method in 
Authenticator should extract the realm from a given authentication header.

The same problems occurs with determining which type of authentication is 
being used and what other options there are (basic, digest, NTLM, others)."
"HTTPCLIENT-1053","BUG","BUG","Security issue - DigestScheme uses constant nonce count value","The nonce count value in DigestScheme is static (set to 00000001) and never changes.  (also seen as comment in said file).

This means that it fails against servers that correctly detect man-in-the-middle or replay attacks, leading to additional 401 requests (every second time), or such servers must be configured to turn such checks off (which is either poor security or poor for performance).

I suggest that at minimum, this count is incremented for every call to DigestScheme#createDigest.  It should also be an instance variable instead of a static, as it really relates to the challenge (assuming cases where instances are cached for reuse).  AtomicInteger is a good choice for implementing this counter.

See RFC 2617 chapters 3.2.2 and 3.2.3"
"HTTPCLIENT-158","BUG","BUG","Empty response body is not properly handled when chunked encoding is used","IIS 5.0 server, when returning no content in response to an HTTP/1.1 request,
still includes ""Transfer-Encoding: chunked"" response header. As HttpClient
always expects chunk-encoded stream to be properly terminated, an
HttpRecoverableException exception results, when no content is sent back

=====================================================================

POST /someurl.aspx HTTP/1.1
Content-Length: 1132
Host: xxx.xxx.xxx.xxx
User-Agent: Jakarta Commons-HttpClient/2.0alpha2
Content-Type: multipart/form-data; boundary=----------------314159265358979323846

------------------314159265358979323846
Content-Disposition: form-data; name=""nmFile""; filename=""xxxxxxxxx.xml""
Content-Type: application/octet-stream

<... content removed ...>

------------------314159265358979323846--

HTTP/1.1 200 OK
Server: Microsoft-IIS/5.0
Date: Sat, 08 Feb 2003 15:22:26 GMT
Transfer-Encoding: chunked
Cache-Control: private
Content-Type: text/html

=====================================================================

Bug reported by Jim Crossley"
"HTTPCLIENT-502","BUG","BUG","HttpConnection isOpen flag concurrency problem","The HttpConnection.java class contains an isOpen boolean used to track the state
of the connection (opened or closed).  The problem is that in the
closeSocketAndStreams(), the flag is only flipped at the end of the
unsynchronized method (after resources have been released) which causes a
concurrency issue in flushRequestOutputStream() where the flag is checked first
and the the outputStream is accessed.

I'm providing a patch for this problem."
"HTTPCLIENT-32","IMPROVEMENT","BUG","querystring still not set in Url*Method constructors","The queryString is still not set in various Url*Method's constructors. It does 
get set in setUrl. The simplest fix is to call setUrl in these constructors."
"HTTPCLIENT-544","BUG","BUG","Digest auth uses incorrect URI","This bug seems to be strongly related to #36918. But in this case, I don't have 
proxy and it is GET method.

The problem is that when a GET request with query parameters is sent to the 
server, uri does not count in the parameters.  The server (Apache 1.3) then 
responds with HTTP/1.1 400 Bad Request. In the error log, the server writes:  
Digest: uri mismatch - </query.cgi> does not match request-uri 
</query.cgi?format=advanced&js=1&rememberjs=1>

As far as I can tell, the problem is with the following line of code:
------------ cut DigestScheme.java
public String authenticate(Credentials credentials, HttpMethod method)
....
getParameters().put(""uri"", method.getPath());
....
------------ cut

I am inclined to quick-hack this and add method.getQueryString() to the uri; 
but to make it right it probably needs some refactoring, esp. considering issue 
#36918."
"HTTPCLIENT-389","RFE","IMPROVEMENT","Provide Date Header Util Methods","Hello,

It would be really nice to have util methods that help with setting date
headers.  For instance, like the servlet spec's setDateHeader() method.  This
allows for the client of HttpClient to not have to deal with formatting the date
into the correct string.  There is a parseDate method that turns a String into a
Date.  It would be nice to have the opposite method.

Thanks!
Seth"
"HTTPCLIENT-312","DOCUMENTATION","BUG","Update license terms","Copyright 1999-2003 The Apache Software Foundation.

   Licensed under the Apache License, Version 2.0 (the ""License"");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an ""AS IS"" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License."
"HTTPCLIENT-24","BUG","BUG","Exception shouldn't be thrown for unsupported authentication method","Currently, Authenticator will throw an UnsupportedOperationException for 
unsupported authentication method (like NTLM). This is correct. However,  
HttpMethodBase.execute only catches HttpException, so this 
UnsupportedOperationException is leaked to the user. This is undesirable, 
because user may want a chance to handle such such authentication themself. The 
correct way is to pass the http status code to the user, just like how it 
treats redirect to a different host.

The simple fix is to catch all exceptions in HttpMethodBase.execute when 
calling Authenticator.authenticate."
"HTTPCLIENT-630","DESIGN_DEFECT","BUG","URI.java readObject()/writeObject() must be private","In the class org.apache.commons.httpclient.URI, the readObject/writeObject methods are currently protected - they need to be private, or Java will not invoke them."
"HTTPCLIENT-485","IMPROVEMENT","BUG","Connection is not released back to the pool if a runtime exception is thrown in HttpMethod#releaseConnection method","the default config of leaving the HttpClientParams.CONNECTION_MANAGER_TIMEOUT as zero means 
that the first time the connection manager fails to immediately get a connection you application hangs. 
(at least using MultiThreadedHttpConnectionManager.)

this is because the zero gets passed onto a call to Object.wait(long timeout) and, from the docs, ""If 
timeout is zero, however, then real time is not taken into consideration and the thread simply waits 
until notified."". 

since nothing ever ""notify()""s the thread everything just stops...

the default behaviour of the client more should be more predictable. you don't expect it to hang your 
entire app if it can't get a connection, you expect it to timeout then throw an exception or give some 
other kind of feedback.

it would make sense to give a default of, say, arbitrarily, 10 seconds or so. this would save every single 
user of the classes having to dig around in the code/documentation and explictly set this param. they 
might decide that the default value isn't right and hence change it, but that's tweaking behaviour, not 
correcting it. i certainly thought it was a bug in the code (yours or mine), not my config and have been 
fretting around it for a while.

best,
garry"
"HTTPCLIENT-377","DOCUMENTATION","BUG","[API Doc] HttpClient tutorial update","Bring the tutorial up to date with the latest best practices"
"HTTPCLIENT-98","BUG","BUG","PUT method blocks against older servers","To reproduce, attempt a PUT request against an appropriate servlet under TC3.2
(yes I know that needs an upgrade - sigh)

RFC 2616 says:
""Because of the presence of older implementations, the protocol allows ambiguous
situations in which a client may send ""Expect: 100- continue"" without receiving
either a 417 (Expectation Failed) status or a 100 (Continue) status. Therefore,
when a client sends this header field to an origin server (possibly via a proxy)
from which it has never seen a 100 (Continue) status, the client SHOULD NOT wait
for an indefinite period before sending the request body.""

This isn't how HttpClient behaves. After sending the headers,
PutMethod.writeRequestBody() returns false. HttpMethodBase then calls
readStatusCode(), which blocks waiting for a read (or I guess you could time out
the whole request). Right now this makes it impossible to use HttpClient to PUT
to older Http 1.1 implementations.

A suggested resolution: since the spec allows for clients to avoid waiting if
they know the 100 response will not arrive, why not simply provide a boolean
flag to allow the 'wait for 100' behaviour in PutMethod.writeResponseBody() to
be turned off, on a per-request basis? This solution puts the burden of knowing
""origin server[s]...from which it has never seen a 100 (Continue) status"" on the
user of HttpClient. Less than perfect as you can only find out that this has
happened by trial and error.

A more correct solution, is to maintain a list of servers that ignore the Expect
header in PutMethod, and override PutMethod.readStatusCode() to time out, send
the body, remember this server is buggy, and read the status code again."
"HTTPCLIENT-420","RFE","IMPROVEMENT","Provide a non-pooling connection manager","The current implementations of the connection managers all have a connection
pool. For applications requiring only single requests very rarely this is
overkill. We should provide a very simple connection manager that uses a
connection only one time and then closes it right away."
"HTTPCLIENT-291","DOCUMENTATION","BUG","Cookie docs are outdated.","The cookie docs do not reflect the latest code changes."
"HTTPCLIENT-1014","RFE","RFE","ByteArrayBody as an alternative to InputStreamBody","InputStreamBody can not determine the content length, which in turn causes requests to be sent with a content length of 0, even though the content is there. .NET Servers have trouble dealing with this.

ByteArrayBody provides an alternative that alliviates this limitation.

Source:
 
import java.io.IOException;
import java.io.OutputStream;

import org.apache.http.entity.mime.MIME;
import org.apache.http.entity.mime.content.AbstractContentBody;

/**
 * Body part that is built using a byte array containing a file.
 * 
 * @author Axel Fontaine
 */
public class ByteArrayBody extends AbstractContentBody {
    /**
     * The contents of the file contained in this part.
     */
    private byte[] data;

    /**
     * The name of the file contained in this part.
     */
    private String filename;
    
    /**
     * Creates a new ByteArrayBody.
     * 
     * @param data The contents of the file contained in this part.
     * @param mimeType The mime type of the file contained in this part.
     * @param filename The name of the file contained in this part.
     */
    public ByteArrayBody(final byte[] data, final String mimeType, final String filename) {
        super(mimeType);
        if (data == null) {
            throw new IllegalArgumentException(""byte[] may not be null"");
        }
        this.data = data;
        this.filename = filename;
    }

    /**
     * Creates a new ByteArrayBody.
     * 
     * @param data The contents of the file contained in this part.
     * @param filename The name of the file contained in this part.
     */
    public ByteArrayBody(final byte[] data, final String filename) {
        this(data, ""application/octet-stream"", filename);
    }

    @Override
    public String getFilename() {
        return filename;
    }

    @Override
    public void writeTo(OutputStream out) throws IOException {
        out.write(data);
    }

    @Override
    public String getCharset() {
        return null;
    }

    @Override
    public String getTransferEncoding() {
        return MIME.ENC_BINARY;
    }

    @Override
    public long getContentLength() {
        return data.length;
    }
}
"
"HTTPCLIENT-665","REFACTORING","IMPROVEMENT","Change access to internal maps of HttpState to protected.","To be able to serialize the conversational state of a http session access to the internal maps of HttpState is required. Currently they are all ""private"", so subclasses cannot access them. Changing the access to ""protected"" will allow any subclass to access those maps."
"HTTPCLIENT-692","BACKPORT","IMPROVEMENT","ClientConnectionManager should throw InterruptedException","For historical reasons, ThreadSafeClientConnectionManager throws an IllegalThreadStateException instead of an InterruptedException if the waiting thread is interrupted from outside. This design was chosen since adding InterruptedException to the HttpConnectionManager in 3.x would have broken the API. This is not a concern for HttpClient 4.0.
"
"HTTPCLIENT-500","DOCUMENTATION","BUG","Dependency URL broken for commons-logging","On http://jakarta.apache.org/commons/httpclient/dependencies.html there is a 
typo in the href to the logging dependency, this should be

http://jakarta.apache.org/commons/logging/"
"HTTPCLIENT-13","BUG","BUG","empty path not handled correctly","When requesting for a URL which has an empty path, e.g. http://abcnews.go.com ,
the code sends the following line:

GET  HTTP/1.1

which should be

GET / HTTP/1.1

instead"
"HTTPCLIENT-217","RFE","IMPROVEMENT","httpMethod.abort needed","This is the problem : I use the httpclient to fire many requests. At some point 
of time, the server has queued up requests. So certain requests are waiting for 
response. Now when I call httpMethod.releaseConnection, the request should stop 
waiting for the response and the connection should be closed. However, this 
does not happen. The request is only given up after it has timed out."
"HTTPCLIENT-290","BUG","BUG","MS Proxy with NTLM authentication set up does not work","When I try to go via a MS Proxy which is set up with NTLM authentication I
always get a ""407"" error, no matter which credentials used."
"HTTPCLIENT-1132","RFE","RFE","porting of ProxyClient from 3.1 to 4.x API","With 3.1 version of HttpClient it was possible to establish a tunneled connection to a generic non http server through an authenticated proxy, but since 3.1 version does not support NTLMv2 and Kerberos authentication, that are supported in 4.x version, it is very useful to port the features provided by ProxyClient to 4.x API."
"HTTPCLIENT-670","RFE","RFE","add an interface for plugable dns clients","Currently Httpclient implicitly uses InetAddress.getByName() for DNS resolution.
This has some drawbacks. One is that the DNS cache of Java per default caches entries forever.

So I'd like to be able to replace InetAddress.getByName() with another DNS client implementation.

"
"HTTPCLIENT-289","BUG","BUG","MultiThreadedHttpConnectionManager daemon Thread never GC'd","One of my colleagues was invoking HttpClient by way of a loop something like this:

for (int i = 0; i < 300; i++) {
    GetMethod method = new
GetMethod(""http://cvs.apache.org/viewcvs/jakarta-commons/httpclient/"");
    try {
        HttpClient httpClient = new HttpClient(new
MultiThreadedHttpConnectionManager());
        httpClient.executeMethod(method);
        byte[] bytes = method.getResponseBody();
    } finally {
        // always release the connection after we're done
        method.releaseConnection();
    }
}

He's in the process of revising his code so that he doesn't do this loop, which
other developers might point out as a non-optimal use, but along the way, he
discovered that the daemon thread that the MultiThreadedHttpConnectionManager
makes does not get garbage collected.  Of course, the connection manager itself
is also never gc'd.  While I think we can avoid this problem in our code, in the
more general case, clients may not actually be able to control the number of
MultiThreadedConnectionManagers they create, which could eventually cause
problems.  This makes me think the problem is deserving of a patch.

We found this problem with 2.0rc2, although presumably it also exists with the
CVS HEAD.

Patch to follow."
"HTTPCLIENT-538","DOCUMENTATION","IMPROVEMENT","New PostSOAP example (for src/examples)","I have a slightly modified version of PostXML which invokes SOAP requests. The
only difference to PostXML is that PostSOAP takes the SOAPAction as an extra
commndline arg and adds that as a header into the request."
"HTTPCLIENT-1172","BUILD_SYSTEM","","LocalTestServer and supporting classes should be available as a separate jar","LocalTestServer and it's supporting classes are useful to anyone who wants to easily ""mock""/test simple http calls without having to embed a full jetty or something.
It would be awesome if these were available in a separate http-localtestserver.jar that could be used in projects outside of httpclient."
"HTTPCLIENT-740","IMPROVEMENT","IMPROVEMENT","AbstractConnPool constructor calls thread.Start()","AbstractConnPool constructor calls thread.Start()

Findbugs says:

Constructor invokes Thread.start()

The constructor starts a thread. This is likely to be wrong if the class is ever extended/subclassed, since the thread will be started before the subclass constructor is started.

The class is not final (and the constructor is protected) which suggests that the class is intended to be extended..."
"HTTPCLIENT-322","TEST","IMPROVEMENT","Deprecate and replace SimpleHttpConnection with the SimpleHttpServer based testing framework","Thanks to Christian Kohlschuetter and Odi we now have a very flexible testing
framework, which enables us to emulate pretty much all the aspects of a HTTP
server functionality including non-compliant behavior and various vendor
specific implementation quirks. 

Many, many thanks go to Christian Kohlschuetter for having contributed the
original code. 

I propose SimpleHttpConnection be deprecated and eventually be phased out. I
took the first steps toward this goal by migrating Basic authentication test
cases. I urge all committers and contributors to use SimpleHttpServer for all
the new cases from now on. Ideally in the future we should even be able to get
rid of Tomcat as a dependency for testing.

I also took liberty of tweaking the SimpleHttpServer API a little. I factored
SimpleRequest and SimpleResponse classes out and provided a new interface called
HttpService, which can be used instead of HttpRequestHandler to implement test
cases in a way very similar to writing servlets. 

I'll commit the patch shortly as it does not really touch any _productive_ code. 

Oleg"
"HTTPCLIENT-157","IMPROVEMENT","BUG","migrate to commons-codec Base64","Commons Codec is now the authoritative source for Base64 functionality.  The
Base64 in HttpClient is now deprecated and should be removed in 2.1.  This will
also add a new dependancy for HttpClient on the commons-codec package."
"HTTPCLIENT-635","BUG","IMPROVEMENT","Port fix for HTTPCLIENT-633 to 4.0","The fix for MultiThreadedHttpConnectionManager from HTTPCLIENT-633 should be ported to ThreadSafeClientConnManager in 4.0."
"HTTPCLIENT-1122","BUG","BUG","NPE in RequestProxyAuthentication on Android","Got a NPE backtrace in RequestProxyAuthentication.process(). 

HttpRoute route = conn.getRoute();
        if (route.isTunnelled()) {      <= line 88, NPE here
            return;
        }

There's no null check on the returned route although getRoute() can return null.
I guess it's not supposed to happen.

In the httpclient code, there's a few more calls to getRoute() without a null check on the returned route.


java.lang.NullPointerException
at com.bubblesoft.org.apache.http.client.protocol.RequestProxyAuthentication.process(SourceFile:88)
at com.bubblesoft.org.apache.http.protocol.ImmutableHttpProcessor.process(SourceFile:108)
at com.bubblesoft.org.apache.http.protocol.HttpRequestExecutor.preProcess(SourceFile:174)
at com.bubblesoft.org.apache.http.impl.client.DefaultRequestDirector.execute(SourceFile:457)
at com.bubblesoft.org.apache.http.impl.client.AbstractHttpClient.createHttpProcessor(SourceFile:821)
                                                                 execute
at com.bubblesoft.org.apache.http.impl.client.AbstractHttpClient.createHttpProcessor(SourceFile:755)
                                                                 execute
at com.bubblesoft.org.apache.http.impl.client.AbstractHttpClient.createHttpProcessor(SourceFile:733)
                                                                 execute
"
"HTTPCLIENT-401","RFE","BUG","HttpState should have methods for clearing all cookies and credentials"," "
"HTTPCLIENT-66","RFE","IMPROVEMENT","RFC 2965 Support (Port sensitive cookies)","RFC 2109 doesn't consider port numbers when matching and filtering cookies. RFC
2965 does. Modify the Cookie class so that it (optionally?) supports RFC 2965,
while maintaining support for RFC 2109-style (portless) cookies."
"HTTPCLIENT-426","IMPROVEMENT","BUG","httpclient doesn't read and parse response from certain types of proxy servers when POST method is used","It was determined that when sending post data to server via Squid proxy server
of version 2.4.STABLE2 and Squid responds 
with ""407 proxy authentication required"" response, httpclient doesn't read this
response in order to parse, but rather
fails with soket exception ""java.net.SocketException: Software caused connection
abort: recv failed"".

This behaviour is reproduced with the latest nigtly build of httpclient version
3.0. (from 9 of February 2005) as
well as 3.0. RC1, 2.0.2 and 2.0.

This is the piece of code that sends post data using httpclient:

try
{
	HttpClientParams httpClientParams = new HttpClientParams();
	HttpClient client = new HttpClient(httpClientParams);

	HostConfiguration hostconfig = new HostConfiguration();
	hostconfig.setProxy(""db00-devl.eps.agfa.be"", 3128); // SQUID proxy server
version 2.4.STABLE2
	client.setHostConfiguration(hostconfig);
	PostMethod postMethod = new
PostMethod(""http://brugge.eps.agfa.be/portal03/servlet/selectFiles"");

	postMethod.addParameter(""data"", ""some data"");
	int status = client.executeMethod(postMethod);
	System.out.println(""status = "" + status);
	if (status == HttpStatus.SC_OK)
		System.out.println(""Ok"");
	else if (status == HttpStatus.SC_PROXY_AUTHENTICATION_REQUIRED)
		System.out.println(""Proxy authentication required."");
}
catch (Exception e)
{
	System.out.println(""Socket exception."");
	e.printStackTrace();
}

Look at ""debug log of the problem"" attachment to see all output from httpclient
and mentioned piece of code.
In ""problem_request_response_interaction"" attacment it is possible to see
interaction beetween httpclient and Squid proxy server: httpclient sends initial
request and headers, then squid responds with ""proxy authentication required""
response and afterwards httpclient tries to send post data(without reading the
response) but fails because connection is already closed.

For more details look at ""ethereal_problem"" attachment for all network traffic
during running of mentioned piece of code:
Ethereal protocol analyzer can be used to open this file(http://www.ethereal.com/).

Most likely this particular version of Squid closes connection after it sends
proxy athentication response back,
which causes httpclient to fail while sending post data.

Let's have a look at what writeRequest(...) method of HttpMethodBase class does:

1) sends request line and headers to server,
2) handles 'Expect: 100-continue' handshake if needed,
3) sends post data to server.

My question is should HTTPClient send initial request and headers before data
even if it is not going to read 
a response from the server(proxy server), or this should be done only in case of
'Expect: 100-continue' handshake 
(this seems the only case when HTTPClient is going to listen to server
in-between of steps 1 and 3)?

My understanding is that the command

        // make sure the status line and headers have been sent
        conn.flushRequestOutputStream();
        
which actually splits sending of data in two parts are needed only for 'Expect:
100-continue' handshake case.
Just by moving ""flush"" command to appropriate place inside 'Expect:
100-continue' handshake case:
		.....
                try {
	            conn.flushRequestOutputStream(); // moved
                    conn.setSocketTimeout(RESPONSE_WAIT_TIME_MS);
		.....
it is posible to solve described problem.

I created PostMethodEx that overrides writeRequest(...) method of
HttpMethodBase(look at ""PostMethodEx"" attachment) 
and for all cases but the 'Expect: 100-continue' handshake it sends request
line, headers and post data to server 
at once.

When mentioned piece of code(with PostMethod changed to PostMethodEx) is
executed everyting works fine:
look at ""debug log of the fix"", ""fix_request_response_interaction"" and
""ethereal_fix""(all network trafic) 
attachments.

According to mentioned logs httpclient sends all post data at once and then
reads and parses ""proxy authentication required"" 
response from squid and sets status code to 407. Correct."
"HTTPCLIENT-834","RFE","RFE","Transparent Content Coding support","I would like to see HttpClient features brought up to parity with other libraries, both in Java and other languages. c.f. Python's httplib2 (not yet in the standard library, but many would like to see it in there). That library transparently handles gzip and compress content codings.

This issue is to capture possible solutions to providing this sort of innate functionality in HttpClient, so that users aren't required to know RFC2616 intimately. The HttpClient library should do the right thing and use the network in the most efficient manner possible."
"HTTPCLIENT-625","RFE","IMPROVEMENT","shutdown of MultiThreadedHttpConnectionManager","- declare 'shutdown' attributes volatile
- interrupt cleanup thread to avoid polling
- don't use iterator on WeakHashMap, ConcurrentModificationException
  might be triggered by garbage collection

patch follows
"
"HTTPCLIENT-517","DOCUMENTATION","IMPROVEMENT","Cookie Documentation clarifications","The JavaDoc for CookieSpec mentions that the default policy is RFC2109 - it
would be nice if this was mentioned on
http://jakarta.apache.org/commons/httpclient/cookies.html as well
(likewise for 2.0)

The Javadoc for getDefaultPolicy() says to use getCookieSpec(String); it would
be better to say to use getCookieSpec(DEFAULT), and it would be helpful to
mention getDefaultSpec().

CookiePolicy Javadoc does not mention the IGNORE_COOKIES policy in the header
documentation.

The cookies.html page mentions automatic and manual handling of cookies, but
does not provide any links as to how to control these. For example, how does one
turn off automatic cookie handling?"
"HTTPCLIENT-917","IMPROVEMENT","BUG","When authentication is invalidated during redirection, proxy authentication also should be invalidated","This was discovered during use by Lucene Connector Framework, on 3.1.

When a document is fetched through a proxy authenticated with NTLM, and
that document is a redirection (301 or 302), the httpclient fails to
properly use the right proxy credentials on the subsequent document
fetch. This leads to 407 errors on these kinds of documents.

I've attached a proposed patch.
"
"HTTPCLIENT-132","RFE","IMPROVEMENT","New Preferences Architecture","An architectural solution is needed to configure various aspects of HttpClient,
Methods and Connections. 

Features:
- can configure certain properties per request / per connection
- all configuration is done in a consistant way 
- do not use system properties
- configuration is completely optional: default values should be used if no
configuration is made

This is a refactoring request / reminder. File configuration issues as
dependencies of this bug."
"HTTPCLIENT-901","RFE","IMPROVEMENT","Add a ContextAwareAuthScheme that has access to the HttpContext in the authenticate method","The interface to be added would be:

/**
 * This interface represents an extended  authentication scheme
 * that requires access to {@link HttpContext} in order to
 * generate an authorization string.
 *
 * @since 4.1
 */

public interface ContextAwareAuthScheme extends AuthScheme {

    /**
     * Produces an authorization string for the given set of
     * {@link Credentials}.
     *
     * @param credentials The set of credentials to be used for athentication
     * @param request The request being authenticated
     * @param context HTTP context
     * @throws AuthenticationException if authorization string cannot
     *   be generated due to an authentication failure
     *
     * @return the authorization string
     */
    Header authenticate(
            Credentials credentials,
            HttpRequest request,
            HttpContext context) throws AuthenticationException;

}

Binary compatibility can be maintained by doing an instanceof check at the location where AuthScheme.authenticate() is called at the moment, and calling the context aware version if available.

This interface is necessary for the NegotiateScheme authentication scheme because the service names for the authentication tickets are based on the hostname of the target host or proxy host, depending on whether it's normal or proxy authentication, and this information is only available from the HttpContext.

Without the HttpContext there is a workaround that works most of the time, which looks like this:

	String host;
	if (isProxy()) {
		// FIXME this should actually taken from the HttpContext.
		HttpHost proxy = ConnRouteParams.getDefaultProxy(request.getParams());
		host = proxy.getHostName();
	} else {
		host = request.getLastHeader(""Host"").getValue();
	}

"
"HTTPCLIENT-335","RFE","BUG","Handling sub-domain cookies.","I noticed a difference in behaviour between httpclient and most common browsers 
(IE/Mozilla). If a web site sets a cookie for ""beta.gamma.com"", this cookie is 
not sent in requests to ""alpha.beta.gamma.com"". 
  I am not sure what the cookie specs say, but Mozilla, IE and even 
HTTP::Cookies module in LWP seem to behave differently from HttpClient. 
HttpClient seems to rely on the leading dot in the domain name 
(like "".beta.gamma.com"")."
"HTTPCLIENT-135","BUG","BUG","Possible HttpClient codepage issue (ascii/ebcdic) on WebSphere z/OS","I am working with Cactus 1.4.1 on WebSphere NT and also WebSphere z/OS
(mainframe). The problem seems to be with HTTPClient. I have tried with the
nuild on the 7th December.

I am trying to get basic cactus servlet tests working on WebSphere z/OS.
Everything works fine through WebSphere NT, however, when the same application
is deployed to WebSphere z/OS then we get the following error:

<?xml version=""1.0"" encoding=""UTF-8"" ?><?xml-stylesheet type=""text/xsl""
href=""junit-noframes.xsl""?><testsuites><testsuite name=""TestCactusServlet""
tests=""1"" failures=""0"" errors=""1"" time=""10.184""><testcase name=""testNeal""
time=""10.182""><error message=""Error in parsing the status  line from the
response: unable to find line starting with &quot;HTTP/&quot;""
type=""org.apache.commons.httpclient.HttpRecoverableException"">org.apache.commons.httpclient.HttpRecoverableException:
Error in parsing the status  line from the response: unable to find line
starting with &quot;HTTP/&quot;
	at
org.apache.commons.httpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1791)
	at
org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1559)
	at
org.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBase.java:2219)
	... etc ...

I have verified that the Application Server on WebSPhere z/OS is working fine. I
set the logging on the cactus to DEBUG and noticed that the data that the
HTTPClient is retrieving from the connection is scrambled in some way. For example:

16:06:20,213 [WebSphere t=009d7920] DEBUG ent.HttpClientConnectionHelper  -
>getCookieString = [null] 
16:06:20,317 [WebSphere t=009d7920] DEBUG httpclient.wire                 - >> ""@a??? etc...

On WebSphere NT the data at this point looks OK.

What springs to mind is maybe ascii/ebcdic conversion problem. z/OS uses unicode
 for java, as it should. However, the HTTPClient creates it own socket
connection to the app server and therefore it is connecting to non java code. In
such a situation codepage conversion is necessary.

Could anybody adsvise on how to get this to work?

Regards,

Neal Johnston-Ward"
"HTTPCLIENT-930","BUG","BUG","Unencoded redirect URI causes exception when following redirects","When HttpClient is set to follow redirects, the DefaultRedirectHandler gets the redirect location from the appropriate request header and attempts to create a new java.net.URI from it. If the location contains an invalid URI character, creating the URI fails. For example, if the redirect location were ""/foo?bar=<baz/>"", it would fail because the '<' and '>' are not legal in a URI.

I'm not sure if this should actually be considered a bug in HttpClient, since the website in question should probably be responsible for encoding the URI appropriately; however, browsers handle the situation gracefully, and it would be nice if this excellent library would do so as well."
"HTTPCLIENT-445","BUG","BUG","304 response status handling","I have an IBM WebSphere server that returns 304 responses with a Content-
Length header set to something other than 0 and the server is not closing the 
connection.  According to the HTTP RFC 
(http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.5):

""The 304 response MUST NOT contain a message-body, and thus is always 
terminated by the first empty line after the header fields.""

Obviously, the web server is returning a bad response but the HTTPClient 
blocks waiting on data in the response even though there shouldn't be any.  
Other HTTP clients (browsers) do not have this issue and seem to ignore the 
fact that the server set an invalid Content-Length in the response."
"HTTPCLIENT-223","BUG","BUG","URI path resolution problems.","URI does not completely conform to RFC 2396.  In particular it does not handle the following 
relative URIs correctly:

../../../g
../../../../g"
"HTTPCLIENT-1039","BUG","BUG","AbstractHttpClient.determineTarget does not recognize target host correctly","I am trying to execute an HttpGet with the following URI:
""http://www.foo.foo/doSomething.html?url=http://www.bar.bar/doSomethingElse.html""

This leads to UnknownHostException

Going through the internal code, the problem seems to be in the AbstractHttpClient.determineTarget method:
            String ssp = requestURI.getSchemeSpecificPart();
            ssp = ssp.substring(2, ssp.length()); //remove ""//"" prefix
            int end = ssp.indexOf(':') > 0 ? ssp.indexOf(':') :
                    ssp.indexOf('/') > 0 ? ssp.indexOf('/') :
                    ssp.indexOf('?') > 0 ? ssp.indexOf('?') : ssp.length();
            String host = ssp.substring(0, end);

This code sets the target host to ""www.foo.foo/doSomething.html?url=http"" instead of ""www.foo.foo"". This obviously breaks the execution not far down the line... DefaultClientConnectionOperator.resolveHostname throws an UnknownHostException.

FWIW the AbstractHttpClient.determineTarget method actually has access to the request URI object, which correctly states that the host is ""www.foo.foo"".

So why does it try to extract the host from the scheme specific part anyway?

I hope this is useful... and if there is any workaround please let me know, as I'm stuck on this one.

Marco"
"HTTPCLIENT-1103","BUG","BUG","GzipDecompressingEntity (and therefore ContentEncodingHttpClient) not consistent with EntityUtils.consumeEntity","Invoking EntityUtils.consume( entity ) after a previous call to entity.getContent (and subsequent processing of the content) throws a java.io.EOFException when gzip decompression support is enabled via ContentEncodingHttpClient or some similar mechanism.  I invoke EntityUtils.consume in a 'finally' block - maybe I'm not using the API correctly ... ?  

java.io.EOFException
	at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:207)
	at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:197)
	at java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:136)
	at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:58)
	at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:68)
	at org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)
	at org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:88)
	at org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)

I believe the problem is that the underlying DecompressingEntity allocates a new GzipInputStream for each call to getContent, rather than caching the stream created by the first getContent call.  
       http://svn.apache.org/repos/asf/httpcomponents/httpclient/trunk/httpclient/src/main/java/org/apache/http/client/entity/DecompressingEntity.java
The ""CustomProtocolInterceptors"" example has the same bug:  http://hc.apache.org/httpcomponents-client-ga/examples.html

I worked around the problem implementing the example with my own GzipDecompressingEntity (scala code - lazy value not evaluated till accessed):

  class GzipDecompressingEntity( entity:http.HttpEntity) extends http.entity.HttpEntityWrapper(entity) {
    private lazy val gzipStream = new GZIPInputStream( entity.getContent() )
    
    /** 
     * Wrap entity stream in GZIPInputStream
     */
    override def getContent():java.io.InputStream = gzipStream

    /**
     * Return -1 - don't know unzipped content size
     */
    override def getContentLength():Long = -1L
  }

"
"HTTPCLIENT-547","RFE","IMPROVEMENT","Provide access to port of Host header","We use a load balancer that connects to the HTTP server and the HTTP server
connects to the application server. We use port translation in our load
balancer. So when e.g. a client connects to 90 of the load balancer, the load
balancer connects to port 100 of the HTTP server. The load balancer doesn't
change the Host request header, so in the host request header is still the
original virtual host name and port, in this case port 90. For this reason, the
virtual hosts of the HTTP server and application server are configured based on
the external port numbers, so in this case port 90.
 
For test purposes, we sometimes want to connect directly to the HTTP server or
the application server, bypassing the load balancer. To do this, we need to
connect to the same port as the load balancer would, in this example port 100,
but the host header of this request should be the same as if the request would
go through the load balancer, so in this example port 90, because the HTTP
server and application server's virtual hosts are configured for this port.

The attached patch adds the possibility to specify the port number for virtual
hosts.

Here's a code snippet that uses the patched code:

HttpClient httpClient = new HttpClient();
HttpMethod method = new GetMethod();
HostConfiguration hostConfiguration = new HostConfiguration();
hostConfiguration.setHost(""localhost"", 80, ""http"");
HostParams params = new HostParams();
params.setVirtualHost(""localhost"");
params.setVirtualHostPort(100);
hostConfiguration.setParams(params);
httpClient.executeMethod(hostConfiguration, method);
System.out.println(method.getResponseBodyAsString());
method.releaseConnection();"
"HTTPCLIENT-889","IMPROVEMENT","","Should USE_EXPECT_CONTINUE be false by default?","It seems the point of USE_EXPECT_CONTINUE is to improve performance when posting large data. 
http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html says:

<< The purpose of the 100 (Continue) status (see section 10.1.1) is to allow a client that is sending a request message with a request body to determine if the origin server is willing to accept the request (based on the request headers) before the client sends the request body. In some cases, it might either be inappropriate or highly inefficient for the client to send the body if the server will reject the message without looking at the body. >>

There's nothing wrong with HttpClient performing well by default, however, every other HTTP client library I've used does not behave like this (PHP curl, Perl LWP). The default is always to do one request, including the body. Maybe dumb, but simple.

It seems to me HttpClient's default behavior should the simplest, most compatible with all HTTP-speaking services out there. ""100 Continue"" is somewhat advanced, and may not be correctly implemented by all services. (That's of course how I found out about it -- my server doesn't implement it.)

If USE_EXPECT_CONTINUE is used only for performance reasons, it seems like it would be simpler (and therefore maybe more ""correct"") to have it ""off"" by default. And only enable it when needed, when there is a good reason to.

Just my thoughts. And a wish. Thanks! 


"
"HTTPCLIENT-832","IMPROVEMENT","IMPROVEMENT"," MalformedCookieException: distinguish cookie syntax errors from cross-domain errors","MalformedCookieException is used for both cookies with syntax errors,
and for cookies which are invalid for the particular context - e.g.
cross-domain cookies.

I think it would be helpful to be able to distinguish these without
needing to examine the message text."
"HTTPCLIENT-860","BUG","BUG","DefaultRequestDirector converts redirects of PUT/POST to GET for status codes 301, 302, 307","The DefaultRequestDirector treats redirect requests created by all redirect status codes (HttpStatus.SC_MOVED_TEMPORARILY: , HttpStatus.SC_MOVED_PERMANENTLY, HttpStatus.SC_SEE_OTHER, HttpStatus.SC_TEMPORARY_REDIRECT) the same, converting PUT/POST methods to GET.  The HttpClient Tutorial even documents this as being in accordance with the specification, but I don't believe that's true.

Per the RFC (http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html), conversion of PUT/POST to GET is appropriate only for 303 (See Other).  The others do not suggest this behavior.  In fact, the following notes attached to them call it out as incorrect.

301 (Moved Permanently) has this note:

      Note: When automatically redirecting a POST request after
      receiving a 301 status code, some existing HTTP/1.0 user agents
      will erroneously change it into a GET request.

And 302 (Found) say this:

      Note: RFC 1945 and RFC 2068 specify that the client is not allowed
      to change the method on the redirected request.  However, most
      existing user agent implementations treat 302 as if it were a 303
      response, performing a GET on the Location field-value regardless
      of the original request method. The status codes 303 and 307 have
      been added for servers that wish to make unambiguously clear which
      kind of reaction is expected of the client.

The currently implemented behavior is causing problems with interacting with Central Authentication Service protected resources, among other things."
"HTTPCLIENT-1144","IMPROVEMENT","IMPROVEMENT","Caching client has a class for common headers that was not being used consistently in the code","The HttpCachingClient has a class called HeaderConstants that contains all the cache interesting headers that are used in the code base.  This class of string constants was not being used consistently in the code base.  The attached patch cleans this up."
"HTTPCLIENT-1033","IMPROVEMENT","BUG","HttpRoute.equals(Object o) is quite inefficient, as it does not take full advantage of shortcut logic","HttpRoute.equals(Object o) is quite inefficient, as it does not take full advantage of shortcut logic.

It should return as soon as the first  false is detected.

Patch to follow implements short-circuit checking."
"HTTPCLIENT-139","IMPROVEMENT","BUG","isHttp11 should have HttpClient scope","-----Original Message-----
From: Kalnichevski, Oleg [mailto:oleg.kalnichevski@bearingpoint.com] 
Sent: Wednesday, January 15, 2003 8:24 AM
To: Commons HttpClient Project
Cc: Rob Owen
Subject: RE: isHttp11 and HTTP/1.0 servers 

Rob
You are basically right hands down. It does make sense for the HTTP version 
flag to have HttpClient scope. We should address this shortcoming as a part of 
the post-2.0-release redesign

Feel free to file a bug report to make sure the issue does not go forgotten

http://nagoya.apache.org/bugzilla/enter_bug.cgi?product=Commons

Many thanks for bring it up

Cheers

Oleg

-----Original Message-----
From: Rob Owen [mailto:Rob.Owen@sas.com]
Sent: Monday, January 13, 2003 18:31
To: Commons HttpClient Project
Subject: isHttp11 and HTTP/1.0 servers 


The boolean variable http11 is set on a method by method basis. For PutMethod, 
decisions (eg. Expect: 100-continue request header) are made prior to 
determining the value for Http11 (chicken and egg problem) and so the default 
(true) is used to produce the request. An HTTP/1.0 server hangs waiting for 
the extra data on the PUT method body. 

For applications that are using HttpClient (ie. they do not manipulate the 
HTTP methods directly and cannot be expected to set the value of Http11 for 
each method instance), shouldn't http11 have HttpClient scope ? This would 
allow an interaction (eg. OPTIONS) to set http11 and all methods thereafter 
would use this setting?
  
------
Rob Owen
SAS Institute Inc.
email: Rob.Owen@sas.com"
"HTTPCLIENT-56","IMPROVEMENT","IMPROVEMENT","Move to commons-logging","Commons-logging was derived from httpclient.log, still using the old logging
which should be removed.  Some complaints on mailing list about setting up
commons-logging: should be simple and well documented."
"HTTPCLIENT-439","BUG","BUG","Authentication fails when connecting to server with username and password in non ascii characters","Tried connecting to an exchange server using NTLM authentication
Username : 
password : 

I am getting 401 response.
Auth failed
Body: 
Error: Access is Denied."
"HTTPCLIENT-1008","IMPROVEMENT","IMPROVEMENT","Send all variants' ETags on ""variant miss""","From section 13.6 of RFC 2616:

If an entity tag was assigned to a cached representation, the forwarded request SHOULD be conditional and include the entity tags in an If-None-Match header field from all its cache entries for the resource. This conveys to the server the set of entities currently held by the cache, so that if any one of these entities matches the requested entity, the server can use the ETag header field in its 304 (Not Modified) response to tell the cache which entry is appropriate. If the entity-tag of the new response matches that of an existing entry, the new response SHOULD be used to update the header fields of the existing entry, and the result MUST be returned to the client.

Presently, we simply forward the request to the request without the conditionals.  This improvement would consist of adding the conditionals to the request, and properly handling the response.  An example of such would be the following:

 - request resource with ""Accept-Encoding: gzip"", response has ""Etag: etag1"", ""Vary: Accept-Encoding""
 - request resource with ""Accept-Encoding: deflate"", request is forwarded with ""If-None-Match: etag1"" added, response is 200, with ""ETag: etag2""
 - request resource with ""Accept-Encoding: gzip, deflate"", request is forwarded with ""If-None-Match: etag1, etag2"" added, response is 304, with ""ETag: etag1"" indicating we should use the first response for this request"
"HTTPCLIENT-489","BUG","BUG","Request is retried if preemptive authentication fails","Hello,

I'm using premptive authentification from an Axis client using BASIC Http
authentification. When the user isn't authenticated/authorized by server (in my
case, credentials are expired), httpclient runs a ""Chalenge"" that produces a
second request to server with same credentials.

when using preemptive mode, chalenge should be skipped if authentication scheme
hasn't changed !"
"HTTPCLIENT-962","IMPROVEMENT","BUG","client cache may be a shared cache but is caching responses to requests with Authorization headers","""      When a shared cache (see section 13.7) receives a request
      containing an Authorization field, it MUST NOT return the
      corresponding response as a reply to any other request, unless one
      of the following specific exceptions holds:

      1. If the response includes the ""s-maxage"" cache-control
         directive, the cache MAY use that response in replying to a
         subsequent request. But (if the specified maximum age has
         passed) a proxy cache MUST first revalidate it with the origin
         server, using the request-headers from the new request to allow
         the origin server to authenticate the new request. (This is the
         defined behavior for s-maxage.) If the response includes ""s-
         maxage=0"", the proxy MUST always revalidate it before re-using
         it.

      2. If the response includes the ""must-revalidate"" cache-control
         directive, the cache MAY use that response in replying to a
         subsequent request. But if the response is stale, all caches
         MUST first revalidate it with the origin server, using the
         request-headers from the new request to allow the origin server
         to authenticate the new request.

      3. If the response includes the ""public"" cache-control directive,
         it MAY be returned in reply to any subsequent request.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.8

It isn't clear whether the CachingHttpClient is a shared cache or not (it depends on where it gets used), so the conservative compliant behavior is to assume we are a shared cache. The current implementation is caching responses regardless of whether the original requests had Authorization headers or not.

Patch and discussion forthcoming.

"
"HTTPCLIENT-447","BUG","BUG","IllegalStateException: Authentication state already initialized","Hi,

I am running HttpClient 3.0 RC2 in my application and a user send me a logfile
telling ""IllegalStateException: Authentication state already initialized"". 

He wanted to access a site on SUN.com and is behind a proxy. The site seems to
redirect to a different domain.

I have attached a Debug+Trace HttpClient log.

Ben"
"HTTPCLIENT-97","BUG","BUG","Error reading data","Hi,

I have some problems with HttpClient HEAD. It works fine with a build of 
20020720 of HttpClient though.

It seems HttpClient is not reading correctly the returned HTTP response.

I'm attaching the logs.

Here is the output from Cactus build:



     [java]     [junit] Testcase: testLongProcess took 3.645 sec
     [java]     [junit]         Caused an ERROR
     [java]     [junit] Failed to get the test results. This is probably due 
to an error that happen
ed on the server side when trying to execute the tests. Here is what was 
returned by the server : [<
html><head><Long Process></head><body>Some data</body></html>
     [java]     [junit] ]
     [java]     [junit] org.apache.cactus.util.ChainedRuntimeException: Failed 
to get the test resul
ts. This is probably due to an error that happened on the server side when 
trying to execute the tes
ts. Here is what was returned by the server : [<html><head><Long 
Process></head><body>Some data</bod
y></html>
     [java]     [junit] ]
     [java]     [junit]         at 
org.apache.cactus.client.AbstractHttpClient.doTest(Unknown Source
)
     [java]     [junit]         at 
org.apache.cactus.AbstractWebTestCase.runWebTest(Unknown Source)
     [java]     [junit]         at 
org.apache.cactus.AbstractWebTestCase.runGenericTest(Unknown Sour
ce)
     [java]     [junit]         at org.apache.cactus.ServletTestCase.runTest
(Unknown Source)
     [java]     [junit]         at org.apache.cactus.AbstractTestCase.runBare
(Unknown Source)
     [java]     [junit] org.apache.cactus.client.ParsingException: Not a valid 
response. First 100 c
haracters of the reponse: [</webresult>HTTP/1.1 200 OK
     [java]     [junit] Server: Resin/2.1.2
     [java]     [junit] Content-Length: 23
     [java]     [junit] Date: Tue, 13 Aug 2002 08:45:2]
     [java]     [junit]         at 
org.apache.cactus.client.WebTestResultParser.readExceptionClassna
me(Unknown Source)
     [java]     [junit]         at 
org.apache.cactus.client.WebTestResultParser.parse(Unknown Source

Thanks
-Vincent"
"HTTPCLIENT-898","IMPROVEMENT","IMPROVEMENT","Improve multihome support","MultihomePlainSocketFactory is basically broken and should be deprecated. Multihome logic needs to be moved to the DefaultClientConnectionOperator"
"HTTPCLIENT-752","OTHER","IMPROVEMENT","version.properties","If we're not going to split it, there should be only one version.properties in module-client.
module-httpmime is currently missing a version.properties file.
"
"HTTPCLIENT-904","CLEANUP","IMPROVEMENT","HttpMime StringBody constructor throws specification unnecessarily declares UnsupportedEncodingException","The string body constructors that take a charset unnecessarily throw UnsupportedEncodingException - if you have Charset, the encoding is by definition supported:

    public StringBody(
            final String text, 
            final String mimeType, 
            Charset charset) throws UnsupportedEncodingException {
        super(mimeType);
        if (text == null) {
            throw new IllegalArgumentException(""Text may not be null"");
        }
        if (charset == null) {
            charset = Charset.defaultCharset();
        }
        this.content = text.getBytes(charset.name());
        this.charset = charset;
    }
    
    public StringBody(final String text, Charset charset) throws UnsupportedEncodingException {
        this(text, ""text/plain"", charset);
    }
    
I suggest to change this to

    public StringBody(
            final String text, 
            final String mimeType, 
            Charset charset)  {
        super(mimeType);
        if (text == null) {
            throw new IllegalArgumentException(""Text may not be null"");
        }
        if (charset == null) {
            charset = Charset.defaultCharset();
        }
        this.content = text.getBytes(charset);
        this.charset = charset;
    }
    
    public StringBody(final String text, Charset charset) {
        this(text, ""text/plain"", charset);
    }

The important change is to change

        this.content = text.getBytes(charset.name());

to 

        this.content = text.getBytes(charset);

which will not throw and hence the throws specifications can be removed.
"
"HTTPCLIENT-145","CLEANUP","BUG","Align the code base with checkstyle","The style use in HttpClient is still quite inconsistant.  checkstyle should be
used to align the code base to a similar style.

The checkstyle report can be found at:
http://jakarta.apache.org/commons/httpclient/checkstyle-report.html

And can be generated with:
maven checkstyle:generate-report"
"HTTPCLIENT-152","DOCUMENTATION","BUG","Ensure the features.html and index.html adequately give httpclient enough credit","See the email thread started by Eric Johnson.
http://archives.apache.org/eyebrowse/BrowseList?listId=128&by=thread&from=316092

Initial post:
Based on the recent URI discussion, and some other points, it strikes me that we
could take a little more credit for the work that has gone into HttpClient.

On the HttpClient home page
(http://jakarta.apache.org/commons/httpclient/index.html) four RFCs are listed.

Given all the discussion about URIs being thrown around, I think it might be
reasonable to add RFC 2396 - for URI compliance.  Then there is RFC 1867, for
multipart/form-data POST requests (I think I got the right number there).  Are
there RFCs corresponding to our ""cookie"" compliance? Any other RFCs we can claim
credit for conforming to?

With the recent ""Protocol"" changes, I think we've made it relatively
straightforward for clients of HttpClient to plug in their own secure sockets
implementations, making it easier to use third party, non-Sun solutions."
"HTTPCLIENT-151","BUG","BUG","CookieSpec.formatCookie(Cookie) produces an incorrect cookie header value","Consider the following:
----------------------------------------------------------------------
Cookie cookie = new Cookie("".foo.com"", ""name"", ""value"");
cookie.setVersion(1);
cookie.setPath(""/"");
CookieSpec spec = CookiePolicy.getSpecByPolicy(CookiePolicy.RFC2109);
System.out.println(spec.formatCookie(cookie));                
----------------------------------------------------------------------

When calling CookieSpec.formatCookie(Cookie) the resulting output is:

   name=""value""

The Version attribute is not present as required by RFC2109, nor is the path or
domain information included.

It seems that in this case, only Cookie type 0 output is produced."
"HTTPCLIENT-795","BUG","BUG","If there is more than 15 seconds between HttpClient.execute() calls using a MultipartEntity, a ProtocolException is thrown complaining about the Content-Length header already being present.","I am not sure if this time-related behaviour is intentional or not (I have only been using this library for a few weeks) , but even if a timeout is to be expected, the exception thrown ought to indicate that there is a time component involved. ""org.apache.http.ProtocolException: Content-Length header already present"" is incredibly misleading. 

A simple-ish compileable program to reproduce the bug is as follows:

import java.nio.charset.Charset;
import org.apache.http.HttpResponse;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.client.params.ClientPNames;
import org.apache.http.client.params.CookiePolicy;
import org.apache.http.entity.mime.MultipartEntity;
import org.apache.http.entity.mime.content.StringBody;
import org.apache.http.impl.client.DefaultHttpClient;
public class Simple {
    static public void main(String [] args)
    {
        try
        {
            DefaultHttpClient client = new DefaultHttpClient();
            client.getParams().setParameter(
                        ClientPNames.COOKIE_POLICY, CookiePolicy.BROWSER_COMPATIBILITY);
            MultipartEntity entity;
            StringBody stringBody;
            HttpPost post;
            HttpResponse response;
            entity = new MultipartEntity();
            stringBody = new StringBody(""field contents"",Charset.forName(""ISO-8859-1""));
            entity.addPart(""field"", stringBody);  
            post = new HttpPost(""http://localhost/simple.php"");
            post.setEntity(entity); 
            response = client.execute(post);
            
            //The exception does not occur if the content is not consumed
            response.getEntity().consumeContent();
            System.out.println(""First post done"");
            
            //The exception does not occur if the time interval between the requests is too short
            Thread.sleep(15000);
            
            //The exception naturally doesn't occur if a new HttpClient is created
            //client = new DefaultHttpClient();

            entity = new MultipartEntity();
            stringBody = new StringBody(""field contents"",Charset.forName(""ISO-8859-1""));
            entity.addPart(""field"", stringBody);  

            post = new HttpPost(""http://localhost/simple.php"");
            post.setEntity(entity); 
            response = client.execute(post); //Will throw the following:
            /*
                org.apache.http.ProtocolException: Content-Length header already present
                at org.apache.http.protocol.RequestContent.process(RequestContent.java:70)
                at org.apache.http.protocol.BasicHttpProcessor.process(BasicHttpProcessor.java:290)
                at org.apache.http.protocol.HttpRequestExecutor.preProcess(HttpRequestExecutor.java:160)
                at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:356)
                at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)
                at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)
                at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)
                at test.Simple.main(Simple.java:57)
             */ 
            System.out.println(""Second post done"");
        }
        catch(Exception e)
        {
            System.out.println(e);
            e.printStackTrace();
        }
    }    
}"
"HTTPCLIENT-57","RFE","BUG","Define and implement Logging policy","When to use info vs debug vs warning?  
When to log exceptions?
enter() and exit() messages on a per method basis?
Always log debug when swallowing an exception?"
"HTTPCLIENT-734","IMPROVEMENT","IMPROVEMENT","request.abort() should interrupt thread waiting for a connection","Calls to HttpRequestBase.abort() will not unblock a thread that is still waiting for a connection and therefore has no ConnectionReleaseTrigger yet.
"
"HTTPCLIENT-1007","RFE","IMPROVEMENT","When A URL is redirected, there is no easy way to encode the new url before HC tries to execute it/","When you implement your custom RedirectHandler, there is no easy way to encode the new URL being redirected to.

A public method to access the location string prior to the URI generation would be useful."
"HTTPCLIENT-516","DOCUMENTATION","IMPROVEMENT","Javadoc: does not mention Expires; clarify validate","The Expires attribute processing is not mentioned in any of the Javadoc, as far
as I can tell. 

Also, the public method parseAttribute() actually handles the attributes, but
does not contain the details. It would be useful if there was at least a
backlink to the parse() documentation.

It's not clear from the Javadoc whether parse() automatically calls validate()
or not. It doesn't."
"HTTPCLIENT-652","RFE","IMPROVEMENT","Add optional state attribute to managed client connections","Provide an optional state attribute to managed client connections. The connection state can represent a user identify in case of connection based authentication schemes such as NTLM or SSL, thus allowing for connection re-use on a per user identity basis."
"HTTPCLIENT-686","BUILD_SYSTEM","BUG","Maven 2 POM includes junit in default ""compile"" scope, rather than ""test"" scope","The POM at the URL above declares a dependency on JUnit in the default scope, rather than the ""test"" scope."
"HTTPCLIENT-387","BUG","BUG","DefaultHttpParamsFactory.getDefaultParams() is not thread safe","The method getDefaultParams() in 
org.apache.commons.httpclient.params.DefaultHttpParamsFactory is not thread 
safe.  In this code:

    public HttpParams getDefaultParams() {
        if (httpParams == null) {
            httpParams = createParams();
        }

        return httpParams;
    }

it is possible that httpParams will be called by one thread which will set 
httpParams, then a second thread may call it and may find httpParams is 
non-null.  However, under both the old (Java Language Spec chapter 17) and 
new Java Memory Models, the second thread won't necessarily see the values 
the first thread has set in the referenced HttpParams object.

The easiest way to fix this for all JVMs and memory models is by declaring 
getDefaultParams() to be synchronized."
"HTTPCLIENT-189","RFE","BUG","Set-Cookie2 and Set-Cookie","Acording to RFC2965 9.1:
                                                 User agents that
   receive in the same response both a Set-Cookie and Set-Cookie2
   response header for the same cookie MUST discard the Set-Cookie
   information and use only the Set-Cookie2 information.

this is read that the header for a cetain cookie, but not all cookie.
So, Server can send only Set-Cookie header for some cookies and,
for cookies send Set-Cookie2,Set-cookie both.

But httpclient implementation handles this that if find any set-cookie2 header,
then ignores all Set-cookie header.
I know some sites use set-cookie2 only for cookies which needs
 more flexible exiration handling, and for other cookies use only
Set-Cookie. One of exmaples of such sites I know is 
TDNet Database service provided by Tokyo Stock Exchange.

So, the preferred implementation is that if set-cookie2 header
 found for a certain cookie then cookie value is set from set-cookie2 header, if
not, then from Set-Cookie header."
"HTTPCLIENT-213","BUG","BUG","Authentication fails with proxied SSL Connections","When connecting through a proxy, using SSL and authentication HttpClient winds 
up sending a GET request to the proxy after the initial auth required response, 
the proxy then obviously responds with a not implemented response since it 
can't handle a GET request to an SSL URL.  In essence the following is 
happening:

1. HttpClient sends Connect response.
2. Proxy responds 200 Connect OK
3. HttpClient uses SSL connection to send the request to the web server.
4. Web server responds with not authorized and closes the connection.
5. HttpClient opens a new connection to the proxy and issues a GET request for 
the SSL URL.
6. Proxy returns 501 not implemented.

I'll attach a full log to this bug.

This is likely to be hard to fix since the retry is performed in HttpMethodBase 
but the Connect method is executed by HttpClient so a fix for this may be best 
waiting for 2.1.  This looks very similar to HTTPCLIENT-195 except that that bug is 
marked as fixed and this one still doesn't work, this also applies to 
authentication schemes other than NTLM (testing NTLM and basic).

My best evaluation is that the web server returns Connection: close when it 
rejects the authorization attempt and then HttpMethodBase is incapable of 
creating a new SSL connection through the proxy.  The only thing I can think of 
that could be done prior to 2.1 to fix this is to send a Connection: keep-alive 
as well as the Proxy-Connection: Keep-Alive we're already sending with the 
original request."
"HTTPCLIENT-641","BUG","BUG","Resource Leakage when loading keystore in AuthSSLProtocolSocketFactory","Opened stream not closed after keystore is loaded, resulting in resource leakage:

private static KeyStore createKeyStore(final URL url, final String password) 
        throws KeyStoreException, NoSuchAlgorithmException, CertificateException, IOException
    {
        if (url == null) {
            throw new IllegalArgumentException(""Keystore url may not be null"");
        }
        LOG.debug(""Initializing key store"");
        KeyStore keystore  = KeyStore.getInstance(""jks"");
        keystore.load(url.openStream(), password != null ? password.toCharArray(): null);
        return keystore;
    }

Should be changed to something like:

private static KeyStore createKeyStore(final URL url, final String password) 
        throws KeyStoreException, NoSuchAlgorithmException, CertificateException, IOException
    {
        if (url == null) {
            throw new IllegalArgumentException(""Keystore url may not be null"");
        }
        LOG.debug(""Initializing key store"");
        KeyStore keystore  = KeyStore.getInstance(""jks"");
        InputStream is = ulr.openStream();
        try {
          keystore.load(is, password != null ? password.toCharArray(): null);
        } finally {
           is.close();
        }
        return keystore;
    }"
"HTTPCLIENT-1032","IMPROVEMENT","BUG","cache revalidation of variants does not update original variant entry","When the cache stories multiple variant entries due to Vary headers in responses, the cache correctly sends a conditional request containing the etags of any existing variants on a ""variant miss"" (incoming request does not match the request variants already cached). In addition, when it receives a 304 response, it correctly returns the indicated variant to the request that causes the variant miss. However, it does not update the pre-existing variant cache entry as recommended by RFC 2616.

For example:

request 1, User-Agent: agent1 results in a 200 OK with Etag: etag1 and Vary: User-Agent.
request 2, User-Agent: agent2 causes an If-None-Match to the origin; if it returns 304 Not Modified with Etag: etag1
request 3, User-Agent: agent1 results in a 200 OK but gets the (outdated) entry that resulted from request 1

in other words, the origin response from request 2 does not update the variant for ""agent1"".

This does not cause incorrect behavior (this is a SHOULD) but does miss out on some caching opportunities here.
"
"HTTPCLIENT-776","BUG","BUG","NPE w/ AbstractPoolEntry.open","java.lang.NullPointerException
    at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:171)
    at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)
    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:309)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)
    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:135)
    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)
    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)
    at java.lang.Thread.run(Unknown Source)

Seeing a lot of these against Alpha4.  Also seeing still the occassional IllegalStateException of:

java.lang.IllegalStateException: Connection already open.
    at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:150)
    at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:119)
    at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:309)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)
    at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.performRequest(DefaultHttpExecutor.java:97)
    at com.limegroup.gnutella.http.DefaultHttpExecutor.access$000(DefaultHttpExecutor.java:26)
    at com.limegroup.gnutella.http.DefaultHttpExecutor$MultiRequestor.run(DefaultHttpExecutor.java:135)
    at org.limewire.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1006)
    at org.limewire.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:549)
    at java.lang.Thread.run(Unknown Source)
"
"HTTPCLIENT-559","IMPROVEMENT","BUG","SSL contrib files do not use standard javax.net.ssl package provided from JDK 1.4.2","Hi all,

While trying to use ssl on AIX, i found that some of the files contributed in 
src/contrib/org/apache/commons/httpclient/contrib/ssl were making hard 
references to com.sun.net.ssl package. Since JDK 1.4.2, one shall use the 
javax.net.ssl package instead.

I have then:
1/ fixed the source files appropriately
2/ updated the build.xml to also build a commons-http-client-contrib.jar 

I will attached to this bug report the resulting unified diff to include in svn"
"HTTPCLIENT-92","BUG","BUG","Cookies with ',' in the value string is not parsed correctly in some cases","This version extracts the ""Set-Cookie"" statementes of the following
HTTP response headers incorrectly.

The HTTP response is sent when executing GET method on --->
""http://my.taishinbank.com.tw/netbank/nbslogin.asp?
subFunID=https://my.taishinbank.com.tw/netbank/AccountQuery/QAccbyID.asp""

After the HttpClient extracts Set-Cookie from the response, it generates a wrong
cookie statement---->

  [INFO] wire - ->> ""Cookie: $Version=0; _mysite=520163500; 1027657033=null; 
   1027787539=null; 0=null; $Path=/; cata=11; $Path=/;   
   ASPSESSIONIDGGGQQXEU=ADLCDAGAJLKEBJEKBOMMAMOB; 
   $Path=/""

, where it shall 
be ""_mysite=520163500,1027657033,1027787539,1027787539,0;"" ,but 
not ""_mysite=520163500; 1027657033=null; 1027787539=null; 0=null;""
 

Thank you"
"HTTPCLIENT-779","CLEANUP","IMPROVEMENT","toplevel exception cleanup","HttpClient.execute should throw only one exception, for easier general use.
HttpMethod constructors (HttpGet, HttpPut, etc..) should throw IllegalArgumentException in the string constructor (imply the string is pre-checked).  People wanting to see a URIException can use 'new HttpGet(new URI(uri))' and trigger the exception from the explicit URI creation."
"HTTPCLIENT-994","RFE","IMPROVEMENT","cache does not allow client to override origin-specified freshness using max-stale","According to the RFC, the default freshness lifetime is supposed to be the LEAST restrictive of that specified by the origin, the client, and the cache. Right now, a client can't use 'max-stale' to relax the freshness constraints to get a cache hit without validation occuring first.
"
"HTTPCLIENT-991","BUG","BUG","cache module produces improperly formatted Warning header when revalidation fails","The warning header currently attached to a stale response by the caching module when validation with the origin server fails is not a properly-formatted Warning header.

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.46"
"HTTPCLIENT-350","BUG","BUG","HttpState#matchCredentials is broken","Credentials matching algorithm is flawed, generates unnecessary garbage by
instantiating intermediate object during lookup"
"HTTPCLIENT-716","RFE","IMPROVEMENT","application-defined routes","Allow applications to specifiy a route as request parameter (or in the context).
This functionality is a replacement for RoutedRequest, which is removed by HTTPCLIENT-715."
"HTTPCLIENT-987","IMPROVEMENT","BUG","cache module does not recognize equivalent URIs","http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.2.3

""When comparing two URIs to decide if they match or not, a client SHOULD use a case-sensitive octet-by-octet comparison of the entire URIs, with these exceptions:
  * A port that is empty or not given is equivalent to the default port for that URI-reference;
  * Comparisons of host names MUST be case-insensitive;
  * Comparisons of scheme names MUST be case-insensitive;
  * An empty abs_path is equivalent to an abs_path of ""/"".
Characters other than those in the ""reserved"" and ""unsafe"" sets (see RFC 2396 [42]) are equivalent to their """"%"" HEX HEX"" encoding.

For example, the following three URIs are equivalent:
      http://abc.com:80/~smith/home.html
      http://ABC.com/%7Esmith/home.html
      http://ABC.com:/%7esmith/home.html""

The current implementation does not canonicalize the URIs it uses for cache keys, and so is missing potential cache hits. More importantly, though, required invalidations due to PUT/POST/DELETE to a URI (as well as those mentioned in Location or Content-Location headers) may not occur properly due to this bug."
"HTTPCLIENT-249","IMPROVEMENT","IMPROVEMENT","please log allocation of new connections to support debugging, testing","I'd like to suggest that the MultiThreaded connection manager emit a trace-level log when it 
allocates a new HttpConnection to support debugging and testing.  I added one while working on 
my integration in Apache Axis (see org.apache.axis.transport.http.CommonsHTTPSender) and 
figured this would be of general use.  I'll attach a patch with the oh-so-minor addition after 
submitting this enhancement request."
"HTTPCLIENT-252","RFE","IMPROVEMENT","Cookie Strict Mode independent of regular Strict Mode","Hi,

I'm having a problem where a web site I'm trying to access is using strict 
cookies (on one line) and a 302 redirect that fails in strict mode.  So I 
cannot access this website because in strict mode it fails because of the 302 
redirect and in non-strict mode the website doesn't recognize the Cookies on 
separate lines.

I'd love to see this added for the next release candidate.

Thanks,

Brent"
"HTTPCLIENT-51","RFE","BUG","Redefine HttpClient vs HttpMultiClient interface for 2.0","In particular the HttpClient/HttpMultiClient issue must be resolved. 
HttpultiClient functionality should be prefered, but HttpClient is the most
suitable name.  Consider impact to other projects.  Is java1.1 compatability
really an issue anymore?"
"HTTPCLIENT-540","DOCUMENTATION","BUG","Typo in API_CHANGES_3_0.txt","DigestSheme should be DigestScheme :)  Also, why is there not an httpclient
component in the list?"
"HTTPCLIENT-974","BUG","BUG","RequestWrapper does not use the headers of the request it wraps.","The RequestWrapper does not use the headers of the request it wraps. Therefore the wrapper appears as having no header, while the wrapped request may have some.

To work-around that behavior, I have to call resetHeaders() on the wrapper just after having created it.
This method does the following:
    public void resetHeaders()
    {
        headergroup.clear();
        setHeaders(original.getAllHeaders());
    }

I suggest calling setHeaders directly in the constructor. Or at least highlight in the Javadoc that we should call resetHeaders()."
"HTTPCLIENT-698","BUG","BUG","DefaultRedirectHandler not resolving relative location URI wrt the request URI","The adjustment of a relative URI in the Location header value does not take the request URI into account. So you may want to replace ...
------------------------------
try {
    uri = new URI(
            target.getSchemeName(),
            null,
            target.getHostName(),
            target.getPort(),
            uri.getPath(),
            uri.getQuery(),
            uri.getFragment());
------------------------------
... with ...
------------------------------
HttpRequest request = (HttpRequest) context.getAttribute(ExecutionContext.HTTP_REQUEST);
try {
    URI requestURI = new URI(request.getRequestLine().getUri());
    URI absoluteRequestURI = new URI(
            target.getSchemeName(),
            null,
            target.getHostName(),
            target.getPort(),
            requestURI.getPath(),
            requestURI.getQuery(),
            requestURI.getFragment());
    uri = absoluteRequestURI.resolve(uri);
------------------------------
... or get the request URI from somewhere else."
"HTTPCLIENT-105","BUG","BUG","ChunkedInputStream broken (2 bugs + fixes, 1 suggestion)","Bug 1.

In the     

read(byte[] b, int off, int len)  method

of ChunkedInputStream, the number of bytes to read from the underlying 
InputStream is calculated wrongly. In the code this is done by

len = Math.min(len, chunkSize);

This could (and will) cause the server (also Apache) to indeed serve that 
number of bytes (let's say chunkSize), but it may be that we already had a 
number of bytes on the first read. The result is that the input is now NOT 
positioned on the end of a chunk and the rest of the reader fails because it 
cannot find CRLF or a valid chunksize.

Proposed fix (works, tested)
len = Math.min(len, chunkSize-pos);

Bug 2.

In the calculation of the chunkSize (method getChunkSizeFromInputStream) the 
conversion to int is done by calling             

result = Integer.parseInt(dataString, 16);

This is not robust and causes the occasional crash. The fix is simple and in 
fact implements what is done when the chunkSize is commented (see lines in code 
above)

result = Integer.parseInt(dataString.trim(), 16);

Tested and works.



Suggestion:
Same routine, input state machine. Perhaps just being pedantic..change while 
loop to:

        while (state != 2) {
            int b = in.read();
            if (b == -1) throw new IOException(""chunked stream ended 
unexpectedly"");
            switch (state) {
                case 0:
                    if (b == '\r')
                      state = 1;
                    else
                      baos.write(b);
                    break;
                case 1:
                    if (b == '\n')
                      state = 2;
                    else{
                     // this was not CRLF, so now write '\r' + this char
                      baos.write('\r');
                      baos.write(b);
                      state = 0;
                    }
                    break;
                default: throw new RuntimeException(""assertion failed"");
            }
        }.

In the     

read(byte[] b, int off, int len)  method

of ChunkedInputStream, the number of bytes to read from the underlying 
InputStream is calculated wrongly. In the code this is done by

len = Math.min(len, chunkSize);

This could (and will) cause the server (also Apache) to indeed serve that 
number of bytes (let's say chunkSize), but it may be that we already had a 
number of bytes on the first read. The result is that the input is now NOT 
positioned on the end of a chunk and the rest of the reader fails because it 
cannot find CRLF or a valid chunksize.

Proposed fix (works, tested)
len = Math.min(len, chunkSize-pos);

Bug 1.

In the     

read(byte[] b, int off, int len)  method

of ChunkedInputStream, the number of bytes to read from the underlying 
InputStream is calculated wrongly. In the code this is done by

len = Math.min(len, chunkSize);

This could (and will) cause the server (also Apache) to indeed serve that 
number of bytes (let's say chunkSize), but it may be that we already had a 
number of bytes on the first read. The result is that the input is now NOT 
positioned on the end of a chunk and the rest of the reader fails because it 
cannot find CRLF or a valid chunksize.

Proposed fix (works, tested)
len = Math.min(len, chunkSize-pos);

Bug 2.

In the calculation of the chunkSize (method getChunkSizeFromInputStream) the 
conversion to int is done by calling             

result = Integer.parseInt(dataString, 16);

This is not robust and causes the occasional crash. The fix is simple and in 
fact implements what is done when the chunkSize is commented (see lines in code 
above)

result = Integer.parseInt(dataString.trim(), 16);

Tested and works.



Suggestion:
Same routine, input state machine. Perhaps just being pedantic..change while 
loop to:

        while (state != 2) {
            int b = in.read();
            if (b == -1) throw new IOException(""chunked stream ended 
unexpectedly"");
            switch (state) {
                case 0:
                    if (b == '\r')
                      state = 1;
                    else
                      baos.write(b);
                    break;
                case 1:
                    if (b == '\n')
                      state = 2;
                    else{
                     // this was not CRLF, so now write '\r' + this char
                      baos.write('\r');
                      baos.write(b);
                      state = 0;
                    }
                    break;
                default: throw new RuntimeException(""assertion failed"");
            }
        }.

In the calculation of the chunkSize (method getChunkSizeFromInputStream) the 
conversion to int is done by calling             

result = Integer.parseInt(dataString, 16);

This is not robust and causes the occasional crash. The fix is simple and in 
fact implements what is done when the chunkSize is commented (see lines in code 
above)

result = Integer.parseInt(dataString.trim(), 16);

Tested and works.



Suggestion:
Same routine, input state machine. Perhaps just being pedantic..change while 
loop to:

        while (state != 2) {
            int b = in.read();
            if (b == -1) throw new IOException(""chunked stream ended 
unexpectedly"");
            switch (state) {
                case 0:
                    if (b == '\r')
                      state = 1;
                    else
                      baos.write(b);
                    break;
                case 1:
                    if (b == '\n')
                      state = 2;
                    else{
                     // this was not CRLF, so now write '\r' + this char
                      baos.write('\r');
                      baos.write(b);
                      state = 0;
                    }
                    break;
                default: throw new RuntimeException(""assertion failed"");
            }
        }"
"HTTPCLIENT-1035","RFE","IMPROVEMENT","cache should invalidate obsoleted entries mentioned in Content-Location","From http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.6:

If a cache receives a successful response whose Content-Location field matches that of an existing cache entry for the same Request-URI, whose entity-tag differs from that of the existing entry, and whose Date is more recent than that of the existing entry, the existing entry SHOULD NOT be returned in response to future requests and SHOULD be deleted from the cache.

Current caching module doesn't do this (yet). As this is a recommendation (SHOULD) and not a requirement (MUST) I am marking this as an improvement rather than a bug.
"
"HTTPCLIENT-215","BUILD_SYSTEM","BUG","Build problem with StrictSSLProtocolSocketFactory","StrictSSLProtocolSocketFactory requires jcert.jar to be in compile.classpath of
build.xml.  Here is a patch that will fix it:

Index: build.xml
===================================================================
RCS file: /home/cvspublic/jakarta-commons/httpclient/build.xml,v
retrieving revision 1.27
diff -u -r1.27 build.xml
--- build.xml   23 May 2003 02:49:01 -0000      1.27
+++ build.xml   26 May 2003 04:23:50 -0000
@@ -98,6 +98,7 @@
     <pathelement location=""${build.home}/classes""/>
     <pathelement location=""${junit.jar}""/>
     <pathelement location=""${jsse.jar}""/>
+    <pathelement location=""${jcert.jar}""/>
     <pathelement location=""${jce.jar}""/>
     <pathelement location=""${jnet.jar}""/>
     <pathelement location=""${commons-logging.jar}""/>"
"HTTPCLIENT-209","RFE","IMPROVEMENT","Add set/getLocalAddress methods to HostConfiguration","On clustered or multi-homed systems, there's a need to specify the local bind
address of sockets, to ensure that they're created on the right interface.  To
do this, the local address needs to be passed to the 4-argument version of
ProtcolSocketFactory.createSocket.

After discussion on the mailing list, the best approach for this seems to be
adding the local address as a property on HostConfiguration and HttpConnection.  

I've attached a patch which does the following:
- Add public set/getLocalAddress methods to HostConfiguration and HttpConnection.
- HttpConnection uses the local address when opening connections.
- Modify HostConfiguration.equals and hostEquals to compare the local address too.
- SimpleHttpConnectionManager uses the local address from the provided config. 
I also cleaned up its getConnection method a bit.
- HttpClient.executeMethod uses the local address from its default
HostConfiguration if the method's config doesn't specify one."
"HTTPCLIENT-456","BUG","BUG","HttpClient should always override the host of HostConfiguration if an absolute request URI is given","This bug most likely occurs on all patforms and OS's, but I have only tested it
on WinXP.

The HttpClient.executeMethod(HostConfiguration,HttpMethod,HttpState) will
receive and throw an IllegalArgumentException stating that ""host parameter is
null"" when a  HostConfiguration object is passed in that ONLY has a proxy set
(via HostConfiguration.setProxy(String, int)). Details to reproduce follow--the
bug can be easily reproduced by using the Apache Axis 1.2 CommonsHTTPSender
class (with JVM system props http.proxyHost, http.proxyPort set):

There is a bug in the Apache Commons HTTP Client 3.0rc2 that does not set the
hostname property
in the <code>HostConfiguration</code> object if the following two steps
are performed:<br>
1. You call
<code>HttpClient.executeMethod(HostConfiguration,HttpMethod,HttpState)</code>
with a <code>HostConfiguration</code> object and an <code>HttpMethod</code> object
(created using the HttpMethod(String uri) constructor).This method 
is called in this exact way in the Apache Axis 1.2 client
(CommonsHTTPSender.java lines 132 and 186).<br>
2. That <code>HostConfiguration</code> object only has a proxy set (using
setProxy(String, int)). This method 
is called in this exact way in the Apache Axis 1.2 client
(CommonsHTTPSender.java line 389).<br>

Apache Axis 1.2rc3 CommonsHTTPSender.java did not expose this bug in Commons
HTTP Client 3.0rc2 because
it set the <code>HostConfiguration</code> in a different manner, as follows:<br>
1. Call <code>HttpClient.setHostConfiguration(HostConfiguration)</code> first.
Again,
The <code>HostConfiguration</code> object must only have a proxy set and no host
name.<br>
2. Then call <code>HttpClient.executeMethod(HttpMethod)</code>.<br>

Using the above steps (as in Axis 1.2rc3 CommonsHTTPSender.java, invoke()
method), line 379 in HttpClient.java evaluates to true
because the argument <code>hostConfiguration</code> is null (see line 324 in
HttpClient.java) and the local 
variable <code>defaultHostConfiguration</code> ==
<code>HttpClient.setHostConfiguration(HostConfiguration)</code>
which was set in item #1 above. The hostname then gets set in the
<code>HostConfiguration</code>
object in line 384 of HttpClient.java."
"HTTPCLIENT-1156","RFE","IMPROVEMENT","Kerberos Authentication Scheme","HttpClient 4.1.2 has a SPNEGO authentication that uses the Negotiate keyword.  But the MS IIS that I must connect to does not send back an WWW-Authenticate: Negotiate, but, instead, does send an WWW-Authenticate: Kerberos

So I used the NegotiateScheme.java and NegotiateSchemeFactory.java as a base to create a ""new"" scheme, called, KerberosScheme.java and KerberosSchemeFactory.java to make it work.

Essentially I replaced every ""Negotiate"" scheme by ""Kerberos"", in the KerberosScheme.java, and removed the part of the code that tried, first, SPNEGO_OID, using KERBEROS_OID directly, instead.

It works fine for me, but took me a while to figure this out.

That why I think it could come on the new versions.

I'll attach my version but it has no package - it was made only for a test project.  It's trivial to put it in the right place/package.
"
"HTTPCLIENT-1087","BUG","BUG","Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED when using NTLM authentication","Trying to connect to a website that requires basic authentication through a proxy that requires NTLM authentication.

Proxy authentication fails with ""Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED"".

Full wire log attached.  Code to replicate problem follows:

    private void execute() throws HttpException, IOException {
    	
    	URL targetUrl = new URL(TARGET_URL);
    	
        DefaultHttpClient httpclient = new DefaultHttpClient();

        HttpHost targetHost = new HttpHost(targetUrl.getHost()); 
        HttpHost proxyHost = new HttpHost(PROXY_HOST, PROXY_PORT); 
        
        httpclient.getParams().setParameter(ConnRoutePNames.DEFAULT_PROXY, 
        		proxyHost);

        CredentialsProvider credProvider = httpclient.getCredentialsProvider();
        
        Credentials proxyCredentials = new NTCredentials(PROXY_USER, 
        		PROXY_PASSWORD, PROXY_MACHINE, PROXY_DOMAIN);
        AuthScope proxyAuthScope = new AuthScope(proxyHost.getHostName(),
        		proxyHost.getPort());
        
        credProvider.setCredentials(proxyAuthScope, proxyCredentials);
        
        Credentials targetCredentials = new UsernamePasswordCredentials(
        		TARGET_USER, TARGET_PASSWORD);
        AuthScope targetAuthScope = new AuthScope(targetHost.getHostName(),
        		targetHost.getPort());
        
        credProvider.setCredentials(targetAuthScope, targetCredentials);
      
        HttpGet httpget = new HttpGet(targetUrl.getPath());

        HttpResponse response = httpclient.execute(targetHost, httpget);
        
        System.out.println(""response = "" + response);
        
       
    }
"
"HTTPCLIENT-353","RFE","IMPROVEMENT","Setting different MAX_HOST_CONNECTION values per host using a single MultiThreadedHttpConnectionManager","Right now, it's not possible to use the
MultiThreadedHttpConnectionManager.setMaxConnectionsPerHost(int) method in a per
HostConfiguration basis. The value applies to every HostConfiguration the
current connection manager is managing.

I would be quite useful to allow the connection manager to set different values
depending on the HostConfiguration."
"HTTPCLIENT-650","IMPROVEMENT","BUG","Wire log is incomplete if HttpParser detects an error","If HttpParser detects an error in any of the headers, it throws a ProtocolException

Although the failing header is included in the Exception detail, the headers leading up to the failure are not logged, which makes it hard to debug (and is quite confusing, as the PE does not appear to be related to the data that has been received).

This is because the wire-logging is done in the caller (HttpMethodDirector) which only logs the header if the parse succeeds.

Perhaps the Wire logging should be done at the point where the HttpParser reads the line."
"HTTPCLIENT-594","BUG","BUG","HttpMethodBase#aborted variable mistakenly declared transient instead of volatile","HttpMethodBase#aborted variable mistakenly declared transient instead of volatile. This is quite nasty. 

Do we want to cut an emergency release (3.0.2) because of that or can this wait until 3.1-beta1?

Fix attached.

Oleg"
"HTTPCLIENT-178","IMPROVEMENT","IMPROVEMENT","MultiThreadedHttpConnectionManager never reclaims unused connectons","There is no limit on the number of connections that will get created by the
MultiThreadedHttpConnectionManager.  Unused connections are never destroyed."
"HTTPCLIENT-438","DOCUMENTATION","IMPROVEMENT","commons codec not documented as a dependency","Except for some entries on the jdepend-report, commons codec is not documented
as a dependency for using HttpClient 3.0 RC1.  The only dependency documented is
commons logging.

java.lang.NoClassDefFoundError: org/apache/commons/codec/DecoderException
	at org.apache.commons.httpclient.HttpMethodBase.<init>(HttpMethodBase.java:217)
	at
org.apache.commons.httpclient.methods.ExpectContinueMethod.<init>(ExpectContinueMethod.java:92)
	at
org.apache.commons.httpclient.methods.EntityEnclosingMethod.<init>(EntityEnclosingMethod.java:114)
	at org.apache.commons.httpclient.methods.PostMethod.<init>(PostMethod.java:105)"
"HTTPCLIENT-188","BUG","BUG","recoverable exceptions when reading are not retried","If a recoverable exception occurs after a request is written then the method is
not retried."
"HTTPCLIENT-656","RFE","RFE","IP address of the server of a HttpConnection","AFAIK it's not possible to get the IP address of the server of a HttpConnection.

I propose to add a getServerAddress() method to the HttpConnection class that returns the IP address of the server, if the connection has been opened.
And either returns null or throws an Exception if the IP address is not available, i.e. the connection is not open.

Below is a workaround for getting the IP address in current versions.

-----------------------
package org.apache.commons.httpclient;

import java.io.IOException;
import java.net.InetAddress;

public class InetAddressFetcher {
	private HttpConnection hc;

	public InetAddressFetcher(HttpConnection hc) {
		this.hc = hc;
	}

	public InetAddress getInetAddress() throws IOException {
		if (!hc.isOpen()) {
			hc.open();
		}
		return hc.getSocket().getInetAddress();
	}
}"
"HTTPCLIENT-940","BUG","BUG","impl.conn.Wire uses String.getBytes() which depends on the default charset","impl.conn.Wire uses String.getBytes() which depends on the default charset

The methods 
public void output(final String s)
and
public void input(final String s)

could probably be recoded to avoid this problem, as the output routine uses a StringBuilder."
"HTTPCLIENT-639","BUILD_SYSTEM","","Add OSGi bundle metadata to manifest","See this discussion on the Felix mailing list:
http://www.mail-archive.com/felix-dev@incubator.apache.org/msg04041.html

If there is an easy way to generate the information required for an OSGi bundle into the manifest of our distributable JAR, we should do it.
The runtime and API are not affected, it is only a modification of the build process.
I'll follow up on this when I have information about the required tooling.

cheers,
  Roland
"
"HTTPCLIENT-1075","BUG","BUG","ContentEncodingHttpClient.execute(HttpGet, ResponseHandler<T>) throws IOException when reading compressed response","The following snippet:

    String url = ""http://yahoo.com"";
    HttpClient httpClient = new ContentEncodingHttpClient();
    HttpGet get = new HttpGet(url);
    String content = httpClient.execute(get, new BasicResponseHandler());

throws:

java.io.IOException: Attempted read from closed stream.
	at org.apache.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:126)
	at java.util.zip.CheckedInputStream.read(CheckedInputStream.java:42)
	at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:205)
	at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:197)
	at java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:136)
	at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:58)
	at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:68)
	at org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)
	at org.apache.http.conn.BasicManagedEntity.getContent(BasicManagedEntity.java:88)
	at org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:974)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:919)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:910)
	at tv.adap.service.HttpPoolTest.testChunkedGzip(HttpPoolTest.java:41)

whereas the following snippet runs fine:

    String url = ""http://yahoo.com"";
    HttpClient httpClient = new ContentEncodingHttpClient();
    HttpGet get = new HttpGet(url);
    HttpResponse response = httpClient.execute(get);
    HttpEntity entity = response.getEntity();
    String content = EntityUtils.toString(entity);

These two snippets should be functionally the same (putting the entity body into content). Creating a JIRA per the recommendation of Oleg from httpclient-users."
"HTTPCLIENT-861","RFE","BUG","URI reference resolution fails examples in RFC 3986","org.apache.http.client.utils.URIUtils.resolve(final URI baseURI, URI reference) fails to resolve some examples from RFC 3986 section 5.3 correctly. See TestCase."
"HTTPCLIENT-541","RFE","IMPROVEMENT","Redesign virtual host API","HttpClient is ignoring an explicity set host.  e.g. if you set the host like
client.getHostConfiguration().setHost(""127.0.0.1"") then execute a method looking
up say http://google.com then the program will connect to google.com rather than
the localhost.

The fix that works for me:
diff -Naur
../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpClient.java
src/java/org/apache/commons/httpclient/HttpClient.java
---
../../t2/commons-httpclient/src/java/org/apache/commons/httpclient/HttpClient.java
2005-12-22 01:06:54.000000000 +1300
+++ src/java/org/apache/commons/httpclient/HttpClient.java	2005-12-22
19:13:30.000000000 +1300
@@ -383,7 +383,9 @@
         if (hostconfig == defaulthostconfig || uri.isAbsoluteURI()) {
             // make a deep copy of the host defaults
             hostconfig = new HostConfiguration(hostconfig);
-            if (uri.isAbsoluteURI()) {
+	    // if the host is explicity set already (e.g. to the IP of the virtual host
+	    // on which we are executing a method), just leave it
+            if (uri.isAbsoluteURI()  && hostconfig.getHost()==null) {
                 hostconfig.setHost(uri);
             }

Note: Why do we care that the host is specified?  Why not just use the uri
authority?  In my case I have a virtual host running on several servers/IPs and
I need to make sure the request goes through to a specific IP and the response
that comes back is for the virtual host I am testing."
"HTTPCLIENT-198","BUG","BUG","The PostMethod did not bring back response headers from proxy servers","Description:

When doing tunnelling through proxy servers, in case of 407 response, the 
wrapper class ConnectMethod failed to pass the response header back to the 
wrapped method (PostMethod in our case).  As result, the response headers are 
not passed back to the application.

Proposed Fix:
Change the ConnectMethod to use the wrapped method instance to get response 
headers.  It will be reinitialized again if ""CONNECT"" is successful.

Also have to modify the addProxyAuthorizationRequestHeader code to use the 
wrapped method for the authenticator to work."
"HTTPCLIENT-951","BUG","BUG","Incorrect handling of InputStreams when connecting to a server that requires authentication","I'm trying to upload a file to a WebDav server (mod_dav on Apache Web Server 2.2.14) that has basic (or digest, the result is the same) authentication enabled.
I'm using the following code:
        String url = ""http://myserver/dir/test2.gif"";
        File file = new File(""d:/test2.gif"");
        DefaultHttpClient httpClient = new DefaultHttpClient();
        HttpPut put = new HttpPut(url);
        put.setEntity(new InputStreamEntity(new FileInputStream(file), file.length()));
        
        URI uri = put.getURI();
        httpClient.getCredentialsProvider().setCredentials(new AuthScope(uri.getHost(), uri.getPort()),
                getCredentials());
        put.getParams().setBooleanParameter(CoreProtocolPNames.USE_EXPECT_CONTINUE, true);
        HttpResponse response = httpClient.execute(put);
        System.out.println(response.getStatusLine());

When running the above code, I'm getting a org.apache.http.client.NonRepeatableRequestException: Cannot retry request with a non-repeatable request entity. I tested both the latest alpha & the svn head. Doing the same thing in HttpClient 3.1 worked as expected. 

This could be normal, as I'm using an InputStream that is indeed not repeatable, but as I'm also using Expect: 100-Continue, the stream shouldn't have been consumed with the first connection (the one that gets a code 401 from the WebDav server), and only in the second one, when the credentials are provided.

The problem is that DefaultRequestDirector.execute doesn't take this into account and assumes that if a request has been tried once, its associated entity (if any) has been consumed.
Here's the fix that I came up with:
Change DefaultRequestDirector.execute so that if the wrapper is an EntityEnclosingRequestWrapper, it checks if the entity has actually been consumed before throwing a NonRepeatableRequestException. I'm using the method isStreaming() from HttpEntity, as it's the closest thing to what I was looking for. Reading the JavaDoc, it could lead to the situation where an entity has started streaming but has not yet finished, and so is not in a state where it can be used. However I don't think that's a problem as the javadoc for HttpEntity.getContent() states that it can't be called two times on a non-repeatable entity, so it's just a matter of when the request will fail.
This lead me to also modify InputStreamEntity (from the httpCore project) as it didn't comply with the javadoc. With these two modifications, The file upload completes successfully.

I also modified:
 * TestInputStreamEntity.testBasics() (from the httpCore project) test so that it complies with getContent()'s Javadoc.
 * TestDefaultClientRequestDirector.FaultyHttpRequestExecutor because it didn't consume the entity's content.
All the tests from both httpCore and httpClient pass.
I tested both InputStreamEntity and BasicHttpEntity.
 
Please keep in mind that I am by no means an httpClient (or http, for that matter) expert, and these modifications may have some unexpected side-effects that I did not foresee, contain plain dumb code, or whatever, so it would be great if someone could review my changes and give their opinion.
"
"HTTPCLIENT-820","DOCUMENTATION","BUG","AbstractHttpClient.addRequestInterceptor should document in what order the interceptors run","http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/impl/client/AbstractHttpClient.html#addRequestInterceptor(org.apache.http.HttpRequestInterceptor) has no documentation. It should at least say what order new interceptors run in. Presumably they run in order by index, but does the lowest or highest index run first?

This class or DefaultHttpClient should also say what interceptors are added by default. That is, what would I be getting rid of by calling clearResponseInterceptors()?"
"HTTPCLIENT-805","RFE","IMPROVEMENT","Pass ClientConnectionManager to DefaultHttpClient constructor","Copied from my mailing list post, Oleg suggested I post it to JIRA for 4.1 fix.

I'm trying to find the least verbose way of configuring a DefaultHttpClient with a ThreadSafeClientConnManager.

The example code given for this goes through a manual process of configuring HttpParams and SchemeRegistry objects, which is more or less copied from the DefaultHttpClient.createHttpParams() and createClientConnectionManager() methods.

It's a bit of a chicken and egg situation - DefaultHttpClient can create its own HttpParams and SchemeRegistry, which are themselves fine, but only once its been constructed, and the constructor requires the ThreadSafeClientConnManager, but that in turn requires the HttpParams and SchemeRegistry objects.  The only way out is to manually construct the HttpParams and SchemeRegistry, which is a waste.

It seems to me that DefaultHttpClient's constructor should take a ClientConnectionManagerFactory instead of a ClientConnectionManager. That way, the createClientConnectionManager() method already has the factory reference, and doesn't have to grub around in the HttpParams object to find it.

The code would then become:

new DefaultHttpClient(new ThreadSafeClientConnManagerFactory(), null);

where ThreadSafeClientConnManagerFactory.newInstance() just constructs ThreadSafeClientConnManager.  There's no manual construction of HttpParams and SchemeRegistry, you just leave it up to DefaultHttpClient.
"
"HTTPCLIENT-233","DOCUMENTATION","IMPROVEMENT","HttpMethodBase Javadoc patches","Clarify that HTTP 1.1 is the default. Attaching."
"HTTPCLIENT-284","DOCUMENTATION","BUG","Updates to connectionStaleCheckingEnabled docs.","Comments from Itai Brickner:

In the Threading section of the UserGuide
(
http://jakarta.apache.org/commons/httpclient/threading.html
)

There is no mentioning of the
'setConnectionStaleCheckingEnabled'
I also felt that it wasn't clear from the APIDOC
(http://jakarta.apache.org/commons/httpclient/apidocs/org/apache/commons/httpclient/MultiThreadedHttpConnectionManager.html)
that staleCheckingEnabled will cause a stale
connection to be reconnected by the
MultiThreadedHttpConnectionManager

thanks,

Itai"
"HTTPCLIENT-3","BUG","BUG","Http Authentication with invalid credentials causes infinite loop","At HttpMethodBase(460), a break statement is executed only if
log.isInfoEnabled(). The break statement needs to be moved outside of the if
statement so that it breaks if realms already contains foo. Patch submitted on
mailing list as per Apache site guidelines."
"HTTPCLIENT-768","BUILD_SYSTEM","","Publish source/javadoc jar files to the Maven repository","It would be really nice if HttpComponents (Core and Client) published jar files to the Maven repository for not just the bytecode, but also for the source and javadoc (done by defining a ""classifier"" attribute of ""javadoc"" or ""source"" for the jar when publishing with Maven).

Having these in the Maven repo allows an IDE (like Eclipse) to auto-download and attach the source/javadoc to the HttpComponent jar files - meaning developers will then see the API documentation automatically in their IDE.  This also greatly aids debugging if one needs to step through HttpComponent code, and placing the source in the hands of more developers also means you might see more patches coming back."
"HTTPCLIENT-150","BUG","BUG","StringIndexOutOfBound exception in RFC2109 cookie validate when host name contains no domain information and is short in length than the cookie domain.","If the target server is identified by hostname only (no domain) and the domain
of the cookie is greater in length than the target hostname, a
StringIndexOutOfBoundsException occurs.

Offending line(s) of code: 174-176 in o.a.c.h.cookie.RFC2109Spec.java"
"HTTPCLIENT-833","BUG","BUG","SSLSocketFactory.connectSocket() possible NPE - or use of wrong variable?","SSLSocketFactory.connectSocket() has a possible NPE at line 324:

            sock.connect(remoteAddress, connTimeout);

Or perhaps this should really be:

            sslsock.connect(remoteAddress, connTimeout);"
"HTTPCLIENT-19","BUG","BUG","Response Folded Headers throws HttpException","As of 4/4/02 CVS repository the HttpMethodBase class
doesn't handle folded headers in the 
readResponseHeaders method

HTTP/1.1 and HTTP/1.0 descriptions of folded headers (see 
section 2.2 Basic Rules)
http://www.ietf.org/rfc/rfc2616.txt
http://www-
old.ics.uci.edu/pub/ietf/http/rfc1945.html#Basic-Rules

I've prepared a patch and was 
emailed to jakarta-commons@jakarta.apache.org"
"HTTPCLIENT-645","IMPROVEMENT","BUG","Cookie.compare(...) uses single instance STRING_COLLATOR to do blocking compares","I am using a MultiThreadedHttpConnectionManager with a single HttpClient instance and multiple GetMethod objects.  I have a 500 thread max.  I recently noticed that all 500 threads are in the same place and seem to be blocking each other - the stack trace is below.  I dug into the Cookie.compare(...) method and saw that it is using STRING_COLLARTOR.compare(c1.getPath(), c2.getPath()).  STRING_COLLATOR is defined as a single instance object, 'private static final RuleBasedCollator STRING_COLLATOR = (RuleBasedCollator) RuleBasedCollator.getInstance(new Locale(""en"", ""US"", """"));'.  I also saw that RuleBasedCollator.compare is synchronized.  That means that every thread that is trying to make a request is getting blocked while it tries to add cookies to the request method.  I do not see a workaround because this is the same static final object in every Cookie instance.  So, the more threads, the more synchronized comparisons.  At times I am fetching URLs all from the same site so I am going through this code a lot.  I need it to be much faster than it currently is because all of my threads are getting eaten up on this call and backlogging my system.  Can a different RuleBasedCollator be used for each compare (use the RuleBasedCollator.getInstance() for every compare?  I think that would solve things.

Name: pool-1-thread-1443: 72.21.206.5
State: BLOCKED on java.text.RuleBasedCollator@190330a owned by: pool-1-thread-1867: 72.21.206.5
Total blocked: 9,598  Total waited: 381

Stack trace: 
java.text.RuleBasedCollator.compare(RuleBasedCollator.java:396)
org.apache.commons.httpclient.Cookie.compare(Cookie.java:484)
org.apache.commons.httpclient.cookie.CookieSpecBase.addInPathOrder(CookieSpecBase.java:578)
org.apache.commons.httpclient.cookie.CookieSpecBase.match(CookieSpecBase.java:557)
org.apache.commons.httpclient.HttpMethodBase.addCookieRequestHeader(HttpMethodBase.java:1179)
org.apache.commons.httpclient.HttpMethodBase.addRequestHeaders(HttpMethodBase.java:1305)
org.apache.commons.httpclient.HttpMethodBase.writeRequestHeaders(HttpMethodBase.java:2036)
org.apache.commons.httpclient.HttpMethodBase.writeRequest(HttpMethodBase.java:1919)
org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:993)
org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:397)
org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:324)"
"HTTPCLIENT-330","BUG","BUG","[PATCH] Wirelog corrections","This patch 

* fixes the problem reported by Geir H. Pettersen <geir at cellus.no>. See
http://marc.theaimsgroup.com/?t=108072355300004&r=1&w=2 for details

* increases the priority of HTTP request/status line & HTTP headers output from
DEBUG to INFO. Quite often request/response content generate excessive amount of
output in the wirelog and produce no valuable debug information of what so ever.
By setting wirelog verbosity to INFO one can turn off the logging of 
request/response content.

I believe the patch should be applied to both CVS HEAD and 2.0 branch. Please
let me know if you agree

Oleg"
"HTTPCLIENT-767","BUG","BUG","Static variables need to be final (or access should be synchronised):","Static variables need to be final (or access should be synchronised):

Index: module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java
===================================================================
--- module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java	(revision 652021)
+++ module-client/src/main/java/org/apache/http/conn/params/HttpConnectionManagerParams.java	(working copy)
@@ -53,7 +53,7 @@
     public static final int DEFAULT_MAX_TOTAL_CONNECTIONS = 20;
 
     /** The default maximum number of connections allowed per host */
-    private static ConnPerRoute DEFAULT_CONN_PER_ROUTE = new ConnPerRoute() {
+    private static final ConnPerRoute DEFAULT_CONN_PER_ROUTE = new ConnPerRoute() {
         
         public int getMaxForRoute(HttpRoute route) {
             return ConnPerRouteBean.DEFAULT_MAX_CONNECTIONS_PER_ROUTE;
"
"HTTPCLIENT-952","BUG","BUG","SSLSocketFactory.createSSLContext does not process trust store","org.apache.http.conn.ssl.SSLSocketFactory.createSSLContext() does not process a provided trust store.
Only the default (cacerts) is processed. An additional provided trust store is ignored.
Adding the ""trusted"" certificate to the keystore, the peer is authenticated.

Eventually
        tmfactory.init(keystore);
needs to be
        tmfactory.init(truststore);

"
"HTTPCLIENT-1113","BUG","BUG","Error downloading text file with gzip content encoding","Hello I am getting an exception when I try to download certain files.

I don't have control over the host server, only the client.  Here's my client code:

		HttpParams params = new BasicHttpParams();
		params.setParameter(CoreConnectionPNames.CONNECTION_TIMEOUT, 300000L);
		params.setParameter(ClientPNames.HANDLE_REDIRECTS, true);

		// This client indicates to servers that it will support 'gzip'
		// and 'deflate' compressed responses.
		ContentEncodingHttpClient.setDefaultHttpParams(params);
		ContentEncodingHttpClient client = new ContentEncodingHttpClient();

		if (user != null && password != null) {
			String hostname = url.getHost();
			HttpHost hostHttp = new HttpHost(hostname, 80, ""http"");
			HttpHost hostHttps = new HttpHost(hostname, 443, ""https"");
			client.getCredentialsProvider().setCredentials(
			        new AuthScope(hostname, 80), 
			        new UsernamePasswordCredentials(user, password));
	
			client.getCredentialsProvider().setCredentials(
			        new AuthScope(hostname, 443), 
			        new UsernamePasswordCredentials(user, password));
	
			// Create AuthCache instance
			AuthCache authCache = new BasicAuthCache();
			// Generate BASIC scheme object and add it to the local auth cache
			BasicScheme basicAuth = new BasicScheme();
			authCache.put(hostHttp, basicAuth);
			authCache.put(hostHttps, basicAuth);
	
			// Add AuthCache to the execution context
			BasicHttpContext localcontext = new BasicHttpContext();
			localcontext.setAttribute(ClientContext.AUTH_CACHE, authCache);
		}
		HttpGet httpget = new HttpGet(url.toString());
		httpget.setHeader(""If-Modified-Since"", lastModified);


		HttpResponse response = client.execute(httpget);
		responseCode = response.getStatusLine().getStatusCode();
		HttpEntity entity = response.getEntity();
		if (responseCode == HttpStatus.SC_NOT_MODIFIED) {
			
		} else if (responseCode == HttpStatus.SC_OK && entity != null) {
			outStream = new BufferedOutputStream(new FileOutputStream(outFilename));
			entity.writeTo(outStream);
		}

Here's the log output:

DEBUG [2011-08-02 01:23:01,031] [org.apache.http.impl.conn.SingleClientConnManager:212] Get connection for route HttpRoute[{}->http://<host>]
DEBUG [2011-08-02 01:23:01,036] [org.apache.http.impl.conn.DefaultClientConnectionOperator:145] Connecting to <host>/<IP>:80
DEBUG [2011-08-02 01:23:01,057] [org.apache.http.client.protocol.RequestAddCookies:132] CookieSpec selected: best-match
DEBUG [2011-08-02 01:23:01,057] [org.apache.http.client.protocol.RequestAuthCache:75]   Auth cache not set in the context
DEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.client.DefaultRequestDirector:631]        Attempt 1 to execute request
DEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.DefaultClientConnection:264] Sending request: GET <file> HTTP/1.1
DEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.Wire:63]     >> ""GET <file> HTTP/1.1[\r][\n]""
DEBUG [2011-08-02 01:23:01,058] [org.apache.http.impl.conn.Wire:63]     >> ""If-Modified-Since: Mon, 01 Aug 2011 18:26:09 CEST[\r][\n]""
DEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> ""Host: <host>[\r][\n]""
DEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> ""Connection: Keep-Alive[\r][\n]""
DEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> ""User-Agent: Apache-HttpClient/4.1.1 (java 1.5)[\r][\n]""
DEBUG [2011-08-02 01:23:01,059] [org.apache.http.impl.conn.Wire:63]     >> ""Accept-Encoding: gzip,deflate[\r][\n]""
DEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.Wire:63]     >> ""[\r][\n]""
DEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:268] >> GET <file> HTTP/1.1
DEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:271] >> If-Modified-Since: Mon, 01 Aug 2011 18:26:09 CEST
DEBUG [2011-08-02 01:23:01,060] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Host: <host>
DEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Connection: Keep-Alive
DEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> User-Agent: Apache-HttpClient/4.1.1 (java 1.5)
DEBUG [2011-08-02 01:23:01,061] [org.apache.http.impl.conn.DefaultClientConnection:271] >> Accept-Encoding: gzip,deflate
DEBUG [2011-08-02 01:23:01,085] [org.apache.http.impl.conn.Wire:63]     << ""HTTP/1.1 200 OK[\r][\n]""
DEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << ""Server: nginx/0.8.54[\r][\n]""
DEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << ""Date: Mon, 01 Aug 2011 23:23:01 GMT[\r][\n]""
DEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << ""Content-Type: text/plain[\r][\n]""
DEBUG [2011-08-02 01:23:01,086] [org.apache.http.impl.conn.Wire:63]     << ""Last-Modified: Wed, 20 Jul 2011 14:39:57 GMT[\r][\n]""
DEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << ""Transfer-Encoding: chunked[\r][\n]""
DEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << ""Connection: keep-alive[\r][\n]""
DEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << ""Vary: Accept-Encoding[\r][\n]""
DEBUG [2011-08-02 01:23:01,087] [org.apache.http.impl.conn.Wire:63]     << ""Expires: Wed, 31 Aug 2011 23:23:01 GMT[\r][\n]""
DEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << ""Cache-Control: max-age=2592000[\r][\n]""
DEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << ""Content-Encoding: gzip[\r][\n]""
DEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.Wire:63]     << ""[\r][\n]""
DEBUG [2011-08-02 01:23:01,088] [org.apache.http.impl.conn.DefaultClientConnection:249] Receiving response: HTTP/1.1 200 OK
DEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:252] << HTTP/1.1 200 OK
DEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Server: nginx/0.8.54
DEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Date: Mon, 01 Aug 2011 23:23:01 GMT
DEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Content-Type: text/plain
DEBUG [2011-08-02 01:23:01,089] [org.apache.http.impl.conn.DefaultClientConnection:255] << Last-Modified: Wed, 20 Jul 2011 14:39:57 GMT
DEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Transfer-Encoding: chunked
DEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Connection: keep-alive
DEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Vary: Accept-Encoding
DEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Expires: Wed, 31 Aug 2011 23:23:01 GMT
DEBUG [2011-08-02 01:23:01,090] [org.apache.http.impl.conn.DefaultClientConnection:255] << Cache-Control: max-age=2592000
DEBUG [2011-08-02 01:23:01,091] [org.apache.http.impl.conn.DefaultClientConnection:255] << Content-Encoding: gzip
DEBUG [2011-08-02 01:23:01,091] [org.apache.http.impl.client.DefaultRequestDirector:477]        Connection can be kept alive indefinitely
DEBUG [2011-08-02 01:23:01,131] [org.apache.http.impl.conn.Wire:63]     << ""600a[\r][\n]""
DEBUG [2011-08-02 01:23:01,132] [org.apache.http.impl.conn.Wire:77]     << ""[0x1f]""
DEBUG [2011-08-02 01:23:03,838] [org.apache.http.impl.conn.Wire:63]     << ""[\r][\n]""

.... (Content)

DEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.SingleClientConnManager:267] Releasing connection org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter@2aa3873
DEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.SingleClientConnManager:285] Released connection open but not reusable.
DEBUG [2011-08-02 01:23:03,839] [org.apache.http.impl.conn.DefaultClientConnection:152] Connection shut down
ERROR [2011-08-02 01:23:03,840] [app]        Exception downloading file
java.io.EOFException
        at java.util.zip.GZIPInputStream.readUByte(GZIPInputStream.java:224)
        at java.util.zip.GZIPInputStream.readUShort(GZIPInputStream.java:214)
        at java.util.zip.GZIPInputStream.readHeader(GZIPInputStream.java:153)
        at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:75)
        at java.util.zip.GZIPInputStream.<init>(GZIPInputStream.java:85)
        at org.apache.http.client.entity.GzipDecompressingEntity.getContent(GzipDecompressingEntity.java:63)
        at org.apache.http.util.EntityUtils.consume(EntityUtils.java:65)
        at org.apache.http.conn.BasicManagedEntity.ensureConsumed(BasicManagedEntity.java:98)
        at org.apache.http.conn.BasicManagedEntity.writeTo(BasicManagedEntity.java:115)
        at util.FileDownload.download(FileDownload.java:188) <--- my app

Does this happen because the server doesn't specify the content length?"
"HTTPCLIENT-232","IMPROVEMENT","IMPROVEMENT","Make MultiThreadedHttpConnectionManager defaults public statics.","Could the defaults for MultiThreadedHttpConnectionManager be made public
constants? I would do it my self since I have karma as a contributer to [lang]
and [codec] but I do not want to step on anyones toes. ;-)

Patch attached."
"HTTPCLIENT-736","REFACTORING","IMPROVEMENT","dependencies for route planner implementations","The implementations of HttpRoutePlanner that we have depend on the ConnectionManager, but use it only to look up the SchemeRegistry. Consider to depend only on the SchemeRegistry.

"
"HTTPCLIENT-1134","DOCUMENTATION","IMPROVEMENT","BasicResponseHandler Javadoc Needs Clarification","The class-level javadoc for BasicResponseHandler indicates that it reads the response body before throwing an Exception for responses with status code >= 300, which is not the case."
"HTTPCLIENT-262","DOCUMENTATION","BUG","Minor typo in org.apache.commons.httpclient.Wire 2.0-rc1","Minor typo ""...may noy be null"" in 
public static final void output(final String s) and
public static final void input(final String s)
of org.apache.commons.httpclient.Wire."
"HTTPCLIENT-270","BUG","BUG","return value of PostMethod#removeParameter","<HttpClient2.0-rc1>

About 
public boolean removeParameter(String paramName)
                 throws IllegalArgumentException
method.

-------------------------------------------------
PostMethod method = new PostMethod(uri);
method.addParameter(""name"", ""Matsui Hideki"");
boolean b;
b = method.removeParameter(""name""); // returns ""true"".
b = method.removeParameter(""XXXX""); // returns ""true"". why??? 
---------------------------------------------------

sorry for my poor english."
"HTTPCLIENT-332","IMPROVEMENT","IMPROVEMENT","Connection timeout logic redesign","Changelog:

* CreateSocket method with timeout parameter added to the ProtocolSocketFactory
interface

* TimeoutController related code factored out of HttpConnection class and moved
into ControllerThreadSocketFactory helper class

* ReflectionSocketFactory helper class added. This factory encapsulates
reflection code to call JDK 1.4 Socket#connect method if supported

* All protocol socket factories now attempt to initially use
ReflectionSocketFactory if required to create a socket within a given limit of
time. If reflection fails protocol socket factories fall back onto the good ol'
ControllerThreadSocketFactory

Benefits:

* HttpConnection code got a lot cleaner
* When running in modern JREs expensive timeout controller thread per connection
attempt is no longer needed
* Ugly code intended to work around limitations of the older JREs is now
confined to a few helper classes that can be easily thrown away once we move
onto Java 1.4

Let me know what you think

Oleg"
"HTTPCLIENT-636","IMPROVEMENT","IMPROVEMENT","Revise internal data structures of ThreadSafeClientConnManager","ThreadSafeClientConnManager internal data structures can be improved:
- keep track of issued connections with weak references
- use class derived from WeakReference instead of a lookup table for callbacks from ReferenceThread
  (or drop ReferenceThread in favor of occasionally polling the issued connections for leaks)
"
"HTTPCLIENT-35","RFE","IMPROVEMENT","[HttpClient] Better proxy support in HttpMultiClient","If proxy requires authentication, it sends status 407 (Proxy Authentication 
Required) and the response header ""Proxy-Authenticate"" (see RFC2616; e.g. Squid 
can be configured to do so).
HttpClient doesn't yet process this response.
Behavior should be similar to processing of status 401 (Unauthorized)."
"HTTPCLIENT-895","IMPROVEMENT","IMPROVEMENT","Log creation impairs performance","Running JProfiler on a program that uses HttpClient with a ThreadSafeClientConnManager, revealed that 5% of the time was spent constructing Log instances in class ClientParamsStack.

Oleg did some further investigation and found that DefaultRequestDirector also has the same problem.

A simple solution would be to make the Log a static member variable, and do this on all classes for consistency.  However this might not be the best solution for interoperating with some frameworks (see http://wiki.apache.org/jakarta-commons/Logging/StaticLog)

Another solution would be to simply remove the Log from the affected classes, although they are presumably there for a reason...
"
"HTTPCLIENT-358","IMPROVEMENT","BUG","Auto method retrial broken","Folks,
While working on the exception handling guide for the 3.0-alpha2 release I
stumbled upon a problem with HttpTimeoutException and its subclasses. In 3.0a1
HttpTimeoutException subclasses HttpRecoverableException which causes HTTP
methods failed due to a connect or socket timeout to be automatically retried. 

[INFO] HttpMethodDirector - -Recoverable exception caught when processing request
[INFO] HttpMethodDirector - -Recoverable exception caught when processing request
[INFO] HttpMethodDirector - -Recoverable exception caught when processing request
[INFO] HttpMethodDirector - -Recoverable exception caught when processing request
[WARN] HttpMethodDirector - -Recoverable exception caught but
MethodRetryHandler.retryMethod() returned false, rethrowing exception
org.apache.commons.httpclient.IOTimeoutException: Read timed out
	at
org.apache.commons.httpclient.HttpConnection$WrappedInputStream.handleException(HttpConnection.java:1350)
	at
org.apache.commons.httpclient.HttpConnection$WrappedInputStream.read(HttpConnection.java:1360)
	at java.io.FilterInputStream.read(FilterInputStream.java:66)
	at java.io.PushbackInputStream.read(PushbackInputStream.java:120)
	at org.apache.commons.httpclient.HttpParser.readRawLine(HttpParser.java:76)
	at org.apache.commons.httpclient.HttpParser.readLine(HttpParser.java:104)
	at org.apache.commons.httpclient.HttpConnection.readLine(HttpConnection.java:1054)
	at
org.apache.commons.httpclient.HttpMethodBase.readStatusLine(HttpMethodBase.java:1785)
	at
org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1546)
	at org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:977)
	at
org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:383)
	at
org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:164)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:437)
	at org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:324)
	at Test.main(Test.java:13)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.read(SocketInputStream.java:129)
	at java.net.SocketInputStream.read(SocketInputStream.java:182)
	at
org.apache.commons.httpclient.HttpConnection$WrappedInputStream.read(HttpConnection.java:1358)
	... 13 more
Exception in thread ""main"" 

This probably is not what we want. Besides, for non-idempotent methods this may
simply be fatal and result in all sorts of unpleasant side-effects.

One possibilty that I personally favour is to make HttpTimeoutException class
extend IOException instead of HttpRecoverableException. There are others. The
question is whether timeout exceptions should be considered recoverable from the
conseptual standpoint. What do you think?

Oleg"
"HTTPCLIENT-1036","IMPROVEMENT","BUG","StringBody has incorrect default for characterset","StringBody defaults to Charset.defaultCharset() if the charset is not provided.

This means that the default depends on the current host.

The default should be US-ASCII (as was the case with StringPart in Commons HttpClient 3.1)."
"HTTPCLIENT-1029","DOCUMENTATION","IMPROVEMENT","Update 3.x legacy homepage with end of life notification and pointer to HTTPComponents","If you google for ""http client"" or ""httpclient"" or ""apache http client"" the first result is always legacy Commons-HttpClient page.  If you follow the link, there's no indication whatsoever on the legacy page that its not the latest version, or that it's end-of-lifed.  Unless you're already aware of HttpComponents, there's no obvious way to find it from the legacy page.  The only reference to HttpComponents is actually in the 'History' section.  

The source for the legacy page should be updated to indicate Commons-HttpClient is an end-of-lifed project and should provide a pointer to the new HttpComponents page in a more prominent location."
"HTTPCLIENT-865","OTHER","BUG","HttpClient OSGi Export-Package doesn't specify version","The ""Export-Package"" manifest entry doesn't specify the version of the package being exported.  This means that packages importing it can't specify a version to import."
"HTTPCLIENT-780","DOCUMENTATION","BUG","ProxyHost/HttpHost: Checks for null when javadoc document null ok","The constructor javadocs for ProxyHost and HttpHost all state that null is an allowed value - but there's an check in the HttpHost constructor for this which throws IllegalArgumentException.

(Actually allowing null as documented would also allow for a spring wiring remaining the same when using a proxy or not - steering the values from a propertyfile.)"
"HTTPCLIENT-587","BUG","BUG","derelativizing of relative URIs with a scheme is incorrect","URI constructor ""public URI(URI base, URI relative) throws URIException"" assumes that if given 'relative' URI has a scheme, it should provide an authority and complete path to the constructed URI. However, a URI can have a scheme but still be relative, requiring the authority and base path of the 'base' URI. 

Demonstration code:

URI base = new URI(""http://www.example.com/some/page"");
URI rel = new URI(""http:boo"");
URI derel = new URI(base,rel);
derel.toString();
(java.lang.String) http:boo

In fact, derel should be ""http://www.example.com/some/boo"". 

RFC2396 is a little confused about this; section 3.1 states """"Relative URI references are distinguished from absolute URI in that they do not begin with a scheme name."" But, in section 5, there are several sentences talking about relative URIs that begin with schemes (and how this prevents using relative URIs that have leading path segments that look like scheme identifiers). 

RFC3896, which supercedes RFC2396, removes the implication a relative URI cannot begin with a scheme, leaving the other text explcitly discussing relative URIs with schemes. 

Both Firefox (1.5) and IE (6.0) treat ""http:boo"" the same as ""boo"" for purposes of derelativization against an HTTP base URI, which would give the final URI ""http://www.example.com/some/boo"" in the example above. 

Even relative URIs like ""http:../../boo"" are explicitly legal. 

"
"HTTPCLIENT-1168","DOCUMENTATION","BUG","HTTPClient doesn't send authentication header in threaded environment","Using HTTPClient with multiple threads and basic authentication seems to create a race condition. The request headers sometimes don't contain the authorization entry, which results in a 401 (although the username and password credentials are correctly set). "
"HTTPCLIENT-388","DOCUMENTATION","BUG","http.connection-manager.timeout is a LONG not an INTEGER","Documentation is wrong.

Table in Preference Architecture page states http.connection-manager.timeout 
is an Integer.

Doing:

setParameter(""http.connection-manager.timeout"", new Integer(n));

Causes:

java.lang.ClassCastException
	at 
org.apache.commons.httpclient.params.DefaultHttpParams.getLongParameter
(DefaultHttpParams.java:171)
	at 
org.apache.commons.httpclient.params.HttpClientParams.getConnectionManagerTimeo
ut(HttpClientParams.java:143)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod
(HttpMethodDirector.java:161)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:437)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:324)"
"HTTPCLIENT-929","BUG","BUG","Request with two forward slashes for path fails","The following code demonstrates the problem:
        DefaultHttpClient client = new DefaultHttpClient();
        client.execute(new HttpGet(""http://www.google.com//""));

When a request is made, the DefaultRequestDirector invokes rewriteRequestURI(). I don't fully understand why this method does what it does. For a non-proxied request, it attempts to render the URI to a relative URI. In doing so, it tries to create a relative URI whose content is ""//"". Per RFC 2396 section 5 (Relative URI References), a relative URI that begins with ""//"" is a network-path reference, and the ""//"" must be immediately followed by an authority. Therefore, while ""http://www.google.com//"" is a valid absolute URI, ""//"" is not a valid relative one. The resulting exception:

[...]
Caused by: org.apache.http.ProtocolException: Invalid URI: http://www.google.com//
	at org.apache.http.impl.client.DefaultRequestDirector.rewriteRequestURI(DefaultRequestDirector.java:339)
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:434)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)
	... 31 more
Caused by: java.net.URISyntaxException: Expected authority at index 2: //
	at java.net.URI$Parser.fail(URI.java:2809)
	at java.net.URI$Parser.failExpecting(URI.java:2815)
	at java.net.URI$Parser.parseHierarchical(URI.java:3063)
	at java.net.URI$Parser.parse(URI.java:3024)
	at java.net.URI.<init>(URI.java:578)
	at org.apache.http.client.utils.URIUtils.createURI(URIUtils.java:106)
	at org.apache.http.client.utils.URIUtils.rewriteURI(URIUtils.java:141)
	at org.apache.http.client.utils.URIUtils.rewriteURI(URIUtils.java:159)
	at org.apache.http.impl.client.DefaultRequestDirector.rewriteRequestURI(DefaultRequestDirector.java:333)
	... 33 more
"
"HTTPCLIENT-100","RFE","IMPROVEMENT","Add possibility to disable automatic authentication header processing.","In the application I'm working on I need the possibility to manually get the 
WWW-Authenticate header instead of letting the HttpClient process it 
automatically. Instead of rewriting the execute() method in a subclass I added 
a configuration setting, similar to the followRedirects flag. Diffs below for 
anyone interested."
"HTTPCLIENT-563","DOCUMENTATION","BUG","Incorrect copyright statements","Most of the copyright statements in http-core are for 1999-2004.  These should
be updated with the correct years."
"HTTPCLIENT-754","BUG","BUG","BasicClientCookie.toString() contains 'name' instead of 'value' when writing out cookie value","{noformat}
buffer.append(""[name: "");
buffer.append(this.value);
{noformat}

should be

{noformat}
buffer.append(""[value: "");
buffer.append(this.value);
{noformat}

Will provide a patch soon."
"HTTPCLIENT-69","DOCUMENTATION","IMPROVEMENT","User/Developer Documentation","- quotes from user's on why they used it.
- better project docs, including checkstyle and clover reports, and changelog
- examples showing how to configure logging and why you may want to
- Links on HttpClient to 'sister' projects such as Slide, Cactus and Latka to
show where how it's being used."
"HTTPCLIENT-167","BUG","BUG","SSL Tunneling does not work with MultiThreadedHttpConnectionManager","The HttpConnection is released prematurely when doing SSL tunneling with the
MultiThreadedHttpConnectionManager.  The ConnectMethod releases the connection
in responseBodyConsumed() before it can be used by the real method."
"HTTPCLIENT-749","RFE","IMPROVEMENT","HttpClient 'ParamBeans' for easier configuration","As I did for a 'core' here I would like to contribute for 'client' part as few 'ParamBeans' for easier external configuration... Any comment or improvement is very welcome..."
"HTTPCLIENT-942","DOCUMENTATION","BUG","ClientConnectionRelease example is incorrect","http://svn.apache.org/repos/asf/httpcomponents/httpclient/tags/4.0.1/httpclient/src/examples/org/apache/http/examples/client/ClientConnectionRelease.java

is incorrect: 

1. if error happens in BufferedReader constructor (OutOfMemoryError, StackOverflowError), reader.close() is not called and connection is not released

2. if error happens in reader.readLine(), reader.close() is called, but httpget.abort() is not."
"HTTPCLIENT-726","IMPROVEMENT","IMPROVEMENT","review TSCCM for spurious wakeups","Review the code of the TSCCM/ConnPoolByRoute for places where spurious wakeups may happen.
Verify that this case is dealt with correctly. Unit test by giving invalid wakeup signals?"
"HTTPCLIENT-880","BUG","BUG","Check for correct content-type in URLEncodedUtils not working for encoding-suffixes","Dear DEV-Team,

i am developing an application with the httpclient. Today i found a small problem, related to URLEncodedUtils.

Our Tomcat-Server deliveres for Server-Requests, the HTTP-Header: ""Content-Type=application/x-www-form-urlencoded;charset=UTF-8"", but the httpclient only checks for: ""Content-Type=application/x-www-form-urlencoded"". This failing check results in an empty result of call to the method: URLEncodedUtils.parse(entity);

Following source-code causes the prob: 

public class URLEncodedUtils {

    /**
     * Returns true if the entity's Content-Type header is
     * <code>application/x-www-form-urlencoded</code>.
     */
    public static boolean isEncoded (final HttpEntity entity) {
        final Header contentType = entity.getContentType();
        return (contentType != null && contentType.getValue().equalsIgnoreCase(CONTENT_TYPE));
    }
}

IMO the method should be changed to:


public class URLEncodedUtils {

    /**
     * Returns true if the entity's Content-Type header is
     * <code>application/x-www-form-urlencoded</code>.
     */
    public static boolean isEncoded (final HttpEntity entity) {
        final Header contentType = entity.getContentType();
        return (contentType != null && contentType.getValue().startsWith(CONTENT_TYPE + "";""));
    }
}

Best Regards,"
"HTTPCLIENT-328","RFE","IMPROVEMENT","Proxy tunneling/auth with CONNECT for non-HTTP protocols","HttpClient would be even more useful if it supported connections tunneled 
through proxies and proxy authentication for non-HTTP protocols. E.g. Binary 
protocols such as SSH or JXTA-TCP could be tunneled through a web proxy if 
HttpClient provided access to the underlying Socket after the negotiations 
(auth, CONNECT) with the web proxy were complete."
"HTTPCLIENT-589","IMPROVEMENT","IMPROVEMENT","Do not consume the remaining response content if the connection is to be closed","I am working on a HttpClient-based application to send and receive potentially large files (up to Gigabytes). When receiving large files the application allows the user to cancel the download, at which time it closes the response input stream behind the scenes.

The input stream currently provided by HttpMethodBase.getResponseBody() for un-chunked responses with a known content length is a ContentLengthInputStream, which automatically reads the remainder of the wrapped response instead of closing it straight away. This behaviour does not work well with very large files as the data is downloaded unnecessarily and the connection is held open for long very periods.

Per the HTTP 1.1 spec section 14.10 it seems to me that either a server or a client in an HTTP 1.1 connection can use the Connection:close directive to signal that a connection will be non-persistent, and will therefore not require that all data be read before the connection can be released (the cleaning up ContentLengthInputStream performs for persistent connections).

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.10

Could HttpMethodBase be modified to check for this directive, from the server or client, and avoid wrapping the response input stream in ContentLengthInputStream when it is present? It seems straight-forward, though there may be side-effects I am not aware of. 
"
"HTTPCLIENT-1041","BUG","BUG","Enabling wire logging changes isEof/isStale behavior","If you enable wire logging, DefaultClientConnection wraps the SocketInputBuffer with a LoggingSessionInputBuffer. This hides the EofSensor interface implemented by SocketInputBuffer (but not LoggingSessionInputBuffer), which makes at least AbstractHttpClientConnection.isEof() and isStale() methods behave differently.

(That is, stale connection checks won't really work as intended if wire logging is enabled. Which makes it a bit difficult to debug problems related to stale connections...)

Proposed fix: implement EofSensor interface in LoggingSessionInputBuffer (delegating it to wrapped buffer).
"
"HTTPCLIENT-693","BUG","BUG","DEFAULT_HEADERS not added to subsequent requests","DEFAULT_HEADERS are added to the original request only, not to subsequent requests for redirects or authentication."
"HTTPCLIENT-1160","RFE","IMPROVEMENT","LayeredSchemeSocketFactory.createLayeredSocket() should have access to HttpParams","We use a custom implementation of LayeredSchemeSocketFactory that manages a keystore location through HttpParams. That allows us to use different keystores on a per connection basis.

When a proxy is used LayeredSchemeSocketFactory.createLayeredSocket() is invoked which does not have a parameter that passes the HttpParams along. In consequence certificate authentication fails in our implementation. Is there a reason why all other factory methods in the super class have an HttpParams parameter except for LayeredSchemeSocketFactory.createLayeredSocket()?

The downstream bug is here:

369805: certificate authentication with custom keystore fails behind proxy
https://bugs.eclipse.org/bugs/show_bug.cgi?id=369805

Any input would be greatly appreciated."
"HTTPCLIENT-631","IMPROVEMENT","BUG","String constants should be final","RFC2109Spec - SET_COOKIE_KEY

RFC2965Spec - SET_COOKIE2_KEY

both should be final."
"HTTPCLIENT-1155","IMPROVEMENT","BUG","CachingHttpClient should have similar behavior as AbstractHttpClient when executing with ResponseHandler","When calling execute on the AbstractHttpClient with a  ResponseHandler, the AbstractHttpClient will attempt to Consume the Entity and close any open connections before returning. This behavior is not currently in the CachingHttpClient. 

This can lead to connection leaks when switching to CachingHttpClient, becuase the responsibility to fully consume the entity is now on the ResponseHandler instead on the HttpClient.

Here is the code that does the existing 'auto-close' behavior: ""org.apache.http.impl.client.AbstractHttpClient.java"" lines 1080-1111"
"HTTPCLIENT-1107","BUG","BUG","HttpClient does not retry authentication when multiple challenges are present if the primary one fails","I'm trying to request a page from IIS (6 and 7.5).  If the IIS is configured with providers for ""negotiate"" and ""ntlm"" then the Negotiate authentication is tried and fails, but it does not then try to use the NTLM authentication which is what I require.  If I removed ""negotiate"" as a provider from IIS and just use NTLM then all works well - but this is not a solution as I don't have control of the web servers. 

Output below...


[DEBUG] SingleClientConnManager - Get connection for route HttpRoute[{}->http://WIN-HNB91NNAB2G]
[DEBUG] DefaultClientConnectionOperator - Connecting to WIN-HNB91NNAB2G/147.183.80.134:80
[DEBUG] RequestAddCookies - CookieSpec selected: best-match
[DEBUG] DefaultHttpClient - Attempt 1 to execute request
[DEBUG] DefaultClientConnection - Sending request: GET / HTTP/1.1
[DEBUG] wire - >> ""GET / HTTP/1.1[\r][\n]""
[DEBUG] wire - >> ""Host: WIN-HNB91NNAB2G[\r][\n]""
[DEBUG] wire - >> ""Connection: Keep-Alive[\r][\n]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/4.1 (java 1.5)[\r][\n]""
[DEBUG] wire - >> ""[\r][\n]""
[DEBUG] headers - >> GET / HTTP/1.1
[DEBUG] headers - >> Host: WIN-HNB91NNAB2G
[DEBUG] headers - >> Connection: Keep-Alive
[DEBUG] headers - >> User-Agent: Apache-HttpClient/4.1 (java 1.5)
[DEBUG] wire - << ""HTTP/1.1 401 Unauthorized[\r][\n]""
[DEBUG] wire - << ""Content-Type: text/html[\r][\n]""
[DEBUG] wire - << ""Server: Microsoft-IIS/7.5[\r][\n]""
[DEBUG] wire - << ""WWW-Authenticate: Negotiate[\r][\n]""
[DEBUG] wire - << ""WWW-Authenticate: NTLM[\r][\n]""
[DEBUG] wire - << ""Date: Fri, 15 Jul 2011 12:15:11 GMT[\r][\n]""
[DEBUG] wire - << ""Content-Length: 58[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] DefaultClientConnection - Receiving response: HTTP/1.1 401 Unauthorized
[DEBUG] headers - << HTTP/1.1 401 Unauthorized
[DEBUG] headers - << Content-Type: text/html
[DEBUG] headers - << Server: Microsoft-IIS/7.5
[DEBUG] headers - << WWW-Authenticate: Negotiate
[DEBUG] headers - << WWW-Authenticate: NTLM
[DEBUG] headers - << Date: Fri, 15 Jul 2011 12:15:11 GMT
[DEBUG] headers - << Content-Length: 58
[DEBUG] DefaultHttpClient - Connection can be kept alive indefinitely
[DEBUG] DefaultHttpClient - Target requested authentication
[DEBUG] DefaultTargetAuthenticationHandler - Authentication schemes in the order of preference: [negotiate, NTLM, Digest, Basic]
[DEBUG] DefaultTargetAuthenticationHandler - negotiate authentication scheme selected
[DEBUG] NegotiateScheme - Received challenge '' from the auth server
[DEBUG] DefaultHttpClient - Authorization challenge processed
[DEBUG] DefaultHttpClient - Authentication scope: NEGOTIATE <any realm>@win-hnb91nnab2g:80
[DEBUG] DefaultHttpClient - Found credentials
[DEBUG] wire - << ""You do not have permission to view this directory or page.""
[DEBUG] RequestAddCookies - CookieSpec selected: best-match
[DEBUG] NegotiateScheme - init WIN-HNB91NNAB2G
[ERROR] RequestTargetAuthentication - Authentication error: Invalid name provided (Mechanism level: Could not load configuration file C:\WINDOWS\krb5.ini (The system cannot find the file specified))
[DEBUG] DefaultHttpClient - Attempt 2 to execute request
[DEBUG] DefaultClientConnection - Sending request: GET / HTTP/1.1
[DEBUG] wire - >> ""GET / HTTP/1.1[\r][\n]""
[DEBUG] wire - >> ""Host: WIN-HNB91NNAB2G[\r][\n]""
[DEBUG] wire - >> ""Connection: Keep-Alive[\r][\n]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/4.1 (java 1.5)[\r][\n]""
[DEBUG] wire - >> ""[\r][\n]""
[DEBUG] headers - >> GET / HTTP/1.1
[DEBUG] headers - >> Host: WIN-HNB91NNAB2G
[DEBUG] headers - >> Connection: Keep-Alive
[DEBUG] headers - >> User-Agent: Apache-HttpClient/4.1 (java 1.5)
[DEBUG] wire - << ""HTTP/1.1 401 Unauthorized[\r][\n]""
[DEBUG] wire - << ""Content-Type: text/html[\r][\n]""
[DEBUG] wire - << ""Server: Microsoft-IIS/7.5[\r][\n]""
[DEBUG] wire - << ""WWW-Authenticate: Negotiate[\r][\n]""
[DEBUG] wire - << ""WWW-Authenticate: NTLM[\r][\n]""
[DEBUG] wire - << ""Date: Fri, 15 Jul 2011 12:15:11 GMT[\r][\n]""
[DEBUG] wire - << ""Content-Length: 58[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] DefaultClientConnection - Receiving response: HTTP/1.1 401 Unauthorized
[DEBUG] headers - << HTTP/1.1 401 Unauthorized
[DEBUG] headers - << Content-Type: text/html
[DEBUG] headers - << Server: Microsoft-IIS/7.5
[DEBUG] headers - << WWW-Authenticate: Negotiate
[DEBUG] headers - << WWW-Authenticate: NTLM
[DEBUG] headers - << Date: Fri, 15 Jul 2011 12:15:11 GMT
[DEBUG] headers - << Content-Length: 58
[DEBUG] DefaultHttpClient - Connection can be kept alive indefinitely
[DEBUG] DefaultHttpClient - Target requested authentication
[DEBUG] NegotiateScheme - Received challenge '' from the auth server
[DEBUG] NegotiateScheme - Authentication already attempted
[DEBUG] DefaultHttpClient - Authorization challenge processed
[DEBUG] DefaultHttpClient - Authentication scope: NEGOTIATE <any realm>@win-hnb91nnab2g:80
[DEBUG] DefaultHttpClient - Authentication failed
[DEBUG] wire - << ""You do not have permission to view this directory or page.""
content:You do not have permission to view this directory or page.
[DEBUG] SingleClientConnManager - Releasing connection org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter@17fa65e
"
"HTTPCLIENT-1136","BUG","BUG","BasicClientConnectionManager.releaseConnection accesses poolEntry using non-standard lock","According to the annotation, poolEntry is @GuardedBy(""this"").

However, in at least one place, it is accessed without holding a lock on this: 

BasicClientConnectionManager.releaseConnection synchronizes on managedConn, and then accesses poolEntry without synchronising on this.

[Synch. only works if all parties use the same lock.]"
"HTTPCLIENT-475","RFE","IMPROVEMENT","Provide support for unconnected sockets","Overview description:
If Proxy settings are incorrect or host does not reply, the
HttpClient.executeMethod() hangs, and HttpMethod.abort() does not stop it. Thus,
you cannot assert that the entire application will stop immediately on demand.

Expected Results:
During a HttpMethod.executeMethod(), HttpMethod.abort() should cancel
immediately the executeMethod().

Actual Results:
If HttpMethod.executeMethod() freezes because of Proxy bad settings or not
responding hostname (in fact impossible to open the socket), the abort() method
does not do anything.

Platform:
I tested it on Windows XP and Linux Debian with HttpClient 3.0 RC2 (but if you
look further I point the problem and the source code of the nightly build is
identical).

See comments for the dialogue about the problem, and 2 Test cases. The solution
is described at the end, but it may implies a change in the API and works only
since Java 1.4."
"HTTPCLIENT-733","RFE","RFE","Implementation of Delete method","The HTTP request method, Delete, had not been implemented. I needed it and created an HttpDelete class modeled after HttpGet."
"HTTPCLIENT-612","BUG","BUG","FileRequestEntity in SVN does not close input file","FileRequestEntity.java in SVN does not close input file - however the version on the web page:

http://jakarta.apache.org/commons/httpclient/performance.html

has a finally clause that closes the file ;-) - perhaps the source code should too...!"
"HTTPCLIENT-111","RFE","IMPROVEMENT","Add multi-part post support","Add a new method to support multi-part post."
"HTTPCLIENT-679","BUG","BUG","URI Absolutization does not follow browser behavior","This was encountered using Heritrix to crawl a prominent website.

The URI resulting from the HttpClient URI constructor (base, relative) does not follow browser behavior:
URI newUrl = new URI(new URI(""http://www.theirwebsite.com/browse/results?type=browse&att=1""), ""?sort=0&offset=11&pageSize=10"")

Results in newUrl:
http://www.theirwebsite.com/browse/?sort=0&offset=11&pageSize=10

The desired behavior based on Firefox and IE should be:
http://www.theirwebsite.com/browse/results?sort=0&offset=11&pageSize=10

These browsers treat the question mark similar to a directory separator and do not require a file to be specified before the query.

HttpClient's current behavior does not correspond to current browser behavior and leads to an inability to crawl certain websites if HttpClient's URI class is used.

"
"HTTPCLIENT-418","BUG","BUG","ALLOW_CIRCULAR_REDIRECTS has no effect if references include query string","ALLOW_CIRCULAR_REDIRECTS parameter in HttpClientParameters has no effect if
circular reference contains in URL parameters."
"HTTPCLIENT-872","RFE","IMPROVEMENT","Add preemptive authentication","Wishlist request for preemptive authentication to be included in the API, like HttpClient 3.x had.  There is an example ClientPreemptiveBasicAuthentication.java that uses HttpRequestInterceptor which I had adapted to my application and it works fine."
"HTTPCLIENT-980","IMPROVEMENT","BUG","CachingHttpClient returns a 503 response when the backend HttpClient produces an IOException","The CachingHttpClient returns an HTTP 503 response when the backend HttpClient throws an IOException.

It happens for instance when the backend is DefaultHttpClient (AbstractHttpClient), issuing a request to a server not listening on the target port.
Well, it sounds tricky, but it makes the HttpClient not having a consistant behaviour in an implementation using both caching and regular clients.

If a 503 should really be returned in that case, I suggest the AbstractHttpClient to return it and the CachingHttpClient to just propagate any exception thrown by the backend.
"
"HTTPCLIENT-997","IMPROVEMENT","IMPROVEMENT","cache module should handle out-of-order validations properly and unconditionally refresh","There is a protocol recommendation that when we attempt to revalidate a cache entry, but we receive a response that has a Date header that's actually *older* than that of our current entry, we SHOULD revalidate again unconditionally with either max-age=0 or no-cache (since some upstream cache would appear to be out-of-date).

http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.2.6

"
"HTTPCLIENT-454","BUG","BUG","Connection with the proxy is not reopened if an proxy auth failure occurs while SSL tunnel is being established","Connection with the proxy is not reopened if an proxy auth failure occurs while
SSL tunnel is being established.

This problem has been reported by on the httpclient-user by Gebhard Gaukler
<gebhard.gaukler at db.com>.

My bad.

Oleg"
"HTTPCLIENT-509","DESIGN_DEFECT","BUG","need members of MultipartRequestEntity to be ""protected"" instead of ""private"" to make it extendable for multipart/related","As explained in the mailing-list[1], I'd like to have some of 
MultipartRequestEntity move from ""private"" visibility to ""protected"" visibility,
to be able to extend as MultipartRelatedRequestEntity. Namely, the attribute
""parts"" and the method ""getMultipartBoundary"" would be needed.

Thank you.

[1]
http://mail-archives.apache.org/mod_mbox/jakarta-httpclient-dev/200510.mbox/%3c87irw18ndm.fsf@meuh.mnc.ch%3e"
"HTTPCLIENT-319","BUG","BUG","ArrayIndexOutOfBounds Exception on invalid content-length","If the server returns an invalid (not parsable to int) content legnth the method
protected int getResponseContentLength() in HttpMethodBase walks off the
end of the Header[] array and throws the ArrayIndexOutOfBoundsException.

The loop at line 687 in HttpMethodBase.java:

   for (int i = headers.length - 1; i >= 0; i++) {

starts at the end of the array, but uses ++ intead of -- and so walks off the
end of the array on the next line if the header is invalid.  If the header is
valid the return statement in the try block succeeds so there is no error.

The fix is simply to change the line to be

   for (int i = headers.length -1; i>=0; i--) {"
"HTTPCLIENT-961","SPEC","BUG","not all applicable URIs are invalidated on PUT/POST/DELETEs that pass through client cache","""Some HTTP methods MUST cause a cache to invalidate an entity. This is either the entity referred to by the Request-URI, or by the Location or Content-Location headers (if present). These methods are: PUT, DELETE, POST.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.10

The current caching implementation only invalidates the Request URI, and not those present in the Location or Content-Location headers on the request.

I have a patch that fixes this which I will upload momentarily.
"
"HTTPCLIENT-677","IMPROVEMENT","IMPROVEMENT","Connection pool uses Thread.interrupt()","The connection pool for TSCCM uses Thread.interrupt() to wake up waiting threads.
This interferes with application interrupts.

- expose InterruptedException in interface
- change pool implementation to use wait/notify
"
"HTTPCLIENT-1098","IMPROVEMENT","IMPROVEMENT","Populating exception message with InetSocketAddress.getHostName() can take a long time","In the PlainSocketFactory class, when a SocketTimeoutException occurs a call is made to InetSocketAddress.getHostName() when generating the exception message. Unfortunately, this call can take a long time. In my case, the address I am specifying is an IP address, which InetSocketAddress attempts to perform a reverse-lookup on to determine the hostname; however, since  the address does not have a hostname assigned to it, the operation takes a long time to return.

I'm attaching a patch for trunk with my proposed fix. Viewing the source history, it looks like the code used to have the behavior I'm proposing, but it was changed in revision 1070943. Based on the source commits and linked issues, I cannot determine a specific reason for the change. If there is a reason the code needs to be the way it is, then I apologize for inconvenience I have caused."
"HTTPCLIENT-125","BUG","BUG","empty host header with ip address","file: HttpMethodBase.java method: addHostRequestHeader

HttpClient writes an empty Host header if the host is referred using IP address.
HTTP 1.1 RFC is not too clear what should be used in this case. However, other
HTTP 1.1 implementations (e.g. Java 1.4.0) uses IP address instead of dns name
in the header.

Furthermore, some HTTP server implementations (e.g. Jetty) will return ""400 bad
request"" if it encounters an empty Host header. That may be a bug in Jetty, but
it might be a good idea to use IP address in Host header to increase compability."
"HTTPCLIENT-759","BUG","BUG","DefaultClientRequestDirector doesn't release connections back to ClientConnectionManager on exceptions","See HTTPCLIENT-747 for more info.  Basically the deal is that an entry is always allocated, but currently it's only released if execute(..) completes normally."
"HTTPCLIENT-919","RFE","IMPROVEMENT","NTLM implementation lacks support for NTLMv1, NTLMv2, and NTLM2 Session forms of NTLM","The current HttpClient implementation lacks support for all enhancements to NTLM after Windows 95.  That includes NTLMv1, NTLMv2, and NTLM2 Session Response varieties of the protocol.

This seriously impacts the usability of HttpClient in enterprise situations, which has required the Lucene Connector Framework team to extend HttpClient to address the issue.

I've attached a patch which contains the implementation used by LCF.
"
"HTTPCLIENT-25","BUG","BUG","[httpclient] Incorrect credentials loop infinitely","If incorrect credentials are assigned to the request, HttpClient will loop 
forever.  It should only try once, and fail with an HttpException if a request 
with credentials set fails.

In org.apache.commons.httpclient.HttpMethodBase.execute(), a check is needed to 
track if credentials have been sent before."
"HTTPCLIENT-837","BUG","BUG","Wire produces invalid log skipping zero bytes in certain cases","WireLogInputStream class line 82 check if the byte returned is not -1 meaning end of stream. But the condition is wrong in case if this byte is 0, it should look like

if (l != -1) {
//...
}
"
"HTTPCLIENT-915","RFE","RFE","Provide a clean mechanism to attatch user define attributes to connections","It would be nice to have a way to attach user defined attributes to a connection.
Ideally it'd be nice if such support could be added to HttpClientConnection, but understandably this may not be possible due to back-compatibility issues.
So, we could have something like HttpConnectionContext perhaps (or similar) with:

HttpConnectionContext#setAttribute(String name, Object value)
Object HttpConnectionContext#getAttribute(String name)

This would be made available in the HttpContext of a request (like the connection is today):

HttpConnectionContext connectionContext = (HttpConnectionContext) httpContext.getAttribute(ExecutionContext.HTTP_CONNECTION_CONTEXT);

This would make a few things much cleaner to implement than they are today: The most obvious being my current use case of wanting connection isolated cookies.

Currently to achieve this goal we need to provide custom client connection + connection operator + connection manager implementations. Then there is no clean way to currently obtain the actual connection instance created by a custom operator in the HttpContext: As it's wrapped by the connection pool and #getWrappedConnection is protected - so we need to resort to reflection in interceptors.

Providing a clean mechanism for attaching user defined attributes to a connection instance as described above would make such implementations far far simpler.
"
"HTTPCLIENT-593","IMPROVEMENT","BUG","ProtocolSocketFactory equals and hashCode don't support subclassing","In the implemenation of equals and hashCode for the classes
org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory
org.apache.commons.httpclient.protocol.SSLProtocolSocketFactory

The implementation of equals and hashCode attempts to make all instances of the classes equal.  However, the manner in which the methods are coded makes it necessary for any subclass to implement equals and hashCode themselves.  A minor change to the methods in these classes will make possible to subclass these factories without re-implementing the equals and hashCode.  The method equals should be written as

        return ((obj != null) && obj.getClass().equals(getClass()));

rather than

        return ((obj != null) && obj.getClass().equals(DefaultProtocolSocketFactory.class));

And similarly, the hashCode method should be

        return getClass().hashCode();

rather than

        return DefaultProtocolSocketFactory.class.hashCode();"
"HTTPCLIENT-1024","BUG","BUG","cache does not validate multiple cached variants","There is a bug in CachingHttpClient, where when we attempt to collect all the etags for existing cached variants so we can send a conditional request to the origin, we accidentally don't find any, and send an unconditional request instead."
"HTTPCLIENT-287","IMPROVEMENT","IMPROVEMENT","Setting CONNECTION_TIMEOUT and SO_TIMEOUT on a per-method basis","The capability of setting connection timeout and socket timeout on a per-method
basis should be provided. This would enable different threads, sharing the same
HttpClient, to set different timeouts for their methods executions."
"HTTPCLIENT-310","BUG","BUG","Memory leak in MultiThreadedHttpClient caused by bad .equals()","Note: I have '2.0 release candidate 1'; I'm not sure which version this
translates into.  The bug is definitely present in the current source.

MultiThreadedHttpClient uses the following code:

// Look for a list of connections for the given config
HostConnectionPool listConnections = (HostConnectionPool) 
    mapHosts.get(hostConfiguration);
if (listConnections == null) { 
    // First time for this config
    listConnections = new HostConnectionPool();
    listConnections.hostConfiguration = hostConfiguration;
    mapHosts.put(hostConfiguration, listConnections);
}


The hash map relys on HostConfiguration's .equals() to resolve equality &
determine if there is a mapping for the configuration.

HostConfiguration has the following in it's .equals() method:

if (!protocol.equals(config.getProtocol())) {
    return false;
}

. . . and Protocol has:

if (obj instanceof Protocol) {
            
    Protocol p = (Protocol) obj;
            
    return (
        defaultPort == p.getDefaultPort()
        && scheme.equalsIgnoreCase(p.getScheme())
        && secure == p.isSecure()
        && socketFactory.equals(p.getSocketFactory()));

}

However, there is no .equals() method in any of the ProtocolSocketFactory
objects, and there isn't any note in the interface about the necessity of the
.equals() method."
"HTTPCLIENT-497","IMPROVEMENT","BUG","Logger (Category) names don't follow common pattern","The Wire class uses two loggers named unexpected. The ""org.apache.commons.""
prefix is missing - so you can't mute all debug level statements with a
one-liner in you log4j.properties for example:

  log4j.logger.org.apache.commons.httpclient INFO

You have to add this, too:

  log4j.logger.httpclient INFO

Please prepend the ""org.apache.commons."" before both names.

Cheers,
Christian

<code>
class Wire {

    public static Wire HEADER_WIRE = new
Wire(LogFactory.getLog(""httpclient.wire.header""));
    
    public static Wire CONTENT_WIRE = new
Wire(LogFactory.getLog(""httpclient.wire.content""));

</code>

http://svn.apache.org/viewcvs.cgi/jakarta/commons/proper/httpclient/trunk/src/java/org/apache/commons/httpclient/Wire.java?rev=155418&view=markup"
"HTTPCLIENT-867","DOCUMENTATION","BUG","Logging documentation refers to nonexisting level ERROR in java.util.logging section","Page ""Logging Practices""  Section ""java.util.logging Examples"" 
(http://hc.apache.org/httpcomponents-client/logging.html) 
says:
""org.apache.http.level = FINEST
org.apache.http.wire.level = ERROR""

However, there is no such thing as java.util.logging.Level.ERROR

Did you mean SEVERE as in
Logger.getLogger(""org.apache.http.wire"").setLevel(Level.SEVERE);

Thanks"
"HTTPCLIENT-45","RFE","IMPROVEMENT","HTTP Version configuration and tracking","HTTP version tracking is currently oversimplified with a single http11 boolean. 
Extend this to handle any http version simply, and efficiently.

Possible suggestion:
> get rid of setHttp11() an isHttp11
> void setHttpVersion(String version)
> String getHttpVersion()
> boolean isHttpVersion(String version)"
"HTTPCLIENT-264","BUG","BUG","Crashes when it gets a redirect","I get the following crash when VFS (not my code) calls HttpClient. This code 
worked with some older version of HttpClient (is my belief) but doesn't appear 
to work with CVS HEAD, hence this posting.

Note: I'm sorry, but I don't know which Method it was calling, but hopefully a 
redirect is a redirect and the bug stands irrespective of that.

This is major to me (and Ruper) 'cos it is the first thing it does before 
attempting to read the contents of that location.

regards,

Adam

java.lang.NullPointerException
	at 
org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse
(HttpMethodDirector.java:454)
	at org.apache.commons.httpclient.HttpMethodDirector.isRetryNeeded
(HttpMethodDirector.java:639)
	at org.apache.commons.httpclient.HttpMethodDirector.executeMethod
(HttpMethodDirector.java:145)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:378)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:268"
"HTTPCLIENT-819","DOCUMENTATION","BUG","HttpParams doesn't document its key values","http://hc.apache.org/httpcomponents-core/httpcore/apidocs/org/apache/http/params/HttpParams.html should either list the meaningful parameter names with the meanings of their values, or should link to the other classes like HttpClientParams and AuthParams that make it usable. Probably, each class that uses HttpParams should also describe the meaningful values so that human readers find the descriptions however we look for them."
"HTTPCLIENT-369","BUG","BUG","Missing skip()-Method in ContentLengthInputStream","ContentLengthInputStream is missing the skip()-Method.

This causes the internal pos variable to get out of sync with the content 
length. 
We oberseved that closing the stream caused a wait time of about 15 sec in 
routines which use the skip()-method of InputStream.

Here's a possible implementation which should solve the problem:

    public long skip(long len) throws IOException {
        long count = super.skip(len);
        pos += count;
        return count;
    }"
"HTTPCLIENT-366","DOCUMENTATION","BUG","PostMethod Java doc refers to wrong section of RFC1945","""The HTTP POST method is defined in section 9.5 of RFC1945"" should read ""The
HTTP POST method is defined in section 8.3 of RFC1945""

Change 9.5 to 8.3."
"HTTPCLIENT-462","IMPROVEMENT","BUG","ProtocolException thrown on slightly broken headers","HTTPClient throws an exception when parsing headers returned by GET from the
following URL:

 http://butler.cit.nih.gov/hembase/hembase.taf

The headers returned are as follows:

HTTP/1.0 200 OK\r\nServer: WebSTAR/1.0 ID/ACGI\r\nMIME-Version:
1.0\r\nContent-Type: text/html\r\nSet-Cookie:
Tango_UserReference=ADC5871C57FABEDEC63DD47B; path=/\n\r\r\n\r\n<!DOCTYPE HTML
PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"">...

Please note the superfluous \r in the line separating headers from the body.
IMHO this type of error should generate a warning, but then it should cause a
graceful recovery. Currently a ProtocolException is thrown.

Standard java.net.HttpURLConnection handles this just fine, without giving any
warning."
"HTTPCLIENT-141","IMPROVEMENT","BUG","Using deprecated class javax.servlet.http.HttpUtils","[javac]
test-webapp/src/org/apache/commons/httpclient/RedirectServlet.java:74: warning:
javax.servlet.http.HttpUtils in javax.servlet.http has been deprecated
    [javac]             to =
HttpUtils.getRequestURL(request).append(""?"").append(request.getQueryString()).toString();

The javax.servlet.http.HttpUtils class is deprecated in Tomcat 4.1.18 and should
not be used."
"HTTPCLIENT-902","BUG","BUG","In case of ConnectTimeoutException : HttpRequestRetryHandler is not used.",""
"HTTPCLIENT-244","IMPROVEMENT","BUG","URI uses  sun.security.action.GetPropertyAction","URI uses a sun.* class but should not.  Use of this class should be removed.

Reported my Mark Wilcox"
"HTTPCLIENT-688","BUG","BUG","HttpOptions.getAllowedMethods expects single Allow header","In client.methods.HttpOptions.getAllowMethods(), a single Allow header is parsed to obtain the result. Since the value is a comma-separated list, servers can optionally return the values in multiple headers. HttpMethod.getHeaders(name) should be used instead of .getFirstHeader(name).
"
"HTTPCLIENT-74","RFE","IMPROVEMENT","J2EE FORM authentication (also affects pluggable authentication)","Add support for J2EE style FORM authentication type. 

Unlike the BASIC and DIGEST types this is not handled by HTTP headers so needs
an adjustment to the way in which the authentication is sent. As far as i can
tell from my testing with one or two J2EE servers the way to successfully login
requires request of a protected page which will respond with the login FORM and
then the submission of that form. The two requests must be associated with one
another using the jsessionid cookie.

It seems to me that this 'bug' must be solved in cooperation with the recent
discussions of pluggable authentication module. i suggestion the following
signature: 

PluggableAuthenticator.authenticate(HttpMethod method, HttpState state). 

This mirrors the existing Authenticator method but also requires change to the
state object to allow access to the connection properties (i dont know how this
affects MultiClient). Alternately we could go for: 

PluggableAuthenticator.authenticate(HttpMethod method, HttpClient client).

In either case Authenticator needs a way to know which plugin to call. I suggest
modification of HttpMethodBase to detect the 'j_security_check' form action in
the response and automatically submit credentials if they are provided using the
new class 

J2EEFormAuthenticator implements PluggableAuthenticator."
"HTTPCLIENT-222","BACKPORT","BUG","Via NTLM proxy to SSL Apache/BasicAuth. - worked in may 22nd, but broken in beta1","Hi there,

This morning I downloaded beta 1 and tried a small piece of code to connect to 
a SSLified apache server (using basic authentication) via a MS-Proxy 2.0 with 
NTLM enabled. The sourcecode of my crashme is based on the 1st attachment for 
HTTPCLIENT-153. It differs from the original in using basic authentication for the 
webserver instead of NTLM.

It failed with this error:

--
10-jun-2003 16:39:05 org.apache.commons.httpclient.HttpMethodBase 
processAuthenticationResponse
INFO: Already tried to authenticate to ""website#"" but still receiving 407.
Status: 407 : Proxy authentication required
--

Then I downloaded a fresh night build (commons-httpclient-20030605) which also 
failed :/

Then I went back to an old build from May (commons-httpclient-20030522) which 
worked like a charm!!!

Using MSIE I can succesfully connect to the apache server. I know it's not a 
problem with typos because I have MSIE ask me for all creds.

Seems somethings got broken along the way. If I can help, please ask!

Cheers."
"HTTPCLIENT-931","BUG","BUG","Change value of 'Expect' header in org.apache.http.client.methods.HttpPost","see original report at http://code.google.com/p/android/issues/detail?id=7208.

i'm going to apply the obvious patch to Android:

diff --git a/src/org/apache/http/params/CoreProtocolPNames.java b/src/org/apache/http/params/CoreProtocolPNames.java
index a42c5de..a0a726d 100644
--- a/src/org/apache/http/params/CoreProtocolPNames.java
+++ b/src/org/apache/http/params/CoreProtocolPNames.java
@@ -94,8 +94,8 @@ public interface CoreProtocolPNames {
 
     /**
      * <p>
-     * Activates 'Expect: 100-Continue' handshake for the 
-     * entity enclosing methods. The purpose of the 'Expect: 100-Continue'
+     * Activates 'Expect: 100-continue' handshake for the
+     * entity enclosing methods. The purpose of the 'Expect: 100-continue'
      * handshake to allow a client that is sending a request message with 
      * a request body to determine if the origin server is willing to 
      * accept the request (based on the request headers) before the client
diff --git a/src/org/apache/http/protocol/HTTP.java b/src/org/apache/http/protocol/HTTP.java
index de76ca6..9223955 100644
--- a/src/org/apache/http/protocol/HTTP.java
+++ b/src/org/apache/http/protocol/HTTP.java
@@ -60,7 +60,7 @@ public final class HTTP {
     public static final String SERVER_HEADER = ""Server"";
     
     /** HTTP expectations */
-    public static final String EXPECT_CONTINUE = ""100-Continue"";
+    public static final String EXPECT_CONTINUE = ""100-continue"";
 
     /** HTTP connection control */
     public static final String CONN_CLOSE = ""Close"";
"
"HTTPCLIENT-11","BUG","BUG","null domains break Cookie.java","the domain is assumed to be non-null in a few places in Cookie.java, see matches
method, for example"
"HTTPCLIENT-182","BUG","BUG","httpclient charset encooding loosing problem","file: org\apache\commons\httpclient\HttpConstants.java 


line: near 261


---------------------------------


public static String getContentString(final byte[] data, String charset) {


        return getContentString(data, 0, data.length);


    }


---------------------------------


must be


---


        return getContentString(data, 0, data.length, charset);


---"
"HTTPCLIENT-597","IMPROVEMENT","IMPROVEMENT","MultithreadedConnectionManager and IdleConnectionTimeoutThread improvements","Changes to MultithreadedConnectionManager and IdleConnectionTimeoutThread following the suggestions of Balazs SZCS.


-------- Forwarded Message --------
From: SZCS Balazs <Balazs.Szuecs@wave-solutions.com>
Reply-To: HttpClient User Discussion
<httpclient-user@jakarta.apache.org>
To: 'HttpClient User Discussion' <httpclient-user@jakarta.apache.org>
Subject: RE: MultithreadedConnectionManager pooling strategy
Date: Mon, 15 May 2006 15:26:08 +0200

Hello,

I made two changes to the HttpClient code:

1) in the class ConnectionPool in the method getFreeConnection( ... ) I
changed freeConnections.removeFirst() to freeConnections.removeLast(). Now
the container for free connections behaves as a stack rather than a queue.

2) additionally I changed the IdleConnectionTimeoutThread, in the run()
method I added connectionManager.deleteClosedConnections() so that the pool
size is maintained correctly.

What do you think?
Balazs"
"HTTPCLIENT-737","BUG","BUG","EchoHandler:104 possible NPE","Line 104 of EchoHandler is

    bae.setContentType(entity.getContentType());

a few lines previously, entity is checked for null, so it appears that entity can be null."
"HTTPCLIENT-521","DOCUMENTATION","BUG","SimpleHttpConnectionManager is used incorrectly by tutorial code","Using pretty well standard (from the tutorial) code causes the 
SimpleHttpConnectionManager to print its ""being used incorrectly"" warning if 
the connection times out (or other I/O exception occurs).

I will attach a simple test I made to demonstrate this."
"HTTPCLIENT-1116","BUG","BUG","ResponseCachingPolicy uses integers for sizes","ResponseCachingPolicy currently uses integers for interpreting the size of Content-Length, as well internally.

This causes issues in attempting to use the module for caching entities that are over 2GB in size, the module does not fail gracefully, but throws a NumberFormatException

I have a patch that fixes this, by promoting the int -> long, which should allow for larger entities to be cached, it also updates the public facing API where possible, I don't think that the promotion should break compatibility massively

The changes can also be seen here:
https://github.com/GregBowyer/httpclient/commit/1197d3f94bd2eedcec32646cd6146748ca2e6fa1"
"HTTPCLIENT-1105","RFE","","Built-in way to do auto-retry for certain status codes","The HttpRequestRetryHandler mechanism is great.  It allows API users to plug in their own logic to control whether or not a retry should automatically be done, how many times it should be retried, etc.  That works perfectly in scenarios where an exception is caught while issuing the request.  It falls short, however, in this scenario...

If I'm hitting a service that returns a 503, I want to be able to retry that request automatically as well.  As of right now, I need to write my own logic to accomplish that, and it's clunky trying to integrate it with the httpClient.execute() call, since it's my ResponseHandler impl that ends up getting the 503.  I can see use cases for auto-retrying upon getting other HTTP statuses as well, not just 503.

My request here is...I would love to be able to configure, either on the HttpClient itself or on a wrapping class or something, that a request should automatically be retried if the HTTP status code is among of a set of statuses that I configure.  It would be nice if you could set the max # of retries, an optional sleep time in between retries (perhaps optional incremental backoff if you want to get fancy).  I'm not sure if this is possible, but it would be nice if -- when this type of status-based retry is enabled -- my ResponseHandler wouldn't even get invoked until retry was successful.

Here's an alternative suggestion, possibly simpler to build, but definitely not as elegant:

In my ResponseHandler, you could throw a RetryRequestException or something like that, and the calling code would catch that and do as expected.  That might simplify the mechanism so to speak.

Anyway, I would love not to have to roll my own retry code, since I suspect this is something that hundreds (thousands?) of HttpClient users have had to code.  Seems like providing a standardized, well-written way to do it would go a long way to helping many coders out there.

Thanks!"
"HTTPCLIENT-22","BUG","BUG","shouldn't automatically set Content-Length in request header","currently, httpclient automatically add Content-Length: 0 in the request 
header, this is causing problems with some web servers, particularly, with

ar.atwola.com

Try the following URL
http://ar.atwola.com/file/adsWrapper.js

It will block indefinitely. This problem can be fixed by not sending the 
Content-Length header, this is the browser's behavior. I'm not sure why this 
casue problem, but let's conform to a standard browser's practice and avoid 
troubles."
"HTTPCLIENT-320","BUG","BUG","""Socket Closed"" IOException thrown by HttpConnection","HttpClient.java was modified in version 2.0 Final in method executeMethod().
The call to connection.setSoTimeout() used to be in RC3 after the call to
connection.isOpen(), but in the final version the call happens before the call 
to isOpen(). The result of the change is that the setSoTimeout() call could 
throw IOException because of closed socket.

I would fix the problem by adding to HttpConnection.setSoTimeout() (and to 
other similar methods in HttpConnection) an explicit check (a call to isOpen
()) whether the socket is closed as the existence of socket object does not 
guarantee it. I.e the following code:

    public void setSoTimeout(int timeout)
        throws SocketException, IllegalStateException {
        LOG.debug(""HttpConnection.setSoTimeout("" + timeout + "")"");
        soTimeout = timeout;
        if (socket != null) {
            socket.setSoTimeout(timeout);
        }
    }

would be changed to

    public void setSoTimeout(int timeout)
        throws SocketException, IllegalStateException {
        LOG.debug(""HttpConnection.setSoTimeout("" + timeout + "")"");
        soTimeout = timeout;
        if (isOpen()) {
            socket.setSoTimeout(timeout);
        }
    }"
"HTTPCLIENT-588","BUG","BUG","relative URIs with internal double-slashes ('//') misparsed","URI.parseUriReference()'s heuristic for interpreting URI parts is thrown off by relative URIs which include an internal '//'. As a result, portions of the supplied relative URI (path) can be lost. 

For example:

URI rel = new URI(""foo//bar//baz"");
rel.toString();
(java.lang.String) //bar//baz

The culprit seems to be line 1961 of URI improperly concluding that two slashes later than the beginning of 'tmp' are still indicative the URI is a 'net_path'. 

A possible quick fix might be to add a '!isStartedFromPath &&' to the beginning of the line 1961 test, making the line:

            if (!isStartedFromPath && at + 2 < length && tmp.charAt(at + 1) == '/') {

... and thus preventing the misguided authority-parsing from happening when earlier analysis already identified the current string as a strictly path-oriented URI.

(It also appears the setting of the is_net_path boolean at the end of this if's block may be wrong; this code is run for hier_path URIs that are not net_paths in the 2396 syntax. For example:

URI uri = new URI(""http://www.example.com/some/page"");
uri.isNetPath();
 (boolean) true 

)"
"HTTPCLIENT-554","RFE","IMPROVEMENT","AbstractHttpProcessor hard-wired against a single context","I can't use the AbstractHttpProcessor as it is for asynchronously
processing different requests, because it is hard-wired to use a
single context which can not be changed. Async requires different
contexts for requests. Patch follows.

cheers,
  Roland"
"HTTPCLIENT-301","IMPROVEMENT","BUG","Cookie rejected","Hello,

I'm using HttpClient 1.0 rc2 to login in the SourceForge website and perform
some operations, but i'm getting the following error:

Page 1 from https://sourceforge.net/account/login.php
6 dc. 2003 23:45:27 org.apache.commons.httpclient.HttpMethodBase
processResponseHeaders
ATTENTION: Cookie rejected: ""username=l6qpwtK5hpE%3D"". Illegal domain attribute
"".sourceforge.net"". Domain of origin: ""sourceforge.net""
6 dc. 2003 23:45:27 org.apache.commons.httpclient.HttpMethodBase readResponseBody

The cookie returned by Sourceforge is rejected because the domain for the
request was sourceforge.net and the domain for the cookie was .sourceforge.net
I have tried to change the cookie policy to all available options, but none work. 
CookiePolicy.setDefaultPolicy(CookiePolicy.COMPATIBILITY);

What can i do?

Thanks,
Ludovic"
"HTTPCLIENT-103","BUG","BUG","ChunkedInputStream incorrectly handles chunksize without semicolon","ChunkedInputStream does not correctly read the chunk size when a semicolon does
not appear in the first line of the chunk.  If whitespace exists between the
chunk size value and the end of line and no semicolon is present, the whitespace
is not removed before parseInt is called resulting in an IOException ""Bad chunk
size""

I can not tell from RFC2616 if whitespace is legal here, but I have received it
from at least one web server.  The relevant section is 3.6.1.

A small patch repairs the problem.  I will attach it immediately."
"HTTPCLIENT-654","IMPROVEMENT","BUG","Cookie class cannot handle IPv6 literals","When performing requests using IPv6 literals, Cookie.setDomain() will attempt to trim the port number by cutting off the domain string at the first colon. This leads to MalformedCookieExceptions being thrown by CookieSpecBase later on."
"HTTPCLIENT-459","IMPROVEMENT","IMPROVEMENT","Document the problem with MS impl of digest authentication with older JREs and stale connection check","It seems like digest authentication, when used with a username of the format:
domain\username fails in httpclient-3.0-rc2.

I did confirm that digest authentication does work by connecting to a local
Apache HTTP 2.0 server, using just a username and password (no domain\username).
However, it does not support the MD5-sess algorithm, and the server I am getting
the failure from is using MD5-sess. 

It may turn out the username is not causing the problem, but one thing is
consistent--I can connect to the site in the logs below using httpclient-2.0.2.
It fails when I use identical Java code, with the addition of AuthScope, when
using httpclient-3.0-rc2. I will also attach Java code that reproduces the problem.

The following are wire and debug logs from httpclient-2.0.2 and
httpclient-3.0-rc2 respectively. The first one connects and gets an 'HTTP 200'
response. The second one, using 3.0-rc2 fails with an 'HTTP 401'.

LOGS
===============================================================
commons-httpclient-2.0.2 (works):
2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java version: 1.3.1
2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java vendor: IBM Corporation
2005/05/13 11:05:15:185 EDT [DEBUG] HttpClient - Java class path: 
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system name: Windows XP
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system architecture: x86
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - Operating system version: 5.1
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SUN 1.2: SUN (DSA key/parameter
generation; DSA signing; SHA-1, MD5 digests; SecureRandom; X.509 certificates;
JKS keystore)
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SunJCE 1.22: SunJCE Provider
(implements DES, Triple DES, Blowfish, PBE, Diffie-Hellman, HMAC-MD5, HMAC-SHA1)
2005/05/13 11:05:15:205 EDT [DEBUG] HttpClient - SunJSSE 1.0303: Sun JSSE
provider(implements RSA Signatures, PKCS12, SunX509 key/trust factories, SSLv3,
TLSv1)
2005/05/13 11:05:20:893 EDT [DEBUG] HttpConnection - HttpConnection.setSoTimeout(0)
2005/05/13 11:05:20:893 EDT [DEBUG] HttpMethodBase - Execute loop try 1
2005/05/13 11:05:20:913 EDT [DEBUG] header - >> ""GET
/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\r][\n]""
2005/05/13 11:05:20:913 EDT [DEBUG] HttpMethodBase - Adding Host request header
2005/05/13 11:05:20:913 EDT [DEBUG] header - >> ""User-Agent: Jakarta
Commons-HttpClient/2.0.2[\r][\n]""
2005/05/13 11:05:20:913 EDT [DEBUG] header - >> ""Host:
mappoint-css.partners.extranet.microsoft.com[\r][\n]""
2005/05/13 11:05:21:173 EDT [DEBUG] header - >> ""[\r][\n]""
2005/05/13 11:05:21:273 EDT [DEBUG] header - << ""HTTP/1.1 401 Unauthorized[\r][\n]""
2005/05/13 11:05:21:273 EDT [DEBUG] header - << ""Content-Length: 1656[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] header - << ""Content-Type: text/html[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] header - << ""Server: Microsoft-IIS/6.0[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] header - << ""WWW-Authenticate: Digest
qop=""auth"",algorithm=MD5-sess,nonce=""b2a83a38cd57c501af3ad2c91f189512060524424ffc2b818c9920db15cd247a9d47cf5a789d63c6"",opaque=""1704373a505e74c4ec692978e5c1a539"",charset=utf-8,realm=""Digest""[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] header - << ""X-Powered-By: ASP.NET[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] header - << ""Date: Fri, 13 May 2005 15:05:37
GMT[\r][\n]""
2005/05/13 11:05:21:283 EDT [DEBUG] HttpMethodBase - Authorization required
2005/05/13 11:05:21:283 EDT [DEBUG] HttpAuthenticator - Authenticating with the
'Digest' authentication realm at mappoint-css.partners.extranet.microsoft.com
2005/05/13 11:05:21:283 EDT [DEBUG] DigestScheme - Using qop method auth
2005/05/13 11:05:21:283 EDT [DEBUG] HttpMethodBase - HttpMethodBase.execute():
Server demanded authentication credentials, will try again.
2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Resorting to protocol
version default close connection policy
2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Should NOT close
connection, using HTTP/1.1.
2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Execute loop try 2
2005/05/13 11:05:21:293 EDT [DEBUG] header - >> ""GET
/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\r][\n]""
2005/05/13 11:05:21:293 EDT [DEBUG] HttpMethodBase - Request to add Host header
ignored: header already added
2005/05/13 11:05:21:293 EDT [DEBUG] header - >> ""User-Agent: Jakarta
Commons-HttpClient/2.0.2[\r][\n]""
2005/05/13 11:05:21:293 EDT [DEBUG] header - >> ""Host:
mappoint-css.partners.extranet.microsoft.com[\r][\n]""
2005/05/13 11:05:21:293 EDT [DEBUG] header - >> ""Authorization: Digest
username=""domain\user"", realm=""Digest"",
nonce=""b2a83a38cd57c501af3ad2c91f189512060524424ffc2b818c9920db15cd247a9d47cf5a789d63c6"",
uri=""/CustomerData-30/CustomerDataService.asmx"", qop=""auth"",
algorithm=""MD5-sess"", nc=00000001, cnonce=""393a8abf65cd20f85ffdf46a9273b28b"",
response=""854bf54261112caf2e86652276cb2ce6"",
opaque=""1704373a505e74c4ec692978e5c1a539""[\r][\n]""
2005/05/13 11:05:21:293 EDT [DEBUG] header - >> ""[\r][\n]""
2005/05/13 11:05:21:994 EDT [DEBUG] header - << ""HTTP/1.1 200 OK[\r][\n]""HTTP
result: 200

===========================================================

commons-httpclient-3.0-rc2 (does not work):
2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.useragent = Jakarta Commons-HttpClient/3.0-rc2
2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.protocol.version = HTTP/1.1
2005/05/13 11:16:54:881 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.connection-manager.class = class
org.apache.commons.httpclient.SimpleHttpConnectionManager
2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.protocol.cookie-policy = rfc2109
2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.protocol.element-charset = US-ASCII
2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.protocol.content-charset = ISO-8859-1
2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.method.retry-handler =
org.apache.commons.httpclient.DefaultHttpMethodRetryHandler@5048d78c
2005/05/13 11:16:54:891 EDT [DEBUG] DefaultHttpParams - -Set parameter
http.dateparser.patterns = [EEE, dd MMM yyyy HH:mm:ss zzz, EEEE, dd-MMM-yy
HH:mm:ss zzz, EEE MMM d HH:mm:ss yyyy, EEE, dd-MMM-yyyy HH:mm:ss z, EEE,
dd-MMM-yyyy HH-mm-ss z, EEE, dd MMM yy HH:mm:ss z, EEE dd-MMM-yyyy HH:mm:ss z,
EEE dd MMM yyyy HH:mm:ss z, EEE dd-MMM-yyyy HH-mm-ss z, EEE dd-MMM-yy HH:mm:ss
z, EEE dd MMM yy HH:mm:ss z, EEE,dd-MMM-yy HH:mm:ss z, EEE,dd-MMM-yyyy HH:mm:ss
z, EEE, dd-MM-yyyy HH:mm:ss z]
2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java version: 1.3.1
2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java vendor: IBM Corporation
2005/05/13 11:16:54:911 EDT [DEBUG] HttpClient - -Java class path: 
2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system name: Windows XP
2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system architecture: x86
2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -Operating system version: 5.1
2005/05/13 11:16:54:941 EDT [DEBUG] HttpClient - -SUN 1.2: SUN (DSA
key/parameter generation; DSA signing; SHA-1, MD5 digests; SecureRandom; X.509
certificates; JKS keystore)
2005/05/13 11:16:54:951 EDT [DEBUG] HttpClient - -SunJCE 1.22: SunJCE Provider
(implements DES, Triple DES, Blowfish, PBE, Diffie-Hellman, HMAC-MD5, HMAC-SHA1)
2005/05/13 11:16:54:951 EDT [DEBUG] HttpClient - -SunJSSE 1.0303: Sun JSSE
provider(implements RSA Signatures, PKCS12, SunX509 key/trust factories, SSLv3,
TLSv1)
2005/05/13 11:16:54:961 EDT [DEBUG] HttpConnection - -Open connection to
mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:00:629 EDT [DEBUG] header - ->> ""GET
/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\r][\n]""
2005/05/13 11:17:00:629 EDT [DEBUG] HttpMethodBase - -Adding Host request header
2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> ""User-Agent: Jakarta
Commons-HttpClient/3.0-rc2[\r][\n]""
2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> ""Host:
mappoint-css.partners.extranet.microsoft.com[\r][\n]""
2005/05/13 11:17:00:639 EDT [DEBUG] header - ->> ""[\r][\n]""
2005/05/13 11:17:00:989 EDT [DEBUG] header - -<< ""HTTP/1.1 401 Unauthorized[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""Content-Length: 1656[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""Content-Type: text/html[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""Server: Microsoft-IIS/6.0[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""WWW-Authenticate: Digest
qop=""auth"",algorithm=MD5-sess,nonce=""c66759cace57c5016cf5645c6dee5b649ed29067f652939d6aaf7239310bb333eeb0153783ae445f"",opaque=""e7e259c137b65766c971d6cfc4115789"",charset=utf-8,realm=""Digest""[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""X-Powered-By: ASP.NET[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] header - -<< ""Date: Fri, 13 May 2005
15:16:51 GMT[\r][\n]""
2005/05/13 11:17:00:999 EDT [DEBUG] HttpMethodDirector - -Authorization required
2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Supported
authentication schemes in the order of preference: [ntlm, digest, basic]
2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Challenge for ntlm
authentication scheme not available
2005/05/13 11:17:01:009 EDT [INFO] AuthChallengeProcessor - -digest
authentication scheme selected
2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Using
authentication scheme: digest
2005/05/13 11:17:01:009 EDT [DEBUG] AuthChallengeProcessor - -Authorization
challenge processed
2005/05/13 11:17:01:009 EDT [DEBUG] HttpMethodDirector - -Authentication scope:
DIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:01:009 EDT [DEBUG] HttpMethodDirector - -Retry authentication
2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodBase - -Resorting to protocol
version default close connection policy
2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodBase - -Should NOT close
connection, using HTTP/1.1
2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Connection is locked. 
Call to releaseConnection() ignored.
2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodDirector - -Authenticating with
DIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:01:019 EDT [DEBUG] HttpMethodParams - -Credential charset not
configured, using HTTP element charset
2005/05/13 11:17:01:019 EDT [DEBUG] DigestScheme - -Using qop method auth
2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Connection is stale,
closing...
2005/05/13 11:17:01:019 EDT [DEBUG] HttpConnection - -Open connection to
mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> ""GET
/CustomerData-30/CustomerDataService.asmx HTTP/1.1[\r][\n]""
2005/05/13 11:17:01:110 EDT [DEBUG] HttpMethodBase - -Adding Host request header
2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> ""User-Agent: Jakarta
Commons-HttpClient/3.0-rc2[\r][\n]""
2005/05/13 11:17:01:110 EDT [DEBUG] header - ->> ""Authorization: Digest
username=""domain\user"", realm=""Digest"",
nonce=""c66759cace57c5016cf5645c6dee5b649ed29067f652939d6aaf7239310bb333eeb0153783ae445f"",
uri=""/CustomerData-30/CustomerDataService.asmx"",
response=""9cab4fcdb2d09f57523aec80d7b51e95"", qop=""auth"", nc=00000001,
cnonce=""b27507ee79c880b2bb565d363598ce07"", algorithm=""MD5-sess"",
opaque=""e7e259c137b65766c971d6cfc4115789""[\r][\n]""
2005/05/13 11:17:01:120 EDT [DEBUG] header - ->> ""Host:
mappoint-css.partners.extranet.microsoft.com[\r][\n]""
2005/05/13 11:17:01:120 EDT [DEBUG] header - ->> ""[\r][\n]""
2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< ""HTTP/1.1 401 Unauthorized[\r][\n]""
2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< ""Content-Length: 1539[\r][\n]""
2005/05/13 11:17:01:540 EDT [DEBUG] header - -<< ""Content-Type: text/html[\r][\n]""
2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< ""Server: Microsoft-IIS/6.0[\r][\n]""
2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< ""WWW-Authenticate: Digest
qop=""auth"",algorithm=MD5-sess,nonce=""3296b0dace57c5012fe314f8c6f8cafd10abc7a61c09484b2be5c7ef19ecb3c080da1f82c3f5a532"",opaque=""87578a7f0871280654aed868cb9497fb"",charset=utf-8,realm=""Digest""[\r][\n]""
2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< ""X-Powered-By: ASP.NET[\r][\n]""
2005/05/13 11:17:01:550 EDT [DEBUG] header - -<< ""Date: Fri, 13 May 2005
15:17:19 GMT[\r][\n]""
2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Authorization required
2005/05/13 11:17:01:550 EDT [DEBUG] AuthChallengeProcessor - -Using
authentication scheme: digest
2005/05/13 11:17:01:550 EDT [DEBUG] AuthChallengeProcessor - -Authorization
challenge processed
2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Authentication scope:
DIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Credentials required
HTTP result: 401
2005/05/13 11:17:01:550 EDT [DEBUG] HttpMethodDirector - -Credentials provider
not available
2005/05/13 11:17:01:580 EDT [INFO] HttpMethodDirector - -Failure authenticating
with DIGEST 'Digest'@mappoint-css.partners.extranet.microsoft.com:443
2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Buffering response body
2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Resorting to protocol
version default close connection policy
2005/05/13 11:17:01:580 EDT [DEBUG] HttpMethodBase - -Should NOT close
connection, using HTTP/1.1
2005/05/13 11:17:01:580 EDT [DEBUG] HttpConnection - -Releasing connection back
to connection manager."
"HTTPCLIENT-82","RFE","IMPROVEMENT","HttpURLConnection wrapper","Initial comments from Vincent Massol for this feature:

I am moving Jakarta Cactus from using the JDK HttpURLConnection to
Commons HttpClient. However, I have some public interface that return
HttpURLConnection and I cannot break that contract with Cactus users.

I propose to write a HttpURLConnection wrapper for HttpMethod (I have
actually already written it but I am currently testing it on Cactus and
will make a proper donation once I am sure it works - i.e all the Cactus
tests pass as before ... ).

I attach a preview of it for those interested.

What do you think of including it in HttpClient distribution ?

Thanks
-Vincent"
"HTTPCLIENT-578","BUG","BUG","literal plus (+) character in path components of HttpURL is not preserved.","When a literal plus character is included in the path component of an URL, it is
not encoded, but get decoded during getPath() to a space.

Reproducible with the following:

HttpURL httpURL = new HttpURL(""http://localhost/test+test"");
System.out.println(httpURL.getPath());

Output:
""test test""

The following path fixes the issue (This patch does not appear to break anything
 else):

Patch against SVN Repo:
URL: http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk
Repository UUID: 13f79535-47bb-0310-9956-ffa450edef68
Revision: 405803

Index: src/java/org/apache/commons/httpclient/URI.java
===================================================================
--- src/java/org/apache/commons/httpclient/URI.java (revision 405803)
+++ src/java/org/apache/commons/httpclient/URI.java (working copy)
@@ -1552,6 +1552,7 @@
         allowed_abs_path.or(abs_path);
         // allowed_abs_path.set('/');  // aleady included
         allowed_abs_path.andNot(percent);
+        allowed_abs_path.clear('+');
     }


@@ -1563,6 +1564,7 @@
     static {
         allowed_rel_path.or(rel_path);
         allowed_rel_path.clear('%');
+        allowed_rel_path.clear('+');
     }"
"HTTPCLIENT-1127","BUG","BUG","Deadlock between SingleClientConnManager.releaseConnection() and SingleClientConnManager.shutdown()","It's possible to create a deadlock within SingleClientConnectionManager.

When JMeter interrupts a test, it calls HttpUriRequest.abort(), and as part of thread end processing it calls SingleClientConnManager.shutdown().

See deadlock details below.

I don't yet know why the shutdown is called before the abort finishes; that is probably a bug.

However, there may be a issue with the locking strategy within SCCM, hence this report.

""Thread-18"":
        at org.apache.http.impl.conn.SingleClientConnManager.releaseConnection(SingleClientConnManager.java:258)
        - waiting to lock <0x19e00118> (a org.apache.http.impl.conn.SingleClientConnManager)
        at org.apache.http.impl.conn.AbstractClientConnAdapter.abortConnection(AbstractClientConnAdapter.java:323)
        - locked <0x19e00148> (a org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter)
        at org.apache.http.client.methods.HttpRequestBase.abort(HttpRequestBase.java:161)
        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.interrupt(HTTPHC4Impl.java:1090)
        at org.apache.jmeter.protocol.http.sampler.HTTPSamplerProxy.interrupt(HTTPSamplerProxy.java:77)
        at org.apache.jmeter.threads.JMeterThread.interrupt(JMeterThread.java:580)
        at org.apache.jmeter.engine.StandardJMeterEngine.tellThreadsToStop(StandardJMeterEngine.java:552)
        at org.apache.jmeter.engine.StandardJMeterEngine.access$2(StandardJMeterEngine.java:547)
        at org.apache.jmeter.engine.StandardJMeterEngine$StopTest.run(StandardJMeterEngine.java:284)
        at java.lang.Thread.run(Thread.java:662)
""Thread Group 1-1"":
        at org.apache.http.impl.conn.AbstractPooledConnAdapter.detach(AbstractPooledConnAdapter.java:106)
        - waiting to lock <0x19e00148> (a org.apache.http.impl.conn.SingleClientConnManager$ConnAdapter)
        at org.apache.http.impl.conn.SingleClientConnManager.shutdown(SingleClientConnManager.java:342)
        - locked <0x19e00118> (a org.apache.http.impl.conn.SingleClientConnManager)
        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.closeThreadLocalConnections(HTTPHC4Impl.java:1076)
        at org.apache.jmeter.protocol.http.sampler.HTTPHC4Impl.threadFinished(HTTPHC4Impl.java:1065)
        at org.apache.jmeter.protocol.http.sampler.HTTPSamplerProxy.threadFinished(HTTPSamplerProxy.java:71)
        at org.apache.jmeter.threads.JMeterThread$ThreadListenerTraverser.addNode(JMeterThread.java:553)
        at org.apache.jorphan.collections.HashTree.traverseInto(HashTree.java:986)
        at org.apache.jorphan.collections.HashTree.traverse(HashTree.java:969)
        at org.apache.jmeter.threads.JMeterThread.threadFinished(JMeterThread.java:528)
        at org.apache.jmeter.threads.JMeterThread.run(JMeterThread.java:308)
        at java.lang.Thread.run(Thread.java:662)
"
"HTTPCLIENT-31","RFE","IMPROVEMENT","user need a way to control cookie policy","User need a way to control what cookie can be accepted and what should be 
rejected. It would be nice to provide a cookie filter interface, so the user 
can change the cookie policy by implementing his own filter."
"HTTPCLIENT-1017","OTHER","BUG","Checksum Wrong for HttpComponent project pom v4.1 on central","As evidenced on the log here: http://vmgump.apache.org/gump/public/httpcomponents/httpcomponents-core/gump_work/build_httpcomponents_httpcomponents-core.html

The checksum in central for httpcomponents-project-4.1.pom is incorrect in maven central.

---------------------------8<--------------------------------

Downloading: http://localhost:8192/maven2/org/apache/httpcomponents/project/4.1/project-4.1.pom

[WARNING] *** CHECKSUM FAILED - Checksum failed on download: local = 'b63ff67e6ffc1940041319e0e06d7c6b1d671fd2'; remote = '8edff11652ca51b9d110ebfb321daac24f031c07' - RETRYING
Downloading: http://localhost:8192/maven2/org/apache/httpcomponents/project/4.1/project-4.1.pom

[WARNING] *** CHECKSUM FAILED - Checksum failed on download: local = 'b63ff67e6ffc1940041319e0e06d7c6b1d671fd2'; remote = '8edff11652ca51b9d110ebfb321daac24f031c07' - IGNORING
This pom appears to be a dependency for httpcomponents 4.0.3

---------------------------8<--------------------------------

This checksum failure causes configurations that reject such artifacts (such as many maven proxy configurations) to result in build failures due to unsatisfied dependencies. 

"
"HTTPCLIENT-184","BUG","BUG","org.apache.commons.httpclient.HeaderElement fail to parse cookie header","if Set-Cookie header has value such ""expires=Mon, .."".
org.apache.commons.httpclient.HeaderElement will fail to parse this header.

Cause:
In the source cord:
-------------
            try {
                /*
                 * Following to RFC 2109 and 2965, in order not to conflict
                 * with the next header element, make it sure to parse tokens.
                 * the expires date format is ""Wdy, DD-Mon-YY HH:MM:SS GMT"".
                 * Notice that there is always comma(',') sign.
                 * For the general cases, rfc1123-date, rfc850-date.
                 */
                if (tokenizer.hasMoreTokens()) {
                    String s = nextToken.toLowerCase();
                    if (nextToken.endsWith(""mon"") 
                        || s.endsWith(""tue"")
                        || s.endsWith(""wed"") 
                        || s.endsWith(""thu"")
                        || s.endsWith(""fri"")
                        || s.endsWith(""sat"")
                        || s.endsWith(""sun"")
                        || s.endsWith(""monday"") 
                        || s.endsWith(""tuesday"") 
---- snip ---
 
""if (nextToken.endsWith(""mon"") "" is wrong.
this must be ""if (s.endsWith(""mon"") "".

Source cord version:
 * $Header:
/home/cvspublic/jakarta-commons/httpclient/src/java/org/apache/commons/httpclient/HeaderElement.java,v
1.17 2003/03/08 21:30:02 olegk Exp $
 * $Revision: 1.17 $
 * $Date: 2003/03/08 21:30:02 $"
"HTTPCLIENT-1159","RFE","IMPROVEMENT","HttpClientUtils  - Helper methods to release resources of HttpClient / HttpResponse after use ","Found myself writing this boiler plate code in various httpclient related projects , to release resources , and wanted to provide a simpler way to release resources similar to IOUtils.closeQuietly as opposed to maintaining the same in my code. 

New class: 

o.a.http.client.utils.HttpClientUtils added: 
<pre>
  public static void closeQuietly(final HttpResponse response); 
  public static void closeQuietly(final HttpClient httpClient); 
</pre>

with 2 methods ( as above ) in the same, to help release resources: 
"
"HTTPCLIENT-881","BUG","BUG","AbstractClientConnAdapter doesn't ensure that only one of ConnectionReleaseTrigger.abortConnection, .releaseConnection has effect","If HttpUriRequest.abort() is called at about the same time that the request completes, it's possible for an aborted connection to be returned to the pool.  The next time the connection is used, HttpClient.execute fails without retrying, throwing this exception:

java.io.IOException: Connection already shutdown
	at org.apache.http.impl.conn.DefaultClientConnection.opening(DefaultClientConnection.java:112)
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:120)
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:147)
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:101)
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:381)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:576)

Steps to reproduce:
1) Set a breakpoint in ThreadSafeClientConnManager.releaseConnection just after ""reusable"" is set (and found to be true).
2) Run to the breakpoint in releaseConnection.
3) Call HttpUriRequest.abort.
4) Let releaseConnection complete.

When the connection is next used, the exception will be thrown.

Snippet from ThreadSafeClientConnManager:
    public void releaseConnection(ManagedClientConnection conn, long validDuration, TimeUnit timeUnit) {
		...
            boolean reusable = hca.isMarkedReusable();
            if (log.isDebugEnabled()) {                             // breakpoint here
                if (reusable) {
                    log.debug(""Released connection is reusable."");
                } else {
                    log.debug(""Released connection is not reusable."");
                }
            }
            hca.detach();
            if (entry != null) {
                connectionPool.freeEntry(entry, reusable, validDuration, timeUnit);
            }
        }
    }


I think that AbstractClientConnAdapter should be modified as follows:

1) Add ""released"" flag:

    /** True if the connection has been released. */
    private boolean released;

2) Modify abortConnection:

    public void abortConnection() {
        synchronized(this) {
            if (aborted || released) {
                return;
            }
            aborted = true;
        }
        unmarkReusable(); // this line and all that follow unchanged

3) Modify releaseConnection:

    public void releaseConnection() {
        synchronized(this) {
            if (aborted || released) {
                return;
            }
            released = true;
        }
        if (connManager != null) {
            connManager.releaseConnection(this, duration, TimeUnit.MILLISECONDS);
        }
    }

"
"HTTPCLIENT-841","IMPROVEMENT","BUG","potential memory leak when using ThreadSafeClientConnManager","When using ThreadSafeClientConnManager and developing with Jetty using auto-redeploy feature eventually I run into a PermGen out of memory exception.  I investigated with YourKit 8.0.6 and found a class loader circular reference in RefQueueWorker.  Not really sure what I was doing I made the refQueueHandler non-final and nulled it in the shutdown method of RedQueueWorker.  I don't seem to have the problem any longer with circular class loader references.

Here is a diff from 4.0-beta2


--- httpclient/src/main/java/org/apache/http/impl/conn/tsccm/RefQueueWorker.jav(revision 763223)
+++ httpclient/src/main/java/org/apache/http/impl/conn/tsccm/RefQueueWorker.jav(working copy)
@@ -50,7 +50,7 @@
     protected final ReferenceQueue<?> refQueue;
 
     /** The handler for the references found. */
-    protected final RefQueueHandler refHandler;
+    protected RefQueueHandler refHandler;
 
 
     /**
@@ -112,6 +112,8 @@
             this.workerThread = null; // indicate shutdown
             wt.interrupt();
         }
+
+        refHandler = null;
     }
 
 
"
"HTTPCLIENT-1137","IMPROVEMENT","IMPROVEMENT","The values for the Via header are created by httpclient-cache for each cached and backend request","The Via header that gets generated and inserted by the caching layer is done repeatedly in the HTTP conversation, even if the constructed string is constant for each protocol version that is involved.

The proposed patch constructs a map of generated values held in memory with the associated ProtocolVersion as a key and uses read/write locks to access the data. This  solution minimizes the time to generate such a value from several milliseconds to 40-50 microseconds."
"HTTPCLIENT-495","BUG","BUG","DefaultHttpMethodRetryHandler does not check whether the failed method has been aborted","DefaultHttpMethodRetryHandler does not check whether the failed method has been
aborted."
"HTTPCLIENT-662","TASK","TASK","Disentangle commons-httpclient from commons in Gump","Currently, the Gump project for HttpClient 3.x is defined as one of the commons projects.
It should be moved to a separate definition, either all by itself or as a new group of HttpComponents Gump projects.
"
"HTTPCLIENT-378","BUG","BUG","HttpState.setCookiePolicy() is completely ignored","Though this method is deprecated, it currently has no effect and gives no warning that it does nothing.  
A patch that fixes this problem is coming shortly.

Mike"
"HTTPCLIENT-331","DOCUMENTATION","BUG","[PATCH] HttpClient#getHost & HttpClient#getPort methods are misleading","HttpClient#getHost & HttpClient#getPort methods are misleading, accompanied by
obsolete, factually wrong javadocs and as such should be deprecated.

Oleg"
"HTTPCLIENT-777","BUG","BUG","SingleClientConnectionManager Needs to Recreate UniquePoolEntry","Due to the change yesterday of adding some state into DefaultClientConnection (remembering when shutdown was called & aborting the next opening), SingeClientConnectionManager now breaks when subsequent requests are performed if the first one encountered an exception or was aborted.  

Attaching a patch with the fix + a testcase (that previously failed)."
"HTTPCLIENT-1073","BUG","BUG","cache module generates exceptions for non-compliant responses without consuming response bodies","In the ResponseProtocolCompliance class, the caching module checks the incoming origin response to attempt to make it compliant with RFC2616. However, if there are instances where this is not possible, it currently throws an exception without consuming the origin response body; this causes a connection leak if the general try..catch..finally pattern documented on the HttpClient interface Javadoc is followed.
"
"HTTPCLIENT-963","SPEC","BUG","client cache does not respect 'Cache-Control: no-store' on requests","""The purpose of the no-store directive is to prevent the inadvertent release or retention of sensitive information (for example, on backup tapes). The no-store directive applies to the entire message, and MAY be sent either in a response or in a request. If sent in a request, a cache MUST NOT store any part of either this request or any response to it.""

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.2

The current implementation will incorrectly cache responses to requests containing 'Cache-Control: no-store'."
"HTTPCLIENT-303","IMPROVEMENT","IMPROVEMENT","auto close idle connections","This has been mentioned several times on the mailing list (most recently here:
http://nagoya.apache.org/eyebrowse/ReadMsg?listName=commons-httpclient-dev@jakarta.apache.org&msgNo=5191
)
It is desirable for the http client to close it's connection after some
configurable idle time. Failing to do so causes the server (and every TCP
resource in between) to keep the socket open and possibly run out of resources
under load.

The HTTP 1.1 RFC has this to say under section 8.1.4:
Servers will usually have some time-out value beyond which they will
   no longer maintain an inactive connection. Proxy servers might make
   this a higher value since it is likely that the client will be making
   more connections through the same server. The use of persistent
   connections places no requirements on the length (or existence) of
   this time-out for either the client or the server.

   When a client or server wishes to time-out it SHOULD issue a graceful
   close on the transport connection. Clients and servers SHOULD both
   constantly watch for the other side of the transport close, and
   respond to it as appropriate. If a client or server does not detect
   the other side's close promptly it could cause unnecessary resource
   drain on the network.

The first sentence of the 2nd paragraph is interesting: how is the client
supposed to do a ""graceful close""? Does it simply mean closing the socket?
One possiblity may be to issue a HTTP/OPTIONS * request with a Connection:close
header."
"HTTPCLIENT-757","BUG","BUG","Default proxy set at the client level has no effect","Default proxy set at the client level has no effect, as client parameters are not correctly propagated to the HttpRoutePlanner"
"HTTPCLIENT-62","DOCUMENTATION","IMPROVEMENT","Developer documentation","Provide more example code in CVS and give a clear link on the website.  A
walkthrough of the API.  Documenntation suitable for new users."
"HTTPCLIENT-351","IMPROVEMENT","IMPROVEMENT","Split the wire log into header and content parts."," "
"HTTPCLIENT-116","BUG","BUG","Request/Response race condition when doing multiple requests on the same connection.","If one tries to do multiple request over the same socket connection a race 
condition occurs in the input/output streams.
eg. 
-- Some request -->
<- HTTP/1.1 200 OK
<- Some: Headers
<- 
<- The body.

-- Next request -->
<- HTTP/1.1 200 OK
<- More: Headers
<- 
<- Some data.

If the second request is sent, but the second response isn't yet received 
before the client starts to try to read it, it'll get 
a ""org.apache.commons.httpclient.HttpRecoverableException: Error in parsing the 
status  line from the response: unable to find line starting with ""HTTP/"""" 
exception (it will think ""The body."" is part of the second response).

The following code will reproduce the problem:

import java.io.*;
import java.net.*;
import java.util.*;
import org.apache.commons.httpclient.*;
import org.apache.commons.httpclient.methods.*;

public class HttpClientRaceBug {
    public static void main(String[] args) {
        try {
            SimpleHttpServer.listen(8987);
            HttpClient client = new HttpClient();
            client.startSession(""localhost"", 8987);
            client.getState().setCredentials(""Test Realm"",  
                new UsernamePasswordCredentials(""foo"", ""bar""));
            
            for (int i = 0; i < 100; i++) {
                GetMethod meth = new GetMethod();
                client.executeMethod(meth);
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
    
    private static final class SimpleHttpServer implements Runnable {
        private Socket socket;
        public SimpleHttpServer(Socket socket) {
            this.socket = socket;
        }
        public static void listen(final int port) {
            Thread server = new Thread() {
                public void run() {
                    try {
                        ServerSocket ss = new ServerSocket(port);
                        while (true) {
                            new Thread(new 
                                SimpleHttpServer(ss.accept())).start();
                        }
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                }
            };
            
            server.setDaemon(true);
            server.start();
        }
        public void run() {
            try {
                BufferedReader in = new BufferedReader(new 
                    InputStreamReader(this.socket.getInputStream()));
                
                int len = 0;
                boolean auth = false;
                String line;
                while ((line = in.readLine()) != null) {
                    System.out.println(""> "" + line);
                    
                    if (line.trim().equals("""")) {
                        in.read(new char[len]);
                        doOutput(auth);
                        auth = false;
                        len = 0;
                        
                    } else if (line.indexOf(':') > -1) {
                        StringTokenizer tok = new StringTokenizer(line, "":"");
                        String key = tok.nextToken().toLowerCase();
                        if (key.equals(""content-length"")) {
                            len = Integer.parseInt(tok.nextToken().trim());
                        } else if (key.equals(""authorization"")) {
                            auth = true;
                        }
                    }
                }
            } catch (Exception e) {}
        }
        private static int count = 0;
        public void doOutput(boolean authorized) throws IOException {
            Writer out = new OutputStreamWriter(this.socket.getOutputStream());
            count++;
            
            String id = (count < 100) ? 
                ((count < 10) ? ""00"" + count : ""0"" + count) : """" + count;
            if (authorized) {
                write(out, ""HTTP/1.1 200 OK\r\n"");
            } else {
                write(out, ""HTTP/1.1 401 Unauthorized\r\n"");
            }
            write(out, ""WWW-Authenticate: Basic realm=\""Test Realm\""\r\n"");
            write(out, ""Response-Id: "" + id + ""\r\n"");
            write(out, ""Content-Type: text/html; charset=iso-8859-1\r\n"");
            write(out, ""Content-Length: 17\r\n\r\n"");
            write(out, ""My Response ("" + id + "")"");
            out.close();
        }
        private void write(Writer out, String text) throws IOException {
            System.out.print(""< "" + text);
            out.write(text);
        }
    }
}"
"HTTPCLIENT-260","RFE","IMPROVEMENT","Authentication does not respond to stale nonce","When using digest authentication, HTTP allows the server to mark the nonce value
as stale. The client then must re-authenticate with a new nonce value provided
by the server. Currently, HttpClient does not support this functionality. I've
created a patch that allows HttpClient to support stale nonce values. It is
attached below. The patch should be applied to HttpMethodBase.java


***
/home/scohen/downloads/httpclient-src/commons-httpclient-2.0-rc1/src/java/org/apache/commons/httpclient/HttpMethodBase.java
2003-07-31 22:15:26.000000000 -0400
--- org/apache/commons/httpclient/HttpMethodBase.java   2003-08-20
17:22:52.000000000 -0400
***************
*** 1351,1384 ****
       *
       * @throws IOException when errors occur reading or writing to/from the
       *         connection
       * @throws HttpException when a recoverable error occurs
       */
!     protected void addAuthorizationRequestHeader(HttpState state,
!                                                  HttpConnection conn)
!     throws IOException, HttpException {
!         LOG.trace(""enter HttpMethodBase.addAuthorizationRequestHeader(""
!                   + ""HttpState, HttpConnection)"");
   
          // add authorization header, if needed
!         if (getRequestHeader(HttpAuthenticator.WWW_AUTH_RESP) == null) {
!             Header[] challenges = getResponseHeaderGroup().getHeaders(
!                                                HttpAuthenticator.WWW_AUTH);
!             if (challenges.length > 0) {
!                 try {
!                     AuthScheme authscheme =
HttpAuthenticator.selectAuthScheme(challenges);
                      HttpAuthenticator.authenticate(authscheme, this, conn, state);
!                 } catch (HttpException e) {
!                     // log and move on
!                     if (LOG.isErrorEnabled()) {
!                         LOG.error(e.getMessage(), e);
!                     }
                  }
              }
          }
      }
                                                                                
      /**
       * Adds a <tt>Content-Length</tt> or <tt>Transfer-Encoding: Chunked</tt>
       * request header, as long as no <tt>Content-Length</tt> request header
       * already exists.
       *
--- 1351,1391 ----
       *
       * @throws IOException when errors occur reading or writing to/from the
       *         connection
       * @throws HttpException when a recoverable error occurs
       */
!     protected void addAuthorizationRequestHeader(HttpState state,
HttpConnection conn)
!         throws IOException, HttpException {
!         LOG.trace(""enter HttpMethodBase.addAuthorizationRequestHeader("" +
""HttpState, HttpConnection)"");
                                                                                
          // add authorization header, if needed
!
!         Header[] challenges =
getResponseHeaderGroup().getHeaders(HttpAuthenticator.WWW_AUTH);
!         if (challenges.length > 0) {
!
!             try {
!                 AuthScheme authscheme =
HttpAuthenticator.selectAuthScheme(challenges);
!                 if (getRequestHeader(HttpAuthenticator.WWW_AUTH_RESP) == null
!                     || isNonceStale(authscheme) ) {
                      HttpAuthenticator.authenticate(authscheme, this, conn, state);
!                 }
!             } catch (HttpException e) {
!                 // log and move on
!                 if (LOG.isErrorEnabled()) {
!                     LOG.error(e.getMessage(), e);
                  }
              }
          }
      }
                                                                                
+
+     private boolean isNonceStale(AuthScheme authscheme) {
+         return authscheme.getSchemeName().equalsIgnoreCase(""digest"")
+             && ""true"".equalsIgnoreCase(authscheme.getParameter(""stale""));
+     }
+
+
      /**
       * Adds a <tt>Content-Length</tt> or <tt>Transfer-Encoding: Chunked</tt>
       * request header, as long as no <tt>Content-Length</tt> request header
       * already exists.
       *
***************
*** 2419,2430 ****
                  buffer.append(port);
              }
              buffer.append('#');
              buffer.append(authscheme.getID());
              String realm = buffer.toString();
!
              if (realmsUsed.contains(realm)) {
                  if (LOG.isInfoEnabled()) {
                      LOG.info(""Already tried to authenticate to \""""
                               + realm + ""\"" but still receiving ""
                               + statusCode + ""."");
                  }
--- 2426,2442 ----
                  buffer.append(port);
              }
              buffer.append('#');
              buffer.append(authscheme.getID());
              String realm = buffer.toString();
!
!                       // check to see if the server has made our nonce stale.
!                       // if it has, re-auth
              if (realmsUsed.contains(realm)) {
+               if ( isNonceStale(authscheme)) {
+                       return false;
+               }
                  if (LOG.isInfoEnabled()) {
                      LOG.info(""Already tried to authenticate to \""""
                               + realm + ""\"" but still receiving ""
                               + statusCode + ""."");
                  }"
"HTTPCLIENT-126","IMPROVEMENT","BUG","Default charset","As defined in RFC2616 the default character set is ISO-8859-1 an not US-ASCII 
as defined in HttpMethodBase. See ""3.7.1 Canonicalization and Text Defaults"" at
RFC 2616"
"HTTPCLIENT-471","BUG","BUG","DateUtil#formatDate uses default locale instead of US","Problem reported by Yannick <yannick at meudal.net> on the httpclient-user list

==================================================================
Hello,

This is a bug report.

I'm using Commons HTTPClient (rc2) for generating HTTP requests. I put in 
headers some specific header, like the If-Modified-Since attribute. 
When I generate the date through DateUtil.formatDate method, I get a 
localized date, in french. Example: 
If-Modified-Since: dim., 10 avr. 2005 05:04:08 CEST

I get problems on my http server during parsing the received date. This is 
not a RFC 2616 compliant date format. It should be:
If-Modified-Since: Sun, 10 Apr 2005 05:04:08 CEST

A patch should be applied, by creating a new SimpleDateFormat(pattern, 
Locale.US) instead of SimpleDateFormat(pattern) (like it is done in the 
parse method, line #159).

org.apache.commons.httpclient.util.DateUtil, line #205:

    public static String formatDate(Date date, String pattern) {
        if (date == null) throw new IllegalArgumentException(""date is 
null"");
        if (pattern == null) throw new IllegalArgumentException(""pattern 
is null"");
 
        SimpleDateFormat formatter = new SimpleDateFormat(pattern, 
Locale.US);
        return formatter.format(date);
    }


Regards,

Yannick."
"HTTPCLIENT-73","RFE","BUG","No way to get the requestBody out of a PostMethod or use if extending class","Attempting to extend the PostMethod class I discovered that I had no access to 
the requestBody because the member is declared private and there is no get 
method.

I was trying to override the setRequestContentLength() when I discovered the 
problem.

So my enhancement request specifically is:
1. add a get method to be able to get the requestBody (probably a get method to 
the parameters as well)
2. (optionally) make the requestBody and parameters members protected instead 
of private so extending the class is easier.

In case you were wondering, the reason for extending the class was to add the 
ability to set a timeout value on the httpconnection and also the ability to 
set the character encoding of the request body.  I don't know if these are 
worthy of an enhancement request but I require them for what I'm doing.  Nice 
work by the way.

Thank you."
"HTTPCLIENT-892","DOCUMENTATION","BUG","Links in Section ""Example Code"" are broken","Steps to Reproduce: Go to http://hc.apache.org/user-docs.html
Click of one of the Links in the Section ""Example Code"""
"HTTPCLIENT-704","BUG","BUG","Exception not caugh in DefaultResponseParser","The method hasProtocolVersion in o.a.h.message.BaseLineParser (httpcore-alpha6) throws an IndexOutOfBoundsException which is not caught by the parseHead method in the o.a.h.impl.conn.DefaultResponseParser."
"HTTPCLIENT-1120","BUG","BUG","DefaultHttpRequestRetryHandler#retryRequest should not retry aborted requests","DefaultHttpRequestRetryHandler#retryRequest incorrectly retries aborted requests; I have seen the following log messages in JMeter:

org.apache.http.impl.client.DefaultHttpClient: I/O exception (java.net.SocketException) caught when processing request: socket closed
org.apache.http.impl.client.DefaultHttpClient: Retrying request

and

org.apache.http.impl.client.DefaultHttpClient: I/O exception (java.net.BindException) caught when connecting to the target host: Address already in use: connect
org.apache.http.impl.client.DefaultHttpClient: Retrying connect

The abort() method sets the isAborted() flag, but the retry handler does not check it."
"HTTPCLIENT-455","RFE","IMPROVEMENT","Feature Request: include contributed code for Plugin Proxy Detection","Attached is a zip file containing two classes - PluginProxyUtil and
ProxyDetectionException.  I've tested
PluginProxyUtil.detectProxy(URL) on Windows XP(JRE's 1.3/1.4/1.5 with IE) and
Solaris (JRE 1.4 with Netscape)
and it correctly detects browser plugin settings.  I don't have access to MacOS
X  to try it, but I doubt that
it works there anyway based on Dmitri's comments here:

http://forum.java.sun.com/thread.jspa?threadID=364342&tstart=120

Please change the header and package as necessary to include it in the contrib
section.  I plan to contribute
an example Applet that uses this code at some point - our app is way too
complicated to use as an example.
If you want to wait until that is done to include it, that's fine too.  Just
wanted to offer this up now in case
anyone else is looking for it."
"HTTPCLIENT-70","DOCUMENTATION","IMPROVEMENT","Provide more Example Code","- better project samples showing how to use HttpClient in a variety of ways. 
There is already a src/examples directory which is excellent.  Its in the right
place and should be build with a full compile, if only to know how any API
changes may effect example code, and that we will be required to keep them
current.
- make sure it uses the 2.0 API and no depricated methods!"
"HTTPCLIENT-1038","BUG","BUG","AbstractHttpClient.determineTarget(HttpUriRequest)","Issue with 4.1 beta1 fails to parse the right host from the URL, eg. http://my.site.com/search/?for=http://other.site.com
This fails request for eg. REST that has a param value with ':' or '?' or '/'.

AbstractHttpClient.determineTarget(HttpUriRequest)
httpcomponents-client-4.0.3:
    private HttpHost determineTarget(HttpUriRequest request) {
        // A null target may be acceptable if there is a default target.
        // Otherwise, the null target is detected in the director.
        HttpHost target = null;

        URI requestURI = request.getURI();
        if (requestURI.isAbsolute()) {
            target = new HttpHost(
                    requestURI.getHost(),
                    requestURI.getPort(),
                    requestURI.getScheme());
        }
        return target;
    }


httpcomponents-client-4.1-beta1:
    private HttpHost determineTarget(HttpUriRequest request) throws ClientProtocolException {
        // A null target may be acceptable if there is a default target.
        // Otherwise, the null target is detected in the director.
        HttpHost target = null;

        URI requestURI = request.getURI();
        if (requestURI.isAbsolute()) {
            String ssp = requestURI.getSchemeSpecificPart();
            ssp = ssp.substring(2, ssp.length()); //remove ""//"" prefix
            int end = ssp.indexOf(':') > 0 ? ssp.indexOf(':') :
                    ssp.indexOf('/') > 0 ? ssp.indexOf('/') :
                    ssp.indexOf('?') > 0 ? ssp.indexOf('?') : ssp.length();
            String host = ssp.substring(0, end);

            int port = requestURI.getPort();
            String scheme = requestURI.getScheme();
            if (host == null || """".equals(host)) {
                throw new ClientProtocolException(
                        ""URI does not specify a valid host name: "" + requestURI);
            }
            target = new HttpHost(host, port, scheme);
        }
        return target;
    }
"
"HTTPCLIENT-875","BUG","BUG","DefaultClientConnectionOperator doesn't update socket after call to connectSocket(...)","In the DefaultClientConnectionOperator function openConnection(...) it calls SocketFactory.connectSocket(...). The documentation for connectSocket(...) says that it returns:
   ""the connected socket. The returned object may be different from
the sock argument if this factory supports a layered protocol. ""

A quick peek at the source showed:
In org.apache.http.impl.conn.DefaultClientConnectionOperator:

117         final SocketFactory sf = schm.getSocketFactory();
118
119         Socket sock = sf.createSocket();
120         conn.opening(sock, target);
121
122         try {
123             sock = sf.connectSocket(sock, target.getHostName(),
124                     schm.resolvePort(target.getPort()),
125                     local, 0, params);
126         } catch (ConnectException ex) {
127             throw new HttpHostConnectException(target, ex);
128         }
129         prepareSocket(sock, context, params);
130         conn.openCompleted(sf.isSecure(sock), params);

So DefaultClientConnectionOperator never updates conn with the new version of sock that may have been returned from connectSocket(...).

adding:
        130         conn.openCompleted(sf.isSecure(sock), params);
+++ 131         conn.update(sock, target, sf.isSecure(sock), params);
appears to fix the issue.
"
"HTTPCLIENT-491","BUG","BUG","nonce-count in digest auth should not be quoted","In 3.0rc3 nonce-count (nc) is enclosed in quote marks. According to rfc2617 this
is wrong, nonce-count shouldn't be enclosed in quote marks.

> 3.2.2 The Authorization Request Header
> 
>    The client is expected to retry the request, passing an Authorization
>    header line, which is defined according to the framework above,
>    utilized as follows.
> 
>        credentials      = ""Digest"" digest-response
>        digest-response  = 1#( username | realm | nonce | digest-uri
>                        | response | [ algorithm ] | [cnonce] |
>                        [opaque] | [message-qop] |
>                            [nonce-count]  | [auth-param] )
> 
>        username         = ""username"" ""="" username-value
>        username-value   = quoted-string
>        digest-uri       = ""uri"" ""="" digest-uri-value
>        digest-uri-value = request-uri   ; As specified by HTTP/1.1
>        message-qop      = ""qop"" ""="" qop-value
>        cnonce           = ""cnonce"" ""="" cnonce-value
>        cnonce-value     = nonce-value
>        nonce-count      = ""nc"" ""="" nc-value
>        nc-value         = 8LHEX
>        response         = ""response"" ""="" request-digest
>        request-digest = <""> 32LHEX <"">
>        LHEX             =  ""0"" | ""1"" | ""2"" | ""3"" |
>                            ""4"" | ""5"" | ""6"" | ""7"" |
>                            ""8"" | ""9"" | ""a"" | ""b"" |
>                            ""c"" | ""d"" | ""e"" | ""f"""
"HTTPCLIENT-826","BUILD_SYSTEM","IMPROVEMENT","Set source and output encoding in POMs","Modification to POM files to explicitly set the source and report encoding. I've set everything to UTF-8, but this may not be appropriate. However, the encoding properties should be set to ensure that source files are compiled correctly, resources are filtered appropriately and that the reports are using a consistent encoding.

Related info
http://docs.codehaus.org/display/MAVENUSER/POM+Element+for+Source+File+Encoding
http://docs.codehaus.org/display/MAVEN/Reporting+Encoding+Configuration"
"HTTPCLIENT-696","DOCUMENTATION","BUG","java.util.logging configuration examples does not work as intended","java.util.logging configuration examples do not work as intended. Those can be found here: http://jakarta.apache.org/httpcomponents/httpclient-3.x/logging.html

Steps to reproduce:
1. Create a simple project using HttpClient (see listing below) and JDK 1.6 (I suppose it is JDK 1.4 or higher, but I did not test anything other than 1.6). Without log4j in the classpath and without any commons-logging system properties set, java.util.logging is automatically selected by commons-logging.
2. Create logging.properties file as shown in any of the java.util.logging examples
3. Run a program, passing -Djava.util.logging.config.file=logging.properties argument to the JVM

Expected results:
Quite a few log messages should be sent to System.err

Actual results:
Unless there is an I/O error encountered, no log messages are sent to System.err

The problem, as far as I can see, is caused by the default logging level of java.util.logging.ConsoleHandler, which is set to INFO. In order for any log messages to go through, the log hadler log level needs to be lower than logged messages log level. Adding the following line to all java.util.logging examples should fix the problem:

java.util.logging.ConsoleHandler.level = ALL

--- Get.java -----------------------------------------

import java.io.IOException;
import java.io.InputStreamReader;
import java.io.Reader;

import org.apache.commons.httpclient.HostConfiguration;
import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.HttpException;
import org.apache.commons.httpclient.HttpMethodBase;
import org.apache.commons.httpclient.methods.GetMethod;


public class Get {

	/**
	 * @param args
	 */
	public static void main(String[] args) {
		
 		HttpClient client = new HttpClient();
		HttpMethodBase get = new GetMethod(""http://www.apache.org"");
		
		try {
			int code = client.executeMethod(get);
			System.out.println(""Status code: "" + code);
			
			String csn = get.getResponseCharSet();
			System.out.println(""Charset is: "" + csn);
			
			long len = get.getResponseContentLength();
			System.out.println(""Length is: "" + len);
			len = len < 0 ? 200 : len;
			
			StringBuilder buf = new StringBuilder((int)len);
			Reader r = new InputStreamReader(get.getResponseBodyAsStream(), csn);
			for (int c = r.read(); c >= 0; c = r.read()) {
				buf.append((char)c);
			}
			
			System.out.println(""Body:"");
			System.out.println(buf.toString());			
			
		} catch (HttpException e) {
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		} finally {
			get.releaseConnection();
		}				
	}
}

--- logging.properties ----- From examples ----------------------

.level=INFO

handlers=java.util.logging.ConsoleHandler
java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter

httpclient.wire.header.level=FINEST
org.apache.commons.httpclient.level=FINEST

--------------------------------------------------------------------------------
"
"HTTPCLIENT-539","BUG","BUG","UserInfo disapears after creating URI","I tested this using firefox (Where I have configured our proxy server)
I run the following URI: ftp://username:password@ftp.mytest.test/testdir/

I use a sniffer to look at the GET commond send to the proxy server. It looks as
follows:

GET ftp://username:password@ftp.mytest.test/testdir/ HTTP/1.1
Host: ftp.mytest.test
User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.7.12)
Gecko/20050915 Firefox/1.0.7
Accept:
text/xml,application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5
Accept-Language: en-us,en;q=0.5
Accept-Encoding: gzip,deflate
Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7
Keep-Alive: 300
Proxy-Connection: keep-alive

Using this request we get access to the directory and see the contents displayed.
However, when I try the same in Java (using HttpClient) I get the following GET
request (Java code included below):

GET ftp://ftp.mytest.test/testdir/ HTTP/1.1
User-Agent: Jakarta Commons-HttpClient/3.0-rc3
Host: ftp.mytest.test
Proxy-Connection: Keep-Alive

Finally I get a ACCESS DENIED error. 
This seems to be because the GET request does not contain the USER / PASSWORD
info in the URL.

/// JAVA CODE:

package nl.essent.test.ftp.httptest;

import java.io.IOException;

import org.apache.commons.httpclient.Credentials;
import org.apache.commons.httpclient.DefaultHttpMethodRetryHandler;
import org.apache.commons.httpclient.HostConfiguration;
import org.apache.commons.httpclient.HttpClient;
import org.apache.commons.httpclient.HttpException;
import org.apache.commons.httpclient.HttpMethod;
import org.apache.commons.httpclient.HttpStatus;
import org.apache.commons.httpclient.NTCredentials;
import org.apache.commons.httpclient.UsernamePasswordCredentials;
import org.apache.commons.httpclient.auth.AuthScope;
import org.apache.commons.httpclient.methods.GetMethod;
import org.apache.commons.httpclient.params.HttpMethodParams;
import org.apache.commons.httpclient.protocol.DefaultProtocolSocketFactory;
import org.apache.commons.httpclient.protocol.Protocol;

public class TestClient {

    public static void main(String[] args) {
        new TestClient().testFtpViaHttp();
    }
    
    public void testFtpViaHttp() {
        
        HttpClient client = new HttpClient();
        
        HostConfiguration hostConfig = client.getHostConfiguration();
        hostConfig.setProxy(""proxy"", 8080);
        client.setHostConfiguration(hostConfig);
        
        Protocol protol = new Protocol(""ftp"", new
DefaultProtocolSocketFactory(), 21);
        Protocol.registerProtocol(""ftp"", protol);
        
        Credentials proxyCreds = new NTCredentials(""xxxx"", ""xxxxx"","""", ""xxxx"" );
        client.getState().setProxyCredentials(AuthScope.ANY, proxyCreds);
        
        GetMethod gmethod = new
GetMethod(""ftp://username:password@ftp.mytest.test/testdir/"");
        
        gmethod.getParams().setParameter(HttpMethodParams.RETRY_HANDLER, 
                new DefaultHttpMethodRetryHandler(3, false));
       
        try {
            // Execute the method.
            int statusCode = client.executeMethod(gmethod);

            if (statusCode != HttpStatus.SC_OK) {
              System.err.println(""Method failed: "" + gmethod.getStatusLine());
            }

            // Read the response body.
            byte[] responseBody = gmethod.getResponseBody();

            // Deal with the response.
            // Use caution: ensure correct character encoding and is not binary data
            System.out.println(new String(responseBody));

          } catch (HttpException e) {
            System.err.println(""Fatal protocol violation: "" + e.getMessage());
            e.printStackTrace();
          } catch (IOException e) {
            System.err.println(""Fatal transport error: "" + e.getMessage());
            e.printStackTrace();
          } finally {
            // Release the connection.
            gmethod.releaseConnection();
          } 

    }

}

//// END JAVA CODE"
"HTTPCLIENT-746","IMPROVEMENT","IMPROVEMENT","substitute for URLUtils.java","I would like to contribute a substitute for existing URLUtils.java... UrlEncodedUtils.java offer utility methods for dealing with 'urlencoded' data. Main difference with existing class is that parameters are Map <String, List <String>> instead of NameValue pairs and lack of third party dependencies...  It's partially covered with tests which I will further extend to cover all methods of this utility class."
"HTTPCLIENT-941","IMPROVEMENT","IMPROVEMENT","Standardize on a common mocking framework (either EasyMock or Mockito)","We are currently using EasyMock in the caching module and Mockito in the main module. While Mockito appears to have a somewhat nicer API, the sheer number of test cases based on EasyMock in the caching module makes it much simpler to replace Mockito with EasyMock than the other way around."
"HTTPCLIENT-283","BUG","BUG","Invalid cookie causing IllegalArgumentException","The bug reported by Oliver Kll <listen at quimby.de> on HttpClient mailing list

<quote>
I'm dealing with a site that serves invalid Cookies in various kind of  
ways. In some cases the Cookie values contain "","" characters, which  
really confuses the Header/Cookie parsers and eventually leads to  
IllegalArgumentExceptions thrown by the Cookie constructor:

java.lang.IllegalArgumentException: Cookie name may not be blank
   at org.apache.commons.httpclient.Cookie.<init>(Cookie.java:142)
   at  
org.apache.commons.httpclient.cookie.CookieSpecBase.parse(CookieSpecBase 
.java:192)
   at  
org.apache.commons.httpclient.cookie.CookieSpecBase.parse(CookieSpecBase 
.java:256)
   at  
org.apache.commons.httpclient.HttpMethodBase.processResponseHeaders(Http 
MethodBase.java:1826)
   at  
org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase 
.java:1939)
   at  
org.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBa 
se.java:2631)
   at  
org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java 
:1085)
   at  
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:6 
74)
   at  
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:5 
29)
   at my.code.Test.getHttp(Test.java:114)

What bothers me, is that these IllegalArgumentExceptions are never  
caught in the HttpClient code, making it effectivily impossible to  
handle these responses.

</quote>"
"HTTPCLIENT-376","REFACTORING","BUG","DateParser refactoring; Stateful cookie specs","Presently DateParser is tightly coupled with the DefaultHttpParams class. I find
this sub-optimal from the design standpoint. Moreover, I believe that date
patterns should be specifiable at the method, host, and client levels, not only
global one. Currently this is not the case, and out of sync with the rest of the
preference framework, which can result in quite a bit of confusion.

When refactoring the DateParser class I also realized that the cookie specs were
shared by all the HttpMethod instances and as such had to be stateless. Even
though it is presently the case, technically there's nothing that prevents the
user from implementing a stateful cookie spec, plugging it into HttpClient, and
by doing so potentially causing quite unpleasant concurrency issues. Therefore,
I believe pluggable cookie specs MAY NOT be shared. There should be a cookie
spec instance created per method invocation 

Oleg"
"HTTPCLIENT-343","DOCUMENTATION","BUG","[API Doc] Compile new preference architecture and HTTP parameterization guide","Document the new preference architecture based on the hierarchy of HttpParams
collections, as well as available parameters and options"
"HTTPCLIENT-392","TEST","IMPROVEMENT","Provide additional test coverage for HTTP and HTTPS over proxy","HTTP and HTTPS over proxy test coverage is still insufficient"
"HTTPCLIENT-560","IMPROVEMENT","BUG","entities and connection handling incomplete","1. entities can not be explicitly disconnected from the underlying stream
2. entities do not tell whether they have an underlying stream

patch follows

cheers,
  Roland"
"HTTPCLIENT-318","BUG","BUG","Host configuration properties not updated when the method is redirected","the above uri:

http://www.adobe.com/cgi-bin/redirect?http://lists.w3.org/Archives/Public/www-xsl-fo

generates two 302 responses:

from the original to http://lists.w3.org/Archives/Public/www-xsl-fo
and from that to http://lists.w3.org/Archives/Public/www-xsl-fo/

the client accepts and follows these redirects (a trace of the process shows it's working well) but when 
you ask the getmethod what uri we ended up at using the getURI() method it returns the bastardised 
result:

http://www.adobe.com/Archives/Public/www-xsl-fo/

instead of the correct 

http://lists.w3.org/Archives/Public/www-xsl-fo/

that the client has actually downloaded.

using cvsup'd copy showing version string "" Jakarta Commons-HttpClient/2.1m1"""
"HTTPCLIENT-533","DOCUMENTATION","BUG","CookiePolicy.registerCookieSpec(CookiePolicy.DEFAULT, <Some CookieSpec>); does not work as documented","I use HtmlUnit to access some quote information. Cookies shall be ignored,so I
set the default policy to CookiePolicy.IGNORE_COOKIES. Nevertheless I get error
messages after starting my program. 

The code reads:
---------------------------------------
CookiePolicy.registerCookieSpec(CookiePolicy.DEFAULT, IgnoreCookiesSpec.class);
final WebClient webClient = new WebClient();
final URL url = new URL(""http://de.finance.yahoo.com/q?s=CB3569.SG"");
final HtmlPage page = (HtmlPage) webClient.getPage(url);
----------------------------------------

The error messages are:
----------------------------------------
WARNUNG: Cookie rejected: ""$Version=0; PRF=&t=CB3569.SG; $Domain=finance.yahoo.c
om; $Path=/"". Domain attribute ""finance.yahoo.com"" violates RFC 2109: domain mus
t start with a dot
30.11.2005 10:28:20 org.apache.commons.httpclient.HttpMethodBase processResponse
Headers
WARNUNG: Cookie rejected: ""$Version=0; B=7fkoh9l1oqs4h&b=3&s=hb; $Domain=.yahoo.
com; $Path=/"". Domain attribute "".yahoo.com"" violates RFC 2109: host minus domai
n may not contain any dots
----------------------------------------"
"HTTPCLIENT-1111","BACKPORT","IMPROVEMENT","Setting SSLSocket parameters","In HttpClient 4.0.3, it was easy to subclass SSLSocketFactory, and set SSLSocket options (e.g. setEnabledCipherSuites() or setSSLParameterse()) before the SSL handshake happened. This way it was possible to e.g. restrict cipher suites on per-HttpClient basis (instead of JVM-wide system properties).

In HttpClient 4.1.1, the design has changed quite a lot, and copy-pasting of several long methods is needed. 

Ideally, SSLSocketFactory should support applying SSLParameters to the socket. However, SSLParameters is Java 1.6, so if we want to keep compatibility with 1.5, that's out.

However, it'd be nice to at least have a method (e.g. ""protected SSLSocket prepareSSLSocket(SSLSocket s)"") that would get called immediately after a socket is retrieved from the socket factory. The default implementation could be just ""return s;"", but subclasses could do something like s.setEnabledCipherSuites() s.setSSLParameters()."
"HTTPCLIENT-797","DESIGN_DEFECT","BUG","o.a.h.conn.scheme.PlainSocketFactory is not a true Singleton","The class ""org.apache.http.conn.scheme.PlainSocketFactory"" has a factory method, getSocketFactory(), and clearly indicates in the Javadocs that it expects to be a Singleton; however, the presence of public constructors makes it quite possible that this is not the case.

To protect the Singleton status of the class, the constructors should be private, or, at the very least, default (package) access. This will force access to the single instance through the factory method."
"HTTPCLIENT-414","BUG","BUG","cookies > 20 years invalidated"," "
"HTTPCLIENT-583","BUILD_SYSTEM","IMPROVEMENT","Build.xml - add log level definitions","The default log level is debug, which produces quite a lot of output when testing.

The patch allows separate definition of wire and other log levels (assuming SimpleLog is used)"
"HTTPCLIENT-285","RFE","IMPROVEMENT","Ability to ignore (reject) cookies altogether","I was looking for a way to ignore cookies altogether, but there doesn't appear
to be one.  I could definitely use this capability right now, and I can see
others making use of it at times."
"HTTPCLIENT-241","IMPROVEMENT","IMPROVEMENT","Support for handling large files should be added","You should probably change the EntityEnclosingMethod content length field 
to a long in a future release. Currently it's an int."
"HTTPCLIENT-771","BUG","BUG","ConcurrentModificationException thrown in MultiThreaded code","Now seeing this error.  This is with default cookie settings.  Happening rarely, however the web sites we're talking to do not use cookies very much.


java.util.ConcurrentModificationException
        at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
        at java.util.AbstractList$Itr.next(AbstractList.java:343)
        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)
        at org.apache.http.client.protocol.RequestAddCookies.process(RequestAddCookies.java:152)
        at org.apache.http.protocol.BasicHttpProcessor.process(BasicHttpProcessor.java:290)
        at org.apache.http.protocol.HttpRequestExecutor.preProcess(HttpRequestExecutor.java:160)
        at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:355)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:501)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:456)
        at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:422)
        at com.hi5.os.Hi5RemoteContentFetcher.fetch(Hi5RemoteContentFetcher.java:279)"
"HTTPCLIENT-329","DOCUMENTATION","IMPROVEMENT","[API Doc] Compile performance optimization guide","Performance optimization guide is long overdue and badly needed. The more people
start using HttpClient in all sorts of creative ways the more we are going to
need it.

Oleg"
"HTTPCLIENT-121","BUG","BUG","Cookie.java blowing up on cookies from ""country code"" domains","The following exception is thrown from Cookie.java when receiving a cookie from
a ""country code"" domain such as amazon.ca.

     [java] INFO: Cookie.parse(): Rejecting set cookie header
""session-id=702-1613649-9326458; path=/; domain=
.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT,
session-id-time=1035878400; path=/; domain=.amazon.ca;
expires=Tuesday, 29-Oct-2002 08:00:00 GMT"" because ""session-id"" has an illegal
domain attribute ("".amazon.ca"")
 for the given domain ""www.amazon.ca"".  It violoates the Netscape cookie
specification for non-special TLDs.
     [java] Oct 22, 2002 9:32:37 AM org.apache.commons.httpclient.HttpMethodBase
processResponseHeaders
     [java] SEVERE: Exception processing response headers
     [java] org.apache.commons.httpclient.HttpException: Bad Set-Cookie header:
session-id=702-1613649-9326458
; path=/; domain=.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT,
session-id-time=1035878400; path=/; do
main=.amazon.ca; expires=Tuesday, 29-Oct-2002 08:00:00 GMT Illegal domain
attribute .amazon.ca
     [java]     at org.apache.commons.httpclient.Cookie.parse(Cookie.java:944)
     [java]     at
org.apache.commons.httpclient.HttpMethodBase.processResponseHeaders(HttpMethodBase.java:141
9)
     [java]     at
org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1504)
     [java]     at
org.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBase.java:2128)
     [java]     at
org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:790)
     [java]     at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:442)


The http response that caused this exception is below.

HTTP/1.1 302 Found
Date: Tue, 22 Oct 2002 13:30:11 GMT
Server: Stronghold/2.4.2 Apache/1.3.6 C2NetEU/2412 (Unix)
Set-Cookie: session-id=702-8591055-5561622; path=/; domain=.amazon.ca;
expires=Tuesday, 29-Oct-2002 08:00:00 GMT
Set-Cookie: session-id-time=1035878400; path=/; domain=.amazon.ca;
expires=Tuesday, 29-Oct-2002 08:00:00 GMT
Location: http://www.amazon.ca/exec/obidos/tg/browse/-/915398/702-8591055-5561622
Connection: close
Transfer-Encoding: chunked
Content-Type: text/html

I've seen this problem with other .ca domains so this isn't a problem unique to
amazon.ca.

My guess would be that the problem is on line 929 of Cookie.java:

int domainParts = new StringTokenizer(cookie.getDomain(), ""."").countTokens();

Where domainParts would be 2 for a domain like "".amazon.ca"" instead of the 3
that the code is expecting.  I'm not that familiar with the cookie spec so I
could be completely wrong ;-)

The results above were done with the Oct 20/2002 gump build."
"HTTPCLIENT-557","BUG","BUG","Nullpointer when creating URI from scheme specific part with null fragment","in org.apache.commons.httpclient.URI class constructor:

public URI(String scheme, String schemeSpecificPart, String fragment)
        throws URIException {
....
_fragment = fragment.toCharArray(); 

should be 

_fragment = fragment==null ? null : fragment.toCharArray();"
"HTTPCLIENT-627","IMPROVEMENT","IMPROVEMENT","overhaul connection manager and associated connection interface","MultiThreadedHttpConnectionManager/HttpHostConnection needs to be overhauled to provide a layer on top of OperatedClientConnection.
Preliminary working names: ThreadSafeClientConnManager/ManagedClientConnection

This implies some work on former HttpMethodDirector and HttpClient to verify completeness of the new connection management API.
"
"HTTPCLIENT-617","IMPROVEMENT","BUG","Hostname verification:  turn off wildcards when CN is an IP address","Hostname verification:   turn off wildcards when CN is an IP address.  This is a further improvement on HTTPCLIENT-613 and HTTPCLIENT-614.

Example - don't allow:
CN=*.114.102.2

I'm thinking of grabbing the substring following the final dot, and running it through ""Integer.parseInt()"".  If the NumberFormatException isn't thrown (so Integer.parseInt() actually worked!), then I'll turn off wildcard matching.  Notice that this won't be a problem with IP6 addresses, since they don't use dots.  It's only a problem with IP4, where the meaning of the dots clashes with dots in domain names.

Note:  when I turn off wildcard matching, I still attempt an exact match with the hostname.  If through some weird mechanism the client is actually able to use a hostname such as ""https://*.114.102.2/"", then they will be okay if that's what the certificate on the server contains."
"HTTPCLIENT-273","BUG","BUG","ConnectionTimeoutException doesn't releaseConnection()","When a ConnectionTimeoutException is thrown, HttpConnection doesn't seem to
release the connection. Instead, the connection is properly released if an
InterruptedIOException is thrown.

This is the pattern I use:

Try {
     method.execute(...);
     method.getResponseBodyAsString();
 } catch (ConnectionTimeoutException cte) {
     ...
 } catch (InterruptedIOException ioe) {
     ...
 } finally {
     method.releaseConnection();
     LOG.info(""RELEASED"");   
 }

The following log shows that no actual release is performed, while the message
""RELEASED"" is logged.

10544  DEBUG [MainCheck2] httpclient.HttpConnection - enter
HttpConnection.isResponseAvailable(int)
10930  WARN  [MainCheck1] httpclient.HttpConnection - The host
www.pccomputing.com:80 (or proxy null:-1) did not accept the connection within
timeout of 3000 milliseconds
10931  WARN  [MainCheck1] CheckPerformer - Connection Timeout occurred..
org.apache.commons.httpclient.HttpConnection$ConnectionTimeoutException
at org.apache.commons.httpclient.HttpConnection.open(HttpConnection.java:659) 
...
at PersistenceCheck$MainCheck.run(PersistenceCheck.java:306)
10932  INFO  [MainCheck1] CheckPerformer - RELEASED

->Here no call to HttpConnection.releaseConnection() is performed. 

Thanks"
"HTTPCLIENT-205","BUG","BUG","HttpMethodBase(String) incorrectly encoding URI","The HttpMethodBase(String) constructor is handling URIs incorrectly. The
Javadocs indicate that the given URI should already be escaped but the
constructor uses the URI constructor for unescaped URIs."
"HTTPCLIENT-1123","RFE","RFE","Implement a way to override or resolve DNS entries defined in the OS","When working with HttpClient in restrictive environments, where the user doesn't have the permissisions to edit the local /etc/hosts file or the DNS configuration, can be eased with an DNS Overrider capability. 

This can be useful with JMeter which can follow redirects automatically and resolve some of the redirected hosts against its configuration. Another example is a custom forward proxy, written in Java and based on httpclient, which can be deployed is such a restricted environment that would ease the development of various web solutions for some developers. "
"HTTPCLIENT-220","BUG","BUG","HttpClient does not properly handle 'application/x-www-form-urlencoded' encoding","As always I'd like to pass on my thanks, I'm finding HttpClient really useful.

The problem occurs because I use Struts map based ActionForm and these generate 
request parameters of the form:

<input type=""text"" name=""searchSelection(c)"">

When this is submitted using the PostMethod class the generateRequestBody() is 
called and in turn this calls the URI.encode() method with a BitSet of the 
acceptable characters. In this case the '(' and ')' characters are marked as 
acceptable.

The problem is that this does not work correctly when I submit it to my remote 
server. If however I issue the request directly (from a webpage rather than 
using HttpClient) it works and when I examine the request input stream I can see 
that the parameter has been re-written so that 'select(c)' is displayed as 
'select%28c%29'.

This may be my error because of encoding problems or the fact I am not setting 
the content type etc. correctly. Or it could be a bug. I'm afraid my HTTP 
knowledge is not good enough.

Chris Mein"
"HTTPCLIENT-315","BUG","BUG","HttpURL creates wrong authority String when user info is changed","When changing the user info on an existing HttpURL which has additional port
information, the new authority String contains a wrong hostname part: instead of
getting ""hostname:portnumber"" the string is ""hostnameportnumber"", i.e. the "":""
is missing.
Methods which needs to be changed are:

setRawPassword(...)
setRawUser(...)
setRawUserinfo(...)

(look for the line
String hostport = (_port == -1) ? hostname : hostname + _port;
)

Andreas Fnger
ESIGN Software GmbH"
"HTTPCLIENT-136","IMPROVEMENT","BUG","Inadequate HTTP proxy server support in HttpClient.","1. The HttpClient class does not save the StatusLine from the hidden
ConnectMethod object used to connect via an HTTP proxy server, thus any proxy
failures are only picked up as 'anonymous exceptions', this is useless for
gracefull recovery and rapid debugging.

2. The current class structure is too fragile to neatly support HTTP Proxy (and
authenication) chains so it would be a good idea to look at this at the same
time, preferable with support for a Proxy chain redirect when an non/dead HTTP
Proxy server is found."
"HTTPCLIENT-204","BUG","BUG","StackOverflowError in HttpConnection","When the HttpConnection#WrappedOutputStream.flush () encounters IOException 
druign write, it is calling HttpConnection.close which calls 
HttpConnection.closeSocketAndStreams and which eventually calls 
HttpConnection#WrappedOutputStream.flush again.  The circular calls will cause 
StackOverflowError.

I run into this accidentally when I was trying to extend HttpConnection.  But 
looking through the code, I believe any IOException may cause the same 
problem.  The circular calls should be either removed or controlled.  Below is 
part of teh stack trace

java.lang.StackOverflowError
        at java.lang.Exception.<init>(Unknown Source)
        at java.io.IOException.<init>(Unknown Source)
        at java.net.SocketException.<init>(Unknown Source)
        at java.net.SocketOutputStream.socketWrite(Native Method)
        at java.net.SocketOutputStream.write(Unknown Source)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ
e(HttpConnection.java:1273)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.FilterOutputStream.close(Unknown Source)
        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht
tpConnection.java:1083)
        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav
a:1024)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand
leException(HttpConnection.java:1235)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ
e(HttpConnection.java:1275)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.FilterOutputStream.close(Unknown Source)
        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht
tpConnection.java:1083)
        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav
a:1024)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand
leException(HttpConnection.java:1235)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ
e(HttpConnection.java:1275)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.FilterOutputStream.close(Unknown Source)
        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht
tpConnection.java:1083)
        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav
a:1024)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand
leException(HttpConnection.java:1235)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ
e(HttpConnection.java:1275)
        at java.io.BufferedOutputStream.flushBuffer(Unknown Source)
        at java.io.BufferedOutputStream.flush(Unknown Source)
        at java.io.FilterOutputStream.close(Unknown Source)
        at org.apache.commons.httpclient.HttpConnection.closeSocketAndStreams(Ht
tpConnection.java:1083)
        at org.apache.commons.httpclient.HttpConnection.close(HttpConnection.jav
a:1024)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.hand
leException(HttpConnection.java:1235)
        at org.apache.commons.httpclient.HttpConnection$WrappedOutputStream.writ
e(HttpConnection.java:1275)"
"HTTPCLIENT-466","IMPROVEMENT","BUG","URI.parseUriReference treats strings with leading ':' as absolute URIs with zero-length scheme","URI.parseUriReference treats strings with leading ':' as absolute URIs with a
zero-length scheme. If you then try to derelativize such a URI against a base
URI, you just get the same URI with leading ':'. 

IE and Firefox treat URI strings with a leading ':' as relative URIs. For
example, an HREF of "":foo"" in the context of base URI
""http://www.example.com/path/page"" would derelativize as
""http://www.example.com/path/:foo"". (Only if another character comes before the
colon is it interpreted as a URI scheme.)

It'd be desirable for HTTPClient URI to do the same thing.

Example code to demonstrate:

import org.apache.commons.httpclient.URI;
URI base = new URI(""http://www.example.com/path/page"");
URI rel1 = new URI("":foo/boo"");
System.out.println((new URI(base,rel1)).toString()); // displays just "":foo""

A potential fix would be for URI.parseUriReference() to avoid interpreting a ':'
in the zero position as indicating a zero-length scheme:

-       if (atColon < 0 || (atSlash >= 0 && atSlash < atColon)) {
+       if (atColon <= 0 || (atSlash >= 0 && atSlash < atColon)) {

and

-        if (at < length && tmp.charAt(at) == ':') {
+        if (at > 0 && at < length && tmp.charAt(at) == ':') {"
"HTTPCLIENT-714","REFACTORING","","move route computation from client to director","The computation of routes should be done in the ClientRequestDirector, not in the Client.
The director needs to compute routes for redirects, so it should compute all routes.
"
"HTTPCLIENT-561","BUG","BUG","entity returns the same stream for getContent()","BasicHttpEntity and GzipDecompressingEntity will return the same stream
when getContent() is called multiple times. That is not allowed by the
HttpEntity interface. They should rather throw an IllegalStateException.

Some tests and EntityUtils rely on getContent to return the same stream
for multiple calls.

patch follows,
  Roland"
"HTTPCLIENT-257","RFE","BUG","NTLM class registers Sun JCE implementation by default","Currently the NTLM class attempts to load and register the Sun JCE implementation unless a 
System property is set to indicate a different JCE to use.  We should remove this entirely and leave 
the installation and configuration of the JCE to the application rather than trying to do it ourselves 
as this could cause problems with other implementations of JCE.  I'll attach an initial patch for this 
in a moment, with a patch for the documentation in the morning.  (Writing docs at 1am is never a 
good idea.)"
"HTTPCLIENT-745","TASK","IMPROVEMENT","no classes with default visibility","There should be no classes with default (package) visibility. They cause problems when classes using them are extended. All classes should either be public, or nested with protected visibility where they are used. Nesting with private visibility may be acceptable in certain cases, for example in final classes.
"
"HTTPCLIENT-12","BUG","BUG","double encoding of URLs","In HttpMethodBase.generateRequestLine(HttpConnection connection, String name, 
String reqPath, String qString, String protocol)

the path is always encoded using URIUtil.encode(reqPath,URIUtil.pathSafe()). 
However, if the path already contains an encoding space, i.e. %20, the % will 
be encoded again, so we get %2520. This behavior is not correct. We shouldn't 
encode any % signs."
"HTTPCLIENT-885","BUG","BUG","URLEncodedUtils fails to parse form-url-encoded entities that specify a charset","If a form-url-encoded HTTP entity specifies a charset in its Content-Type header, then URLEncodedUtils.parse(HttpEntity) fails to parse it.

An entity with content type ""application/x-www-form-urlencoded; charset=UTF-8"" should be detected as form-url-encoded and parsed as such, honoring the specified character set. Currently the code requires an exact, case-insensitive match with ""application/x-www-form-urlencoded"" for an entity to be detected as form-url-encoded.

It appears that the author of URLEncodedUtils.parse(HttpEntity) tried to take character sets into account, but expected to find them in the Content-Encoding header instead of as a parameter in the Content-Length header. The HTTP 1.1 spec makes it clear that the Content-Encoding header is for specifying transformations like gzip compression or the identity transformation -- not for specifying the entity's character set.

Here are some helpful links.
http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.4
http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.5
http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.11

This is related to: https://issues.apache.org/jira/browse/HTTPCLIENT-884"
"HTTPCLIENT-411","BUG","BUG","Checking of stale connections is broken","HttpConnections that went stale (dropped by server) throw SocketExceptions
instead of silently re-opening themselves, as has been the case with earlier
versions of HttpClient.

I think the problem for this can be found in HttpConnection:

  public boolean closeIfStale() throws IOException {
    if (used && isOpen && isStale()) {
      LOG.debug(""Connection is stale, closing..."");
      close();
      return true;
    }
    return false;
  }

staleness is only checked if used = true, but there is no code in HttpConnection
that sets the used flag. In other words: used is always false and isStale() is
never called."
"HTTPCLIENT-407","DOCUMENTATION","IMPROVEMENT","Errors in character entities in Javadoc for HttpVersion","There are some errors in the Javadoc for the HttpVersion class. This is the
class comment:

 *  <p>HTTP version, as specified in RFC 2616.</p>
 *  <p>
 *  HTTP uses a ""&ltmajor&gt.&ltminor&gt"" numbering scheme to indicate versions
 *  of the protocol. The protocol versioning policy is intended to allow
 *  the sender to indicate the format of a message and its capacity for
 *  understanding further HTTP communication, rather than the features
 *  obtained via that communication. No change is made to the version
 *  number for the addition of message components which do not affect
 *  communication behavior or which only add to extensible field values.
 *  The &ltminor&gt number is incremented when the changes made to the
 *  protocol add features which do not change the general message parsing
 *  algorithm, but which may add to the message semantics and imply
 *  additional capabilities of the sender. The &ltmajor&gt number is
 *  incremented when the format of a message within the protocol is
 *  changed. See RFC 2145 [36] for a fuller explanation.
 *  </p>
 *  <p>
 *  The version of an HTTP message is indicated by an HTTP-Version field
 *  in the first line of the message.
 *  </p>
 *  <pre>
 *     HTTP-Version   = ""HTTP"" ""/"" 1*DIGIT ""."" 1*DIGIT
 *  </pre>
 *  <p>
 *   Note that the major and minor numbers MUST be treated as separate
 *   integers and that each MAY be incremented higher than a single digit.
 *   Thus, HTTP/2.4 is a lower version than HTTP/2.13, which in turn is
 *   lower than HTTP/12.3. Leading zeros MUST be ignored by recipients and
 *   MUST NOT be sent.
 *  </p>

Note that the character entities for less-than and greater-than are not properly
ended with a semi-colon.

I will attach a proposed fix."
"HTTPCLIENT-472","BUG","IMPROVEMENT","No equals operation for Credentials implementations","I tripped across a scenario where I wanted to compare credentials, so I could
know to discard connection state (and thus any associated cookies).

Patch to follow shortly."
"HTTPCLIENT-311","BUG","BUG","getScheme() and getPort() return wrong defaults for HttpsURL","getScheme(), if called on an instance of HttpsURL, wrongly returns http instead
of https. That's because dynamic data binding doesn't work for final static
fields (see DEFAULT_SCHEME)."
"HTTPCLIENT-1061","BUG","BUG","Proxy-Authorization header received on server side","
 
 I'm following example
 http://hc.apache.org/httpcomponents-client-ga/examples.html
 Proxy authentication
 
 but it seems that not only proxy is receiving credentials for proxy.
 In log, which is generated at target.host I can see header
 Proxy-Authorization: Basic ....

--------- HEADER
Host:target.host:443
Connection:Keep-Alive
User-Agent:Apache-HttpClient/4.1 (java 1.5)
Proxy-Authorization:Basic Z
--------- POST


Dusan"
"HTTPCLIENT-680","OTHER","BUG","web site for download of 3.1 fails","Down loading version 3 is not possible.
Documentation for 4. does not match 3."
"HTTPCLIENT-637","TEST","TEST","Unit tests for HttpConn","HttpConn needs more test coverage.
Starting at 0%.
"
"HTTPCLIENT-628","BUG","BUG","AutoCloseInputStream.available() throws IOException when auto-closed","ACIS auto-close itself as soon as EOF is detected. That leads to IOExceptions being throw in response to calls that are valid for a stream that has reached EOF.
ACIS should instead close the _underlying_ stream and switch itself into an EOF mode that does not throw exceptions until it is closed explicitly.

reported by Tom Lipkis on the developer mailing list
http://mail-archives.apache.org/mod_mbox/jakarta-httpcomponents-dev/200702.mbox/%3c200702101905.l1AJ5MeK027997@fw3.pss.com%3e"
"HTTPCLIENT-859","BUG","BUG","BasicCookieStore treats cookies of the same name from the same host as duplicates, even if they have different paths","The DefaultHttpClient is not handling cookies correctly when a single host returns multiple cookies of the same name but with separate paths.  For example, if a single instance of the client is used to access two different webapps on the same server, it may receive two different JSESSIONID cookies:

Cookie: [version: 0][name: JSESSIONID][value: F832C01D23F501CE5EEB296B602700C1][domain: lglom139.example.com][path: /msa-adrenalina][expiry: null]
Cookie: [version: 0][name: JSESSIONID][value: 0FC660347391B93267168F84F2B520F5][domain: lglom139.example.com][path: /maps][expiry: null]

Because the CookieIdentityComparator class does not test the cookie path when determining equality, each new JSESSIONID received replaces the previous one instead of adding a new cookie to the store.  This results in ""disconnecting"" the client from its sessions on the prior webapps.

I've confirmed that adding a path test to CookieIdentityComparator resolves this problem."
"HTTPCLIENT-1001","BUG","BUG","CacheEntryUpdater does not properly update cache entry resource","CacheEntryUpdater#updateCacheEntry() copies the old cache entry's resource, though I believe it should only do so if the response is a 304.  Otherwise it should take the response from the server to update the entry.  This method gets called when validating a cache entry and the server returns a 200 or 304."
"HTTPCLIENT-337","REFACTORING","IMPROVEMENT","Move Content-Type to the RequestEntity","The content type is really a property of the RequestEntity.  It should be moved there."
"HTTPCLIENT-943","DOCUMENTATION","IMPROVEMENT","CacheClient Javadoc and Constants usage cleanup","CacheClient has some empty public java doc on methods that are not get/set.  These should have some body.  

Also the HeaderConstants Class has some overlap with the existing HTTP class for header values.  These need cleaning up."
"HTTPCLIENT-1009","BUG","BUG","http client cache: SizeLimitedResponseReader is not setting content type for InputStreamEntity in constructResponse()","the newly created InputStreamEntity should be populated with content-encoding and content-type."
"HTTPCLIENT-185","BUG","BUG","Ordering of methods in PostMethod changes behaviour","I have just spent the best part of two days trying to work out why
a servlet running in Tomcat was not getting UTF-8 when I had set my
client to send UTF-8. It turns out that if I set my PostMethod request
header after setting the request body the content does not get sent as
UTF-8.

The following gets sent as UTF-8:

      PostMethod post = new PostMethod(destinationUrl.toString());
      post.setStrictMode(false);
      post.setRequestHeader(""Content-Type"",""text/xml; charset=UTF-8"");
      post.setRequestHeader(""user-agent"", ""myAgent"");
      post.setRequestBody(content);
      post.setFollowRedirects(true);

the following doesn't:

      PostMethod post = new PostMethod(destinationUrl.toString());
      post.setStrictMode(false);
      post.setRequestBody(content);
      post.setRequestHeader(""Content-Type"",""text/xml; charset=UTF-8"");
      post.setRequestHeader(""user-agent"", ""myAgent"");
      post.setFollowRedirects(true);

In a live execution I would understand that order makes a big difference, but
when you fill out an object that feels like defining the values of a Java Bean
this likely to be less obvious."
"HTTPCLIENT-1045","BUG","BUG","HttpGet request not being created when parameter ""url"" is present","
/*
* @formatter:off
* 
* The following redirect Location results in a Bad Request (404) being made.
* 
* http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http%3A%2F%2Fwww.qpassport.co.uk%2Fpassport%2F&month=2&year=1947&day=26
* 
* The GET request is made with these headers (Notice the ""Host"" value):
* 
* DEBUG org.apache.http.wire  - >> ""GET http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http%3A%2F%2Fwww.qpassport.co.uk%2Fpassport%2F&month=2&year=1947&day=26 HTTP/1.1[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*//*;q=0.8[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Accept-Language: en-us,en;q=0.5[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Proxy-Connection: Keep-Alive[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Referer: http://www.qpassport.co.uk/passport/register.php?s=b9761dfa820bb55722e3feb6438fa11f&[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""Host: www.qpassport.co.uk/passport/register.php?do=signup&who=adult&url=http[\r][\n]""
* DEBUG org.apache.http.wire  - >> ""User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)[\r][\n]""
*  
* They should be: (Notice the ""Host"" value)
* DEBUG org.apache.http.wire  - >> ""GET http://www.qpassport.co.uk/passport/register.php?do=signup&who=adult&month=2&year=1947&day=26 HTTP/1.1[\r][\n]""
* DEBUG org.apache.http.headers  - >> Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*//*;q=0.8
* DEBUG org.apache.http.headers  - >> Accept-Language: en-us,en;q=0.5
* DEBUG org.apache.http.headers  - >> Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7
* DEBUG org.apache.http.headers  - >> Proxy-Connection: Keep-Alive
* DEBUG org.apache.http.headers  - >> Referer: http://www.qpassport.co.uk/passport/register.php?s=005ef80064a0fb2f5aa6f4677a194928&
* DEBUG org.apache.http.headers  - >> Content-Length: 134
* DEBUG org.apache.http.headers  - >> Content-Type: application/x-www-form-urlencoded; charset=UTF-8
* DEBUG org.apache.http.headers  - >> Host: www.qpassport.co.uk
* DEBUG org.apache.http.headers  - >> User-Agent: Opera/9.20 (Windows NT 6.0; U; en)
* 
* The problem appears to be related to the URL parameter in the request
* when it is removed, the request succeeds.
* 
* @formatter:on
*/
"
"HTTPCLIENT-382","REFACTORING","BUG","Move multipart request to a new RequestEntity type","Multipart posts are currently handled via a separate post method, the MultipartPostMethod.  This 
separate method is unnecessary given the new RequestEntity mechanism."
"HTTPCLIENT-10","IMPROVEMENT","BUG","tests-local fails on 3 tests","1)
testMultiSendCookieGet(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:
<html>
<head><title>ReadCookieServlet: GET</title></head>
<body>
<p>This is a response to an HTTP GET request.</p>
<p><tt>Cookie:
$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>
<tt>$Version=1</tt><br>
<tt>simplecookie=value</tt><br>
<tt>$Path=/httpclienttest/cookie</tt><br>
<tt>$Domain=localhost</tt><br>
</body>
</html>
    at
org.apache.commons.httpclient.TestWebappCookie.testMultiSendCookieGet(TestWebappCookie.java:348)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
2)
testDeleteCookieGet(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:
<html>
<head><title>ReadCookieServlet: GET</title></head>
<body>
<p>This is a response to an HTTP GET request.</p>
<p><tt>Cookie:
$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>
<tt>$Version=1</tt><br>
<tt>simplecookie=value</tt><br>
<tt>$Path=/httpclienttest/cookie</tt><br>
<tt>$Domain=localhost</tt><br>
</body>
</html>
    at
org.apache.commons.httpclient.TestWebappCookie.testDeleteCookieGet(TestWebappCookie.java:389)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
3)
testDeleteCookiePut(org.apache.commons.httpclient.TestWebappCookie)junit.framework.AssertionFailedError:
<html>
<head><title>ReadCookieServlet: PUT</title></head>
<body>
<p>This is a response to an HTTP PUT request.</p>
<p><tt>Cookie:
$Version=1;simplecookie=value;$Path=/httpclienttest/cookie;$Domain=localhost</tt></p>
<tt>$Version=1</tt><br>
<tt>simplecookie=value</tt><br>
<tt>$Path=/httpclienttest/cookie</tt><br>
<tt>$Domain=localhost</tt><br>
</body>
</html>
    at
org.apache.commons.httpclient.TestWebappCookie.testDeleteCookiePut(TestWebappCookie.java:464)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
    at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
FAILURES!!!
Tests run: 108,  Failures: 3,  Errors: 0
httpclient/build.xml [271] Java returned: -1
BUILD FAILED
Total time: 9 seconds"
"HTTPCLIENT-61","RFE","IMPROVEMENT","configurable User-Agent string","User configurable item to set the user agent without haveing to set it on a per
HttpMethod basis."
"HTTPCLIENT-293","RFE","IMPROVEMENT","Provide support for non-ASCII charsets in the multipart disposition-content header","Because of the the following line in getAsciiBytes 
 data.getBytes(""US-ASCII"");

The returned string is modified if has Latin Characters.

Ex : Document non-control -> Document non-control?"
"HTTPCLIENT-937","RFE","IMPROVEMENT","Make CacheEntry use an immutable object to represent cache content ","Make CacheEntry use an immutable object to represent cache content similar to HttpEntity"
"HTTPCLIENT-148","BUG","BUG","Redirect to a relative URL fails","Request the url 
http://commerce1.cera.net/discount-pcbooks/catalog/categories.asp?
search_str=0782128092

On a browser the redirect works, while with HttpClient it doesn't."
"HTTPCLIENT-803","BUG","BUG","SSL connections cannot be established using the IP address","HttpClient 4.x introduced a regression in establishing SSL connections to remote peers. The AbstractVerifier class only checks for matches in CN and SubjectAlternative->DNSName. But, when an IP (instead of a hostname) is used, the check should be done on CN and SubjectAlternative->IPAddress."
"HTTPCLIENT-602","REFACTORING","IMPROVEMENT","refactor HttpClientConnection and HttpProxyConnection","Instead of trying to define a full abstraction for client connections, let's define only a minimal interface in HttpCore with only those methods actually needed in the core. In particular, the core does not need to open connections (since HTTPCORE-11), and it does not care whether a connection is direct or through a proxy. An abstraction for client connections can be defined in HttpConn.

(original description:)
As discussed on the mailing list, separating the responsibility for establishing connections from the connection objects could improve the design and help with proxy support.
"
"HTTPCLIENT-234","RFE","IMPROVEMENT","Customizable Cookie Policy","Even if the server is not complying with the cookie specification, sometimes 
you still need to talk to it.

It would be nice that when setting the Cookie Policy for the HttpMethod, you 
could specify a custom policy that implements the CookieSpecBase but may 
handle certain problems more leniently.  This would be instead of specifying 
one of the three hard-coded policies."
"HTTPCLIENT-504","BUG","BUG","max connections per host setting does not work","When using the MultiThreadedHttpConnectionManager the default maximal
connections per host/port cannot be exceeded (allowed maximum is 2 by default).
Attempts to exceed this by manually setting the max connections using
HttpConnectionManagerParams#setMaxConnectionsPerHost fail. This is caused by a
bug in the MultiThreadedHttpConnectionManager."
"HTTPCLIENT-605","BUILD_SYSTEM","IMPROVEMENT","junit dependency in pom.xml with default compile scope","The dependency set as defined in:
http://www.ibiblio.org/maven2/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.pom
includes junit, but not with a <scope>test</test>. I suppose the junit dependency should have a test scope. Could someone fix this? Because of this my application is packaged including junit 3.8.1, which adds 118KiB for nothing.
"
"HTTPCLIENT-467","BUG","BUG","CookieSpecBase.domainMatch() leaks cookies to 3rd party domains","The change committed for #32833
<http://issues.apache.org/bugzilla/show_bug.cgi?id=32833> is buggy; it doesn't
match browser behavior and in fact leaks cookies to third party domains. 

To see, try the following:

CookieSpecBase cspec = new CookieSpecBase();
Cookie cookie = new Cookie("".hotmail.com"",""foo"",""bar"",""/"",Integer.MAX_VALUE,false);
cspec.match(""iwanttostealcookiesfromhotmail.com"",80,""/"",false,cookie);

It will return true. Testing in Firefox1.0.4 and IE6 show no such similar
leakage for similar cases. (Indeed, it'd be a headline-making privacy bug if
they were to do this.)

Those browsers do, in my limited testing, behave as desired by the filer of
#32833: a cookie of domain value '.mydomain.com' will be returned to exact host
'mydomain.com' (. However, the fix that was suggested was overbroad.

I suggest instead for CookieSpecBase.domainMatch():

    public boolean domainMatch(final String host, final String domain) {
// BUGGY: matches a '.service.com' cookie to hosts like 'enemyofservice.com'
//        return host.endsWith(domain)
//            || (domain.startsWith(""."") && host.endsWith(domain.substring(1)));
// BETTER: RFC2109, plus matches a '.service.com' cookie to exact host 'service.com'
        return host.equals(domain)
            || (domain.startsWith(""."") 
                    && (host.endsWith(domain)
                            || host.equals(domain.substring(1))));
    }"
"HTTPCLIENT-194","RFE","BUG","httpClient does not support installation of different SSLSocketFactory","Description:

The SSLProtocolSocketFactory class had hard-
coded ""javax.net.ssl.SSLSocketFactory"" as the socket factory.  It does not 
support installation of other socket factory.

Proposed Fix:

We added a setDefaultSSLSocketFactory method to the SSLProtocolSocketFactory 
and modified the code to use the factory it it is set.  The code falls back on 
using ""javax.net.ssl.SSLSocketFactory"" if a default is not set."
"HTTPCLIENT-818","DOCUMENTATION","BUG","No documentation on how to use CookieSpec","None of http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpec.html, http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpecFactory.html, http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/cookie/CookieSpecRegistry.html, or http://hc.apache.org/httpcomponents-client/httpclient/apidocs/org/apache/http/impl/client/DefaultHttpClient.html explain how to set the CookieSpec that the HttpClient actually uses. It looks like CookieSpecRegistry might be it, but it doesn't document what the ""names"" mean, so I don't know what to pick to make a factory actually get used."
"HTTPCLIENT-988","IMPROVEMENT","IMPROVEMENT","cache module should strip 'Content-Encoding: identity' from responses","Per the RFC, the ""identity"" content coding SHOULD NOT be used in the Content-Encoding header:

http://www.w3.org/Protocols/rfc2616/rfc2616-sec3.html#sec3.5

The current implementation will pass 'Content-Encoding: identity' through unchanged, although it would be simple enough to filter this out.
"
"HTTPCLIENT-279","BUG","BUG","Connections are not release when a recoverable exception occurs.","Please see the url for discussion details."
"HTTPCLIENT-1000","RFE","IMPROVEMENT","Configure Maximum Connection Lifetimes","Provide a means of configuring a maximum lifetime for HttpClient connections.  Currently, it would appear as long as a connection is used it may persist indefinitely.

This would be useful for situations where HttpClient needs to react to DNS changes, such as the following situation that may occur when using DNS load balancing:
 - HttpClient maintains connections to example.com which resolves to IP A
 - Machine at IP A fails, and example.com now resolves to backup machine at IP B
 - Since IP A is failing, connections are destroyed, and new connections are made to IP B
 - Machine at IP A recovers, but HttpClient maintains connections to IP B since the connections are still healthy

The desired behavior would be that connections to IP B will reach their connection lifetime, and new connections could be created back to IP A according to the updated DNS settings."
"HTTPCLIENT-990","IMPROVEMENT","IMPROVEMENT","Allow heuristic freshness caching","I noticed that the CachingHttpClient behaves strangely when it receives responses with only the public cache-control directive, e.g.:

HTTP/1.0 200 OK
Server: My test server
Cache-control: public
Content-Length: 1

1


Using a debugger, I could see that the response is cached. But when the response is queried from the cache, it is not considered as ""fresh"".
According to the HTTP RFC, such responses ""may"" be cached (I understand it as a ""should"" in our case)... but there's no reason to put responses in the cache if we don't use them later one.

The ""freshness of the response is analysed after the response is queried from the cache, thanks to:
CachedResponseSuitabilityChecker#canCachedResponseBeUsed()
... calling CacheEntry#isResponseFresh()
... returning true if the response date (getCurrentAgeSecs()) is lower than its use-by date (getFreshnessLifetimeSecs())

The issue is that getFreshnessLifetimeSecs() returns 0 when there is no max-age directive.

This could be fixed by replacing the code of CacheEntry#isResponseFresh() by:
    public boolean isResponseFresh() {
        final long freshnessLifetime = getFreshnessLifetimeSecs();
        if (freshnessLifetime == 0) {
            return true;
        }
        return (getCurrentAgeSecs() < getFreshnessLifetimeSecs());
    }

But i'm not 100% confident about not producing some bad side-effects..."
"HTTPCLIENT-356","DOCUMENTATION","IMPROVEMENT","[API DOC] Authentication guide update: alternate authentication","Add a section on alternate authentication."
"HTTPCLIENT-192","BUG","BUG","Duplicate request headers when connect through proxies","When negotiating proxy servers or during write-failure retries, the httpClient 
adds duplicate request headers to each retry.  The result is that each header 
is duplicated multiple times (number of retries).  This only impact the headers 
that allow multiple values (the others were prevented byt the code).  In  
Particular, it affects ""cookie"" header.  It happens more often when going 
through proxy server with tunnelling connections (https), but also happens on 
http on NTLM proxy server (need multiple round trips to get authenticated).

Steps to Reproduce:
Setup a client application to go to a website that requires going through a 
proxy server that supports tunnelling for https connections and authenticate 
users (Basic and/or NTLM).  The website also need to support keep-alive and 
support https. Initilize the HttpState with a cookie. Turn httpClient 
logging ""wire, debug and trace"" logging on.  Set the proxy credential with 
valid user id and password.

Then run the application against any url on the website.

Test Results and fixes:
1. When connect to https through a (Netscape/Basic auth) proxy that does 
the ""tunnelling"", the initial ""CONNECT"" adds the cookie header once.  The proxy 
returns the 407.  Then the code will use the proxy credential to do 
the ""CONNECT"" again.  After successful connection (200), the code will do the 
proper ""POST"".  The httpClient code adds the same cookie one more time in here.

This case was caused by the wrapper class ConnectMethod using the wrapped 
method ""addRequestHeaders"" to build headers for the ""CONENCT"".  It can be fixed 
by having the ConnectMethod only adds headers it needs (""addHostRequestHeader"" 
and ""addProxyAuthorizationRequestHeader"").

2. When connect to http through proxy.  The client first sends a ""POST"" without 
proxy credentials, and gets a 407 back.  The cookie header is added before that 
happens.  Then (loop in the HttpMethodBase.execute) the client will retry 
the ""POST"" with the credentials (the logic require to have a response header to 
submit credentials).  In the retry, the cookie is added again 
(addRequestHeaders is called inside the writeRequest).

3. When using kee-alive with no-proxy on http, if the connection times out, the 
next call of the method will get a socket error on write.  The retry loop in 
the processRequest method will retry the request again.  It will add the cookie 
again.  To deal with both case 2 and 3, the addRequestHeadres call need to be 
moved up to the beginning of the HttpMethodBase.execute.  We tested this 
approach and it worked for us.

4. When negotiating NTLM proxy for https, multiple round trips are needed to 
get user authenticated.  The same ConnectMethod instance is used.  So the 
adding of the proxy authenticate headers need to be done with the ConnectMethod 
instance (vs. the wrapped method for Host header).  Otherwise, the 
Authenticator class would not be able to find the information for 
authenticating user.


I will send in our suggested fixes later.

Build: This is based on 0307 nightly build.  We run into some other problems 
when trying the 0410 nightly build."
"HTTPCLIENT-308","IMPROVEMENT","BUG","Log level for message should be debug instead of error.","In method org.apache.commons.httpclient.HttpMethodBase.getResponseBody() Log
message should be logged as debug instead of error. 

717             } catch (IOException e) {
718                 LOG.error(""I/O failure reading response body"", e);
719                 this.responseBody = null;
720             }

According to HTTPCLIENT-57:
2) Only/always log exception stack traces at the debug level
        } catch (Exception ex) {
            log.debug"
"HTTPCLIENT-622","BUG","BUG","leak in MultiThreadedHttpConnectionManager.ConnectionPool.mapHosts","Once entries are added to MultiThreadedHttpConnectionManager.ConnectionPool.mapHosts, they are never cleaned up unless MultiThreadedHttpConnectionManager is shutdown."
"HTTPCLIENT-17","RFE","IMPROVEMENT","need a way to set time out when using HttpClient and HttpMultiClient","When using class HttpClient or HttpMultiClient, there is no way to set the time 
out value. Because the setTimeout method is in HttpConnection and HttpClient or 
HttpMultiClient doesn't expose the HttpConnection object. One option is to add 
a method setTimeout in HttpClient and HttpMultiClient. Another option is to add 
such a method in HttpMethod."
"HTTPCLIENT-939","BUG","BUG","302 response without location header throws exception","Hi, 

According to HTTP 1.1 Spec : http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3.3
""The temporary URI SHOULD be given by the Location field in the response. Unless the request method was HEAD, the entity of the response SHOULD contain a short hypertext note with a hyperlink to the new URI(s).""

Now, in ""DefaultRedirectStrategy.getLocationURI()"", there's a ProtocolException thrown if location header is null.  

if (locationHeader == null) {
    // got a redirect response, but no location header
    throw new ProtocolException(
        ""Received redirect response "" + response.getStatusLine()
       + "" but no location header"");
 }

The specs says ""SHOULD"" and not ""MUST"". ProtocolException ""signals that an HTTP protocol violation has occurred"", which is not exactly true."
"HTTPCLIENT-1058","BUG","BUG","SO_TIMEOUT not set early enough for SOCKS proxies in PlainSocketFactory","I've created my own delegating SchemeSocketFactory implementation which supports setting SOCKS proxies on socket creation. In the connectSocket implementation, I previously just delegated to PlainSocketFactory.

The problem there was, that the SO_TIMEOUT was not set on the socket before the connection was established through the SOCKS proxy. This lead to a stop on the native read0 method because the socket is endlessly waiting for a read to occur from the proxy, so it can continue with the the connect to the actual socket destination through the proxy. I made sure I set the SO_TIMEOUT parameter in HttpParams, but it did not get honored by PlainSocketFactory.

To fix this and make HttpClient honor SO_TIMEOUT for SOCKS proxies, the following line has to be added:
  sock.setSoTimeout(HttpConnectionParams.getSoTimeout(params));
in PlainSocketFactory.connectSocket(...).

Heres the complete fixed method:

PlainSocketFactory:            
    public Socket connectSocket(
            final Socket socket,
            final InetSocketAddress remoteAddress,
            final InetSocketAddress localAddress,
            final HttpParams params) throws IOException, ConnectTimeoutException {
        if (remoteAddress == null) {
            throw new IllegalArgumentException(""Remote address may not be null"");
        }
        if (params == null) {
            throw new IllegalArgumentException(""HTTP parameters may not be null"");
        }
        Socket sock = socket;
        if (sock == null) {
            sock = createSocket();
        }
        if (localAddress != null) {
            sock.setReuseAddress(HttpConnectionParams.getSoReuseaddr(params));
            sock.bind(localAddress);
        }
        
        //FIX for SOCKS proxies which get stalled if they don't answer
        sock.setSoTimeout(HttpConnectionParams.getSoTimeout(params));
        
        int timeout = HttpConnectionParams.getConnectionTimeout(params);
        try {
            sock.connect(remoteAddress, timeout);
        } catch (SocketTimeoutException ex) {
            throw new ConnectTimeoutException(""Connect to "" + remoteAddress.getHostName() + ""/""
                    + remoteAddress.getAddress() + "" timed out"");
        }
        return sock;
    }

Currently I've implemented this in my delegating SchemeSocketFactory, because PlainSocketFactory misses this setting.

Dunno if there are other implementations of SocketFactory in HttpClient, which might need this fix. Anyway I hope this helps other people who get  headaches about halting threads because they use SOCKS proxies. :)"
"HTTPCLIENT-763","BUG","BUG","AbstractClientConnAdapter#abortConnection() does not release the connection if called from the main execution thread while there is no blocking I/O operation ","#abortConnection() is usually expected to be  called from a helper thread in order to unblock the main execution thread blocked in an I/O operation. It may be unsafe to call #releaseConnection() from the helper thread, so we have to rely on an IOException thrown by the closed socket on the main thread to trigger the release of the connection back to the connection manager. However, if this method is called from the main execution thread it should be safe to release the connection immediately. Besides, this also helps ensure the connection gets released back to the manager if #abortConnection() is called from the main execution thread while there is no blocking I/O operation."
"HTTPCLIENT-173","RFE","BUG","Multiple DIGEST authentication attempts with same credentials","HttpMethodBase's processAuthenticationResponse uses a set of realms to which
attempts to authenticate have already been made. The elements of the set are a
concatenation of the requested path and the value of the Authentication response
header.

For digest authentication this response header contains a nonce value, which is
uniquely generated by the server each time a 401 response is made. This makes it
impossible to recognize that authentication against this realm has been
attempted before and so all 100 attempts are made before returning. The nonce
should probably not be used in the realmsUsed element

Reported by Rob Owen <Rob.Owen@sas.com>"
"HTTPCLIENT-60","RFE","IMPROVEMENT","Handle virtual hosts, relative urls, multi-homing","Need to be able to open a socket to one ipaddress (or hostname) and then include
a virtual hostname in the Host header. Use InetAddress class perhaps."
"HTTPCLIENT-336","BUG","BUG","ArrayIndexOutOfBoundsException in HttpStatus.getStatusText(508)","Try the following:

    System.out.println(""Status text = "" + HttpStatus.getStatusText(507));
    try {
      System.out.println(""Status text = "" + HttpStatus.getStatusText(508));
    }
    catch (Exception ex) {
      System.err.println(""Exception! msg = "" + ex.getMessage());
      ex.printStackTrace();
    }
    System.out.println(""Status text = "" + HttpStatus.getStatusText(509));

507 -> returns a message as expected
508 -> ArrayIndexOutOfBoundsException
509 -> null as expected"
"HTTPCLIENT-1092","IMPROVEMENT","IMPROVEMENT","ClientPNames.VIRTUAL_HOST is used as is; if not provided, the port should be derived from the target URL","The parameter ClientPNames.VIRTUAL_HOST allows the default Host header to be overridden.

Currently the code uses the HttpHost entry as provided, and does not automatically add the port suffix.
This means that user code has to provide the port - but only if it's not the default for the protocol.

It would be simpler for the user if the port were automatically added.

If the user does not provide the port, the code should derive it from the target URL.

If the user does provide a port number, then that should be used (as is done currently). 
This allows the user to override the port (if that should ever prove necessary)."
"HTTPCLIENT-977","RFE","RFE","provide a memcached implementation for HttpCache","The feature here would be an implementation of the HttpCache interface that stored cache entries in memcached."
"HTTPCLIENT-175","BUG","BUG","HttpState cannot differentiate credentials for different hosts with same Realm names","It seems that one needs a separate HttpState per client per host: from the 
javadocs, if (by coincidence or by design) more than one host uses the same 
realm name, such as ""Private"", then there's an unresolvable conflict, as 
HttpState can only store one set of credentials for a given name...

According to Oleg Kalnichevski, it is plausible just to extend the HttpState 
class with additional methods that would require host to be specified along the
authentication realm when dealing with credentials.

See postings on ""Commons HttpClient Project"" mailing list for more info (dated 
21/03/2003)."
"HTTPCLIENT-992","IMPROVEMENT","IMPROVEMENT","cache should not generate stale responses to requests explicitly requesting first-hand or fresh ones","The current implementation will serve a stale response in the case that it has a stale cache entry but revalidation with the origin fails. However, the RFC says we SHOULD NOT do this if the client explicitly requested a first-hand or fresh response (via no-cache, max-age, max-stale, or min-fresh).
"
"HTTPCLIENT-53","IMPROVEMENT","IMPROVEMENT","Handle Returning Null consistantly","Consider returning empty arrays instead of null consistantly.  eg:
getResponseBody().  There may be good reason for both null and empty array
depending on the circumstannces."
"HTTPCLIENT-275","BUG","BUG","problem with isIPv4address() for relative uri's","the following block of code:

try {
	URI uri = new URI(""http://10.0.1.10:8830"");
	System.out.println(""is IP=""+uri. isIPv4address());
	uri = new URI(uri, ""/04-1.html"");
	System.out.println(""is IP=""+uri. isIPv4address());
} catch (URIException e) { ; }

returns the output:

is IP=true
is IP=false

so by being created from a relative uri URI objects don't have the right setting of  isIPv4address()."
"HTTPCLIENT-118","DOCUMENTATION","BUG","Build with JDK 1.4, get many javadoc warnings","Building httpclient ""dist"" ant target, I get lots of ""warning - The first
sentence is interpreted to be:"".

As the summary says, I get these warnings when I build using JDK 1.4.  Using JDK
1.3.1 yields far fewer problems.  I see this with the latest sources as of this
posting."
"HTTPCLIENT-191","BUG","BUG","NTLM Authentication Fails","NTLM Authentication requires multiple request/responses for the authentication
to succeed.  Since HttpMethodBase is now using just the host, port and realm to
identify whether or not authentication has been attempted the second pass for
NTLM authentication is never performed."
"HTTPCLIENT-72","RFE","IMPROVEMENT","Support for NTLM authentication","A late write in for this would be support for NTLM authenticatin as well as
basic and digest.  Obviously non-trivial but it would be a very big feature.

Adrian Sutton, Software Engineer
Ephox Corporation
www.ephox.com <http://www.ephox.com>"
"HTTPCLIENT-663","TASK","TASK","New Gump projects for HttpComponents 4.0","Create new Gump definitions for the 4.0 code base, both core and client.
There are other Maven-based projects in Gump to learn from, for example Apollo and Excalibur.

"
"HTTPCLIENT-712","RFE","IMPROVEMENT","improve HttpRoute API","Some of the constructors of HttpRoute have three boolean parameters.
Use enumerations to reduce the potential for confusion.

The flags for tunnelled and layered are not independent, since layered implies tunnelled.
These can be combined to a 3-valued enum.
"
"HTTPCLIENT-632","BUG","BUG","Possible NPE in HttpHost","HttpHost line 167 says:
        if (this.port != this.protocol.getDefaultPort()) {

However, a few lines above, protocol is checked for null.

Line 167 should probably read:

        if (this.protocol != null && this.port != this.protocol.getDefaultPort()) {
"
"HTTPCLIENT-39","IMPROVEMENT","IMPROVEMENT","Authorization credentials should be sent pre-emptively","When a web browser receives a <i>401: Unauthorized</i> response code, the
browser prompts for the user and password credentials for the requested
authentication realm.  An Authorization header is then sent for this request. 
HttpClient models this behaviour quite well.

After the web browser has the authentication credentials for a given host, port
and realm, it then sends the Authorization header for subsequent requests
pre-emptively, whithout need for a 401 response.  HttpClient always reqires a
401 response before it will send out the Authorization header.

As <code>HttpClient.startSession()</code> will take a <code>Credentials</code>
object as a parameter as the default credentials, the default credentials should
be sent as part of every request in that session.  Some mechanisim for
over-riding the default credentials should also be provided to be sent
pre-emptively.

The point of this enhancement request is to minimize the number of unnecessisary
401 responses.

It appears that the simple solution might be to modify the logic of when
<code>Authenticator.authenticate()</code> gets called in
<code>HttpMethodBase.addAuthorizationRequestHeader()</code>"
"HTTPCLIENT-269","BUG","BUG","HttpConnection.isResponseAvailable() calls setSoTimeout() but does not catch IOException","HttpConnection.isResponseAvailable() can throw an IOException when setting the
soTimeout but should probably just return false in this case.

<http://marc.theaimsgroup.com/?t=106268485100002&r=1&w=2>"
"HTTPCLIENT-730","BUG","BUG","Use of Multi-Args URI Causes URI-Rewriting to improperly unescape characters","See: http://www.nabble.com/unable-to-encode-reserved-characters-using-java.net.URI-multi-arg-constructors-td14954679.html for information from the httpclient-dev thread.  The basic idea is that URI's multi-arg constructors break things."
"HTTPCLIENT-391","TEST","IMPROVEMENT","Deprecate and replace TestWebapp with the SimpleHttpServer based testing framework","Basically TestWebapp based testcases test functionality of Tomcat, rather than
that of HttpClient. They tend to get broken with every major release of Tomcat
and have proven more of a burden than any good"
"HTTPCLIENT-251","DESIGN_DEFECT","IMPROVEMENT","Content-Length & Transfer-Encoding request headers should be handled by entity enclosing methods","Currently 'Content-Length' & 'Transfer-Encoding' request headers are handled by 
the HttpMethodBase class. This is conceptually wrong and error-prone in my 
opinion. Entity enclosing methods should control 'Content-Length' & 'Transfer-
Encoding' request headers instead, as they provide request content and 
encapsulate the requisite content transfer logic."
"HTTPCLIENT-193","IMPROVEMENT","BUG","Buffered output to socket","--Posted by Slavik Markovich:

Hi all,

This is probably a known issue (but I haven't found the answer for it yet).
I'm using httpclient to post data to a remote server but as far as I can see
(using ethereal) the client is writing every line to the wire without buffering.
After examining the code, I can see that the HttpConnection class is using the
output stream received from the socket directly.
Is there a reason for the direct writing?
This is a problem for me 'cause the remote server sets a very low timeout and
returns a bad request response after receiving the request line (without any
other header line or request body).

Can I easily add a buffered behavior to the http client?

10x"
"HTTPCLIENT-781","RFE","BUG","Respect Keep-Alive Header","HttpClient currently does not respect the 'Keep-Alive' header tokens (timeout, max, etc..) and continues to use the persistent connection beyond limits the server requests.  This leads to failure and falling back to HttpRequestRetryHandler, when it should instead just use a new connection explicitly."
"HTTPCLIENT-142","BUG","BUG","Test case failure for testConnTimeout","[java] There was 1 failure:
     [java] 1)
testConnTimeout(org.apache.commons.httpclient.TestHttpConnection)junit.framework.AssertionFailedError:
Should have timed out
     [java]     at
org.apache.commons.httpclient.TestHttpConnection.testConnTimeout(TestHttpConnection.java:118)
     [java]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
     [java]     at
sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
     [java]     at
sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)

This test has been failing for some time.  It is run with the test-local ant target."
"HTTPCLIENT-512","BUG","BUG","UsernamePasswordCredentials.equals(null) throws NPE","Steps to reproduce:
1. new UsernamePasswordCredentials().equals(null);

Observed:
NullPointerException is thrown

Expected:
equals() returns false"
"HTTPCLIENT-202","BUG","BUG","GetMethod.java checks the ""used"" flag which cannot be set at this time","GetMethod.getResponseBodyAsStream calls HttpMethodBase.checkUsed, which asserts
the flag ""used"" is ""true"". But at this time, ""used"" cannot be true, as ""used"" is
set to true in HttpMethodBase.processRequest, two lines after readResponse is
called (which in turn calls readResponseBody / readResponseBodyAsStream).

Maybe ""requestSent"" is the flag which should be checked instead of ""used""?

My stack trace: (fragment)

java.lang.IllegalStateException: Not Used.
        at
org.apache.commons.httpclient.HttpMethodBase.checkUsed(HttpMethodBase.java:1642)
        at
org.apache.commons.httpclient.methods.GetMethod.getResponseBodyAsStream(GetMethod.java:309)
        at
org.apache.commons.httpclient.methods.GetMethod.readResponseBody(GetMethod.java:428)
        at
org.apache.commons.httpclient.HttpMethodBase.readResponse(HttpMethodBase.java:1893)
        at
org.apache.commons.httpclient.HttpMethodBase.processRequest(HttpMethodBase.java:2496)
        at
org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:1062)
        at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:599)
        at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:497)
        at
org.apache.webdav.lib.WebdavResource.getMethodData(WebdavResource.java:2227)
        at
org.apache.webdav.lib.WebdavResource.getMethodData(WebdavResource.java:2206)
[...]"
"HTTPCLIENT-300","DOCUMENTATION","BUG","BasicAuthenticatonExample.java in CVS","From the example in CVS Revision 1.1.2.1 the code below would lead you to 
belive that setCredentials uses (""HOST"", ""REALM"", credientials). It actually 
should be (""REALM"", ""HOST"", credientials). It looks like it was correct in the 
Revision 1.1 and was changed with Revision 1.1.2.1

// pass our credentials to HttpClient, they will only be used for
// authenticating to servers with realm ""realm"", to authenticate agains
// an arbitrary realm change this to null.
client.getState().setCredentials(
            ""www.verisign.com"",
            ""realm"",
            new UsernamePasswordCredentials(""username"", ""password"")
);"
"HTTPCLIENT-44","RFE","IMPROVEMENT","Non-standards configuration and tracking","A simple strict or setLenient is likely inadequate.  Each particular
non-standard behaviour should be tagged, and settable from the client.  A mask
for particular behavioural features could be provided, with STRICT meaning none
and LENIENT meaning all."
"HTTPCLIENT-866","OTHER","BUG","HttpClient depends on jcip-annotations.jar","When using Java 5 to compile code that uses HttpClient, jcip-annotations.jar must be in the classpath or else you get a compiler error:

    [javac] /path/to/src/SomeFile.java:129: cannot access net.jcip.annotations.GuardedBy
    [javac] file net/jcip/annotations/GuardedBy.class not found
    [javac]         DefaultHttpClient httpclient = new DefaultHttpClient();
    [javac]                                        ^


With Java 6, you get a bunch of warnings instead.
    [javac] org/apache/http/impl/client/AbstractHttpClient.class(org/apache/http/impl/client:AbstractHttpClient.class): warning: Cannot find annotation method 'value()' in type 'net.jcip.annotations.GuardedBy': class file for net.jcip.annotations.GuardedBy not found


This requirement doesn't seem to be documented anywhere, and jcip-annotations.jar is not included in the ""httpcomponents-client-4.0-bin-with-dependencies"" package.
"
"HTTPCLIENT-169","BUG","BUG","Cookies with null value are not formatted correctly","I have a server that sets a bunch of empty cookies:

2003/03/06 16:28:52:055 PST [DEBUG] wire - -<< ""Set-Cookie: list%2ESince=; 
path=/[\r][\n]""
2003/03/06 16:28:52:055 PST [DEBUG] wire - -<< ""Set-Cookie: search%2EPhoneSDA=; 
path=/[\r][\n]""


  On subsequent requests, httpclient attaches these cookies thusly:

2003/03/06 16:28:55:480 PST [DEBUG] wire - ->> ""Cookie: $Version=0; list%
2ESince=null; $Path=/[\r][\n]""
2003/03/06 16:28:55:480 PST [DEBUG] wire - ->> ""Cookie: $Version=0; search%
2EPhoneSDA=null; $Path=/[\r][\n]""


  I'm not sure how to read this portion of wirelog, but seems that actual
values containing the string ""null"" are being sent as part of the request.
In the response to my request, the server now echos cookies with ""null""
values back to me.


2003/03/06 16:28:55:660 PST [DEBUG] wire - -<< ""Set-Cookie: search%
2EPhoneSDA=null; path=/[\r][\n]""
2003/03/06 16:28:55:660 PST [DEBUG] wire - -<< ""Set-Cookie: list%2ESince=null; 
path=/[\r][\n]""


  This isn't good.  Basically, the list.Since= cookie is being
converted to list.Since=null.  This causes the server's script to
crash:

<p>Microsoft VBScript runtime </font> <font face=""Arial"" 
size=2>error '800a000d'</font>
<p>
<font face=""Arial"" size=2>Type mismatch: 'CINT'</font>
<p>
<font face=""Arial"" size=2>/listCust.asp</font><font face=""Arial"" size=2>, line 
283</font> 


  I guess the script tries to assign the string ""null"" to an integer, and
dies.

Reported by Tom Samplonius <tom@sdf.com>"
"HTTPCLIENT-67","BUILD_SYSTEM","BUG","Build environment configuration: Mavenize the build process","- ease of building. HttpClient should be buildable without the user needing to
go away and download extra jars. Maven does a good job of this.
- automated site and build on a nightly basis to pick up changes
- move to j2sdk1.4"
"HTTPCLIENT-436","BUG","BUG","Retry on ConnectionException does not work","I noticed that the Retry handler mechanism does not work when the client cannot
initiate a connection (which throws java.net.ConnectionException). This happens
for me for instance when there is proxy and a tunneling in the picture and
sometimes there are connectivity problems.

I had my own RetryHandler, however, the Connection Timeout exception never falls
in it. I took a look at the source code and noticed that the open() method and
any thrown exception at this level occurs outside the control of the Retry
Handler (which seems to be involved only after open() succeeds).

In fact, if the open() throws ConnectionException (as is my case), since the
try/catch wrapping the open() is not inside the while() but on top of it, it
stops the loop and the retry handler does not get a chance to be invoked .

riad"
"HTTPCLIENT-174","RFE","IMPROVEMENT","Need setURI() methods in HttpMethod interface","I'd like to have the methods setURI( URI ) and setURI( String ) methods. Also a 
method like getRequestURI() because the uri I get now with the method getURI() 
changes if I execute a request which will be automatically forwarded.

The methods setURI can throw an exception if it has already been executed."
"HTTPCLIENT-598","BUG","BUG","ContentLengthInputStream does not implement available() properly","ContentLengthInputStream should either extend FilterInputStream or should delegate available() to wrappedStream.

Otherwise, available() on the response stream (an instance of AutoCloseInputStream, which is properly extending FilterInputStream, and, therefore, delegating to the ContentLengthInputStream) always returns 0.

This issue is important for the clients that try to improve performance by processing all data that can be read in a non-blocking way before blocking on the network."
"HTTPCLIENT-124","BUG","BUG","MultipartPost closes input stream","This is something of a collection of issues that are all interrelated.

1. MultipartPost calls close on the outputstream it retrieved from 
HttpConnection which causes an exception to be thrown later on.  This call 
should be replaced with a call to flush().

2. The MultipartPost classes do not have any logging in them.  We should add 
trace statements at a minimum.

3. new FilePart(String, File) throws a null pointer exception.

4. The tests in TestPartsNoHost are broken.

I'll attach patches for these fixes in a moment, broken down as much as 
possible."
"HTTPCLIENT-1005","CLEANUP","IMPROVEMENT","API surface of caching module can be reduced","While the caching module can currently be considered functional and useful for folks as-is, there are several near-term enhancements planned that could change the exposed binary API of the caching module (although it is not yet clear whether they would or not). In an effort to allow the 4.1 GA release to go forward while hedging bets against future development, we should consider drastically reducing the exposed binary API of the caching module, and not exposing extension points until someone explicitly asks for them.
"
"HTTPCLIENT-883","BUG","BUG","SO_TIMEOUT is not set on a request level","The scenario is as follows: I'm doing two consecutive requests to the same host, using a multi-threaded (or thread safe) connection pool manager. The first invocation has a timeout of 10s and the second has a timeout of 30s. 

In version 3.1 of HttpClient all works well, but in 4.0 I get a timeout exception in the second request, after ~10 seconds, which means the first timeout is used.

Looking at the code, I see that in version 3.1, the HttpMethodDirector.executeWithRetry() method invokes a method named applyConnectionParams() that took care of setting the timeout taken from the request on the socket. 

But in version 4.0, the only place I see the timeout is set on the socket is when DefaultRequestDirector.execute(HttpHost, HttpRequest, HttpContext) opens a connection using the managedConn.open() method. Since the connection is reused between the requests, the second request uses a socket with a timeout of the first request.
"
"HTTPCLIENT-1031","BUG","BUG","Cannot clone BasicClientCookie2 without specified ports","The clone method returns a null pointer exception when called on a BasicClientCookie2 that does not use any ports properties.
In other words, it is impossible to clone a BasicClientCookie2 instance without ports specification.

In the clone() method, they are two main instructions :
 - calling clone() method on super
 - calling clone() method on the ports integer array (which is null)

It may be a good idea to check whether the array is null or not

"
"HTTPCLIENT-453","BUG","BUG","Virtual host setting does not apply when parsing and matching cookies","Virtual host setting does not apply when parsing and matching cookies.

Problem has been reported on the httpclient-dev list by Dan Levine"
"HTTPCLIENT-253","DOCUMENTATION","IMPROVEMENT","Javadocs clean-up","Before Httpclient can be released Javadocs need to be updated and proof-read"
"HTTPCLIENT-511","BUG","BUG","Preemptive Authorization parameter initialization incorrect, causes preemptive auth not to work","Preemptive authorization is defeated by an incorrect initialization. Patch 
follows:
--- DefaultHttpParamsFactory.java       2005-10-10 19:09:10.000000000 -0700
+++ DefaultHttpParamsFactory.java.fixed 2005-10-17 17:00:10.259174920 -0700
@@ -118,9 +118,9 @@
         if (preemptiveDefault != null) {
             preemptiveDefault = preemptiveDefault.trim().toLowerCase();
             if (preemptiveDefault.equals(""true"")) {
-                params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, ""on"");
+                params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, Boolean.TRUE);
             } else if (preemptiveDefault.equals(""false"")) {
-                params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, ""off"");
+                params.setParameter
(HttpClientParams.PREEMPTIVE_AUTHENTICATION, Boolean.FALSE);
             }
         }"
"HTTPCLIENT-42","REFACTORING","IMPROVEMENT","Open up org.apache.commons.httpclient.Base64 please","I have had several problems lately where I needed to truck backwards and
forwards between bytes and base64. As I am using HttpClient, I know I have the
code in my proect, but I need to duplicate it into my own heirarchy to get
access rights. 

Please make appropriate changes to Base64 (can be as simple as marking the
encode and decode methods public) to allow outside use of Base64.

Would be nice to extend Base64 to deal with multi-line Base64 content too - but
I know this is outside of Base64 original intended use. But it would be useful. :)"
"HTTPCLIENT-978","RFE","RFE","provide an ehcache implementation for HttpCache","Provide an implementation of the HttpCache interface that stores cache entries in ehcache.
"
"HTTPCLIENT-982","RFE","RFE","Could we get a way to know if the response has been served from the cache or not ?","Is there a way to know if the response has been served from the cache or not ?
That's an information which might be useful for monitoring the activity of the cache.

If there's no current way, maybe a flag could be added in the request context whenever the response comes from the cache ... ?

"
"HTTPCLIENT-1180","BUG","BUG","NullPointerException when using HttpHead and Request/Response interceptors","When you try to execute a HttpHead object instead of a HttpGet object while using the add request/response interceptors, you get a nullpointerexception.

I can replicate the exception when using the ClientGZipContentCompression example that can be found at the HttpClient examples. But instead of using the HttpGet object I execute a HttpHead object. When I comment the interceptor parts out, I don't get the exception. 

This is the error stack trace I get when executing the code in netbeans:

Exception in thread ""main"" java.lang.NullPointerException
	at testhttphead.ClientGZipContentCompression$2.process(ClientGZipContentCompression.java:74)
	at org.apache.http.protocol.ImmutableHttpProcessor.process(ImmutableHttpProcessor.java:116)
	at org.apache.http.protocol.HttpRequestExecutor.postProcess(HttpRequestExecutor.java:342)
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:472)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:820)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:754)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:732)
	at testhttphead.ClientGZipContentCompression.main(ClientGZipContentCompression.java:92)
Java Result: 1

Here is the code that gives me the error:

package testhttphead;

import java.io.IOException;
import java.io.InputStream;
import java.util.zip.GZIPInputStream;
import org.apache.http.*;
import org.apache.http.client.methods.HttpHead;
import org.apache.http.entity.HttpEntityWrapper;
import org.apache.http.impl.client.DefaultHttpClient;
import org.apache.http.protocol.HttpContext;
import org.apache.http.util.EntityUtils;

/**
 * Demonstration of the use of protocol interceptors to transparently modify
 * properties of HTTP messages sent / received by the HTTP client.
 * <p/>
 * In this particular case HTTP client is made capable of transparent content
 * GZIP compression by adding two protocol interceptors: a request interceptor
 * that adds 'Accept-Encoding: gzip' header to all outgoing requests and a
 * response interceptor that automatically expands compressed response entities
 * by wrapping them with a uncompressing decorator class. The use of protocol
 * interceptors makes content compression completely transparent to the consumer
 * of the {@link org.apache.http.client.HttpClient HttpClient} interface.
 */
public class ClientGZipContentCompression {

    public final static void main(String[] args) throws Exception {
        DefaultHttpClient httpclient = new DefaultHttpClient();

        try {
            httpclient.addRequestInterceptor(new HttpRequestInterceptor() {

                public void process(
                        final HttpRequest request,
                        final HttpContext context) throws HttpException, IOException {
                    if (!request.containsHeader(""Accept-Encoding"")) {
                        request.addHeader(""Accept-Encoding"", ""gzip"");
                    }
                }
            });

            httpclient.addResponseInterceptor(new HttpResponseInterceptor() {

                public void process(
                        final HttpResponse response,
                        final HttpContext context) throws HttpException, IOException {
                    HttpEntity entity = response.getEntity();
                    Header ceheader = entity.getContentEncoding();
                    if (ceheader != null) {
                        HeaderElement[] codecs = ceheader.getElements();
                        for (int i = 0; i < codecs.length; i++) {
                            if (codecs[i].getName().equalsIgnoreCase(""gzip"")) {
                                response.setEntity(
                                        new GzipDecompressingEntity(response.getEntity()));
                                return;
                            }
                        }
                    }
                }
            });

            HttpHead httpHead = new HttpHead(""http://www.howest.be"");

            // Execute HTTP request
            System.out.println(""executing request "" + httpHead.getURI());
            HttpResponse response = httpclient.execute(httpHead);

            System.out.println(""----------------------------------------"");
            System.out.println(response.getStatusLine());
            System.out.println(response.getLastHeader(""Content-Encoding""));
            System.out.println(response.getLastHeader(""Content-Length""));
            System.out.println(""----------------------------------------"");

            HttpEntity entity = response.getEntity();

            if (entity != null) {
                String content = EntityUtils.toString(entity);
                System.out.println(content);
                System.out.println(""----------------------------------------"");
                System.out.println(""Uncompressed size: "" + content.length());
            }

        } finally {
            // When HttpClient instance is no longer needed,
            // shut down the connection manager to ensure
            // immediate deallocation of all system resources
            httpclient.getConnectionManager().shutdown();
        }
    }

    static class GzipDecompressingEntity extends HttpEntityWrapper {

        public GzipDecompressingEntity(final HttpEntity entity) {
            super(entity);
        }

        @Override
        public InputStream getContent()
                throws IOException, IllegalStateException {

            // the wrapped entity's getContent() decides about repeatability
            InputStream wrappedin = wrappedEntity.getContent();

            return new GZIPInputStream(wrappedin);
        }

        @Override
        public long getContentLength() {
            // length of ungzipped content is not known
            return -1;
        }
    }
}

With kind regards,

Peter"
"HTTPCLIENT-687","BUG","BUG","DefaultRedirectHandler does not access correct HttpParams","In the getLocationURI(HttpResponse, HttpContext) method, the HttpParams for determining REJECT_RELATIVE_REDIRECT and ALLOW_CIRCULAR_REDIRECTS are retrieved with:

HttpParams params = response.getParams();

The response HttpParams do not contain these values, however the request HttpParams do. The correct implementation is:

HttpRequest request = (HttpRequest) context.getAttribute(HttpExecutionContext.HTTP_REQUEST);
HttpParams params = request.getParams();

"
"HTTPCLIENT-514","BUG","BUG","Preemptive auth flags disregarded during ssl tunnel creation","Using a Squid2.4 proxy, the connection is dropped when trying to connect to a 
ssl site. In order for the connection to remain open, preemptive authorization 
is needed for the proxy. The preemptive authorization flags are not propagated 
down to where the ssl tunnel is created in HttpMethodDirectors executeConnect 
method. A new ConnectMethod object is created for the tunnel but the preemptive 
flags set as parameters are not being set on the new ConnectMethod object.

Here is the code that would replicate the problem using a Squid(2.4) proxy :

HttpClient client = new HttpClient();
client.getHostConfiguration().setProxyHost(new ProxyHost(""someproxy"", 3128));
client.getParams().setAuthenticationPreemptive(true);
client.getState().setProxyCredentials(AuthScope.ANY, new 
UsernamePasswordCredentials(""user"", ""password""));
GetMethod httpget = new GetMethod(""https://www.verisign.com/"");
httpget.getProxyAuthState().setPreemptive();
client.executeMethod(httpget);
httpget.releaseConnection();"
"HTTPCLIENT-292","BUG","BUG","NTLM Proxy and basic host authorization","Using a Microsoft proxy with NTLM validation enabled the authorization against a
remote host does not work. This, of course, assuming that the page is correctly
fetched (which currently is not), see the NTLM authentication bug number 24327"
"HTTPCLIENT-381","BACKPORT","BUG","HttpState#PREEMPTIVE_PROPERTY removed.","Our code no longer compiles as HttpState#PREEMPTIVE_PROPERTY has been removed.
Our code compiles with 2.0.1.

See: 
http://jakarta.apache.org/commons/httpclient/apidocs/org/apache/commons/httpclient/HttpState.html#PREEMPTIVE_PROPERTY"
"HTTPCLIENT-80","RFE","BUG","PostMethod - Chunked requests are not supported at the moment.","For Apache Axis, we'd like send a POST request without needing to calculate the
content-length for HTTP 1.1 based servers. Of course if the server-side does not
support 1.1 then a fallback mechanism could calculate the total size under the
covers. 

Also see related request from ""Trevor O'Reilly"" <wtrevor@yahoo.com>:
http://marc.theaimsgroup.com/?l=jakarta-commons-user&m=102719653201792&w=2"
"HTTPCLIENT-853","BUG","BUG","Wrong cookie matching port number reported when using a proxy","Following the example given in https://issues.apache.org/jira/browse/HTTPCLIENT-852 and the route HttpRoute[{}->http://xyz.webfactional.com:7295->http://www.seoconsultants.com]:

one of the new cookies is reported to be added as:

[java] 2009/05/28 19:58:23:398 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: ASPSESSIONIDCSARBQBA][value: MAMPAMKCBDJJFKNAAPKPMDAA][domain: www.seoconsultants.com][path: /][expiry: null] match [www.seoconsultants.com:7295/]

whereas it should be:

[java] 2009/05/28 19:57:46:667 CEST [DEBUG] RequestAddCookies - Cookie [version: 0][name: ASPSESSIONIDCSARBQBA][value: AAMPAMKCMBINHNEHPFEBFADA][domain: www.seoconsultants.com][path: /][expiry: null] match [www.seoconsultants.com:80/]

i.e. the same as without using a proxy. 7295 is the port number used to access the proxy. The target domain www.seoconsultants.com is accessed through the regular HTTP port number 80, thus the cookie matching should also refer to port 80 and not the proxy's port."
"HTTPCLIENT-349","IMPROVEMENT","IMPROVEMENT","Credentials ignored if realm specified in preemptive authentication","When you specifiy credentials for a specific realm using preemptive 
authentication, the credentials are ignored during the first try (error 401 
back).

...
HttpClient client = new HttpClient(manager);
client.getState().setCredentials(""myRealm"",""myHost"",
			new UsernamePasswordCredentials(
				""user"",""password""));
client.getState().setAuthenticationPreemptive(true); 
...

""myRealm"" will be ignored in HttpState's matchCredentials() private method 
because during preemptive authentication, it is called with a null realm:

 private static Credentials matchCredentials(HashMap map, String realm, String 
host) {
        HttpAuthRealm entry = new HttpAuthRealm(host, realm);
	// no possible match here, map only contains the version with the realm
        Credentials creds = (Credentials) map.get(entry);
        if (creds == null && host != null && realm != null) {
            entry = new HttpAuthRealm(host, null);
            creds = (Credentials) map.get(entry);
            if (creds == null) {
                entry = new HttpAuthRealm(null, realm);
                creds = (Credentials) map.get(entry);
            }
        }
        if (creds == null) {
            creds = (Credentials) map.get(DEFAULT_AUTH_REALM);
        }
        return creds;
    } 

This is quite logical since the realm comes from the server and you don't 
contact the server first during preemptive authentication.

But, it should not be possible to set a realm when using preemptive mode, or at 
least it should not be silently ignored.

The current workaround is to set the realm to null in setCredential(), no 
elegant but works.

Regards,

Philippe"
"HTTPCLIENT-916","RFE","IMPROVEMENT","RFE: Make Credentials Serializable","I've been working on upgrading the HtmlUnit library to use HttpClient 4, and I've realized that we could eliminate some hackish internal code if Credentials instances were Serializable. I don't really see a downside, and this would be a huge convenience for us.

The change would involve making the org.apache.http.auth.Credentials interface extend Serializable, and having org.apache.http.auth.BasicUserPrincipal and org.apache.http.auth.NTUserPrincipal implement Serializable (plus serialVersionUIDs where appropriate, I guess)."
"HTTPCLIENT-114","BUILD_SYSTEM","BUG","httpclient build requires jdk 1.4 or jce in classpath","Currently when a 'ant dist'
is performed httpclient is looking for javax.crypt.* which is in jce.jar

The build.xml and build.properties.sample need to be patched
so they allow the jce.jar file to be specified
just like the jsse.jar is specified.

will attach two patch files made from todays cvs"
"HTTPCLIENT-770","CLEANUP","IMPROVEMENT","Code cleanups for Java 1.5 and more.","I can't resist giving code a good cleansing when I start hacking.  Here's some simple things:
- Use character constants instead of string contstants
- Use java 1.5 style for loops
- Use StringBuilder where appropriate
- Fix javadocs
- switch somestring.equals("""") to .length() == 0
-  simplify some boolean expressions
- eliminate redundant initializers
- fix some html nits
- remove final keyword from static methods
"
"HTTPCLIENT-984","TEST","TEST","additional conditional compliance tests for the caching module for Content-Encoding, Content-Location, Date, Expires, Server, Transfer-Encoding, and Vary headers","Patch is forthcoming."
"HTTPCLIENT-764","DOCUMENTATION","IMPROVEMENT","HttpClient javadocs need improving",".. patch coming."
"HTTPCLIENT-673","RFE","IMPROVEMENT","revise max-per-host configuration","Max-per-host settings for ThreadSafeClientConnManagers are currently stored in HttpParams, where the parameter value is a map from HttpRoute (formerly HostConfiguration) to Integer. This has several drawbacks:

1) maintaining a map as a value in HttpParams doesn't match my understanding of how params should be used
2) the maximums based on HttpRoute are really specific to the TSCCM implementation and not a generic parameterization

some of the options are:

a) revise to define a more generic parameterization approach
b) revise into an implementation specific parameterization approach
c) define an implementation (TSCCM) specific configuration interface and a default implementation keeping the map as run-time data

cheers,
  Roland
"
"HTTPCLIENT-450","TEST","BUG","TestExcetions never run","In one of the testcases of HttpClient, TestExcetions, it reads:

    // ------------------------------------------------------------------- Main
    public static void main(String args[]) {
        String[] testCaseName = { TestChallengeParser.class.getName() };
        junit.textui.TestRunner.main(testCaseName);
    }

    // ------------------------------------------------------- TestCase Methods

    public static Test suite() {
        return new TestSuite(TestChallengeParser.class);
    }

Where ""TestChallengeParser"" should be ""TestExcetions""."
"HTTPCLIENT-375","BUG","BUG","Chunked Stream Encoding Problems Fails to throw Exceptions","Using the HttpClient 2.0.1 with Sun's JDK 1.4.1_01 and connecting to a site 
that appareantly has problems generating proper chunked output causes the http 
client to catch and log an exception then return null data. Ideally the http 
client should throw the IOException to the calling class so that it can be 
handled by the programmer. It's not a problem that an exception is being 
generated it is a bug that the exception is being trapped in the somewhere in 
the httpclient code.

2004-08-27 21:19:01,013 main HttpMethodBase [ERROR]: I/O failure reading 
response body
java.io.IOException: chunked stream ended unexpectedly
        at 
org.apache.commons.httpclient.ChunkedInputStream.getChunkSizeFromInputStream
(ChunkedInputStream.java:234)
        at org.apache.commons.httpclient.ChunkedInputStream.nextChunk
(ChunkedInputStream.java:205)
        at org.apache.commons.httpclient.ChunkedInputStream.read
(ChunkedInputStream.java:160)
        at java.io.FilterInputStream.read(FilterInputStream.java:111)
        at org.apache.commons.httpclient.AutoCloseInputStream.read
(AutoCloseInputStream.java:110)
        at java.io.FilterInputStream.read(FilterInputStream.java:90)
        at org.apache.commons.httpclient.AutoCloseInputStream.read
(AutoCloseInputStream.java:129)
        at org.apache.commons.httpclient.HttpMethodBase.getResponseBody
(HttpMethodBase.java:685)
        at com.algorim.ei.cets.EmailPreProcessor.processMessage
(EmailPreProcessor.java:565)
        at com.algorim.ei.cets.EmailUpdate.run(EmailUpdate.java:332)
        at com.algorim.ei.cets.EmailUpdate.main(EmailUpdate.java:89)

Request and response that are causing the error:
GET /aeq.aspx?k=32226&k=sb1313@xcorp5.com HTTP/1.1
User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0; .NET CLR 
1.1.4322)
Host: 38.117.227.56

HTTP/1.1 200 OK
Date: Fri, 27 Aug 2004 20:55:27 GMT
Server: Microsoft-IIS/6.0
X-Powered-By: ASP.NET
X-AspNet-Version: 1.1.4322
Transfer-Encoding: chunked
Cache-Control: private
Content-Type: text/html; charset=utf-8

179
<html><head><META HTTP-EQUIV=Refresh CONTENT=""1; 
URL=http://www.datingresults.com/default.asp?
p=7090&PRM=38664""</head><body><script>win2=win
dow.open('http://m.qmct.com/images/d.html?
a=1', 'newwin','toolbar=0,width=730,height=500');if (win2 != null) win2.blur
();window.focus();wind
ow.location = 'http://www.datingresults.com/default.asp?
p=7090&PRM=38664';</script></body></html>"
"HTTPCLIENT-760","BUG","BUG","Abort Before Execute & Various Other Times Fails","With svn commit #639506, a few more scenarios become testable & can be fixed.  These are: aborting before HttpClient.execute is called, aborting between setting the connection request for aborting and setting the connection release trigger, and aborting after a redirected route uses a new connection request.  As of r639506, those three scenarios fail to abort correctly."
"HTTPCLIENT-1130","BUG","BUG","New LaxRedirectStrategy class should probably call the super method first.","LaxRedirectStrategy extends the defaulRedirect class but does not call the super method as one would expect.

Just adding a patch to make sure it gets called."
"HTTPCLIENT-573","IMPROVEMENT","BUG","Disallow the use of SecureProtocolSocketFactory with ProxyClient","ProxyClient cannot work correctly if SecureProtocolSocketFactory socket factory
is being used to establish connection with the target server"
"HTTPCLIENT-297","BUG","BUG","DigestScheme.authenticate returns invalid authorization string when algorithm is null","DigestScheme.authenticate returns invalid authorization string when algorithm 
is null. 
I traced the bug and found the following from the method call:
authenticate(Credentials credentials, String method, String uri) calls
authenticate(UsernamePasswordCredentials credentials,
            Map params) calls
createDigest(String uname, String pwd,
            Map params)
  and properly defaults algorithm to MD5 if null
but the final call to createDigestHeader(String uname, Map params,
            String digest) does not default algorithm to MD5 if null"
"HTTPCLIENT-958","SPEC","BUG","client cache currently allows incomplete responses to be passed on to the client","Per the HTTP/1.1 spec:

""A cache that receives an incomplete response (for example, with fewer bytes of data than specified in a Content-Length header) MAY store the response. However, the cache MUST treat this as a partial response. Partial responses MAY be combined as described in section 13.5.4; the result might be a full response or might still be partial. A cache MUST NOT return a partial response to a client without explicitly marking it as such, using the 206 (Partial Content) status code. A cache MUST NOT return a partial response using a status code of 200 (OK).""

(http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.8)

For example, if a 200 response shows up with 128 bytes in the body but a Content-Length header of 256, the cache MUST NOT pass this through unchanged.
"
"HTTPCLIENT-86","RFE","IMPROVEMENT","need to add a default constructor for Cookie","The Cookie class doesn't have a default (no argument) constructor. This is 
causing problem for some framework which supports marshalling and unmarshalling 
of data types. e.g. a SOAP implementation may need to do this to transfer it 
between the SOAP server and SOAP client. It would be nice to add a default 
constructor, as it won't break anything, follows JavaBean convention, and 
potentially save user some trouble in the future."
"HTTPCLIENT-346","BUG","BUG","Cookies with names containing blanks or starting with $ should be rejected by RFC2109 spec only","Reported by John Patterson:

> The Cookie class does not like names with spaces in them.  It throws an
> IllegalArgumentException.  Unfortunately the server that my app interacts
> with uses a space in the cookie name.  Both IE and Mozilla don't mind."
"HTTPCLIENT-325","BUG","BUG","Deadlock with MultiThreadedHttpConnectionManager","I'm getting a dealock with the MultiThreadedHttpConnectionManager. Usually, it
works fine, but when a web page is redirected, it blocks. 

Ludovic.

[ERROR] Redirect to http://sourceforge.net/
Full thread dump Java HotSpot(TM) Client VM (1.4.2_03-b02 mixed mode):

""MultiThreadedHttpConnectionManager cleanup"" daemon prio=5 tid=0x02d566f0
nid=0xe14 in Object.wait() [2e9f000..2e9fd8c]
        at java.lang.Object.wait(Native Method)
        - waiting on <0x10513be8> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(Unknown Source)
        - locked <0x10513be8> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(Unknown Source)
        at
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ReferenceQueueThread.run(MultiThreadedHttpConnectionManager.java:805)

""Signal Dispatcher"" daemon prio=10 tid=0x0003da00 nid=0xd44 waiting on condition
[0..0]

""Finalizer"" daemon prio=9 tid=0x009bca30 nid=0xce8 in Object.wait()
[2b5f000..2b5fd8c]
        at java.lang.Object.wait(Native Method)
        - waiting on <0x10504b80> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(Unknown Source)
        - locked <0x10504b80> (a java.lang.ref.ReferenceQueue$Lock)
        at java.lang.ref.ReferenceQueue.remove(Unknown Source)
        at java.lang.ref.Finalizer$FinalizerThread.run(Unknown Source)

""Reference Handler"" daemon prio=10 tid=0x009bb600 nid=0xfa4 in Object.wait()
[2b1f000..2b1fd8c]
        at java.lang.Object.wait(Native Method)
        - waiting on <0x10504be8> (a java.lang.ref.Reference$Lock)
        at java.lang.Object.wait(Unknown Source)
        at java.lang.ref.Reference$ReferenceHandler.run(Unknown Source)
        - locked <0x10504be8> (a java.lang.ref.Reference$Lock)

""main"" prio=5 tid=0x00035e28 nid=0xf68 in Object.wait() [7f000..7fc3c]
        at java.lang.Object.wait(Native Method)
        - waiting on <0x105170e8> (a
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ConnectionPool)
        at
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager.doGetConnection(MultiThreadedHttpConnectionManager.java:388)
        - locked <0x105170e8> (a
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$ConnectionPool)
        at
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager.getConnection(MultiThreadedHttpConnectionManager.java:296)
        at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:645)
        at
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:529)
        at net.sourceforge.cvsgrab.WebBrowser.executeMethod(WebBrowser.java:201)
        at net.sourceforge.cvsgrab.WebBrowser.getResponse(WebBrowser.java:257)
        at net.sourceforge.cvsgrab.WebBrowser.getDocument(WebBrowser.java:295)
        at
net.sourceforge.cvsgrab.CvsWebInterface.loadDocument(CvsWebInterface.java:111)
        at
net.sourceforge.cvsgrab.CvsWebInterface.getDocumentForDetect(CvsWebInterface.java:216)
        at
net.sourceforge.cvsgrab.CvsWebInterface.findInterface(CvsWebInterface.java:86)
        at net.sourceforge.cvsgrab.CVSGrab.detectWebInterface(CVSGrab.java:688)
        at net.sourceforge.cvsgrab.CVSGrab.grabCVSRepository(CVSGrab.java:616)
        at net.sourceforge.cvsgrab.CVSGrab.run(CVSGrab.java:317)
        at net.sourceforge.cvsgrab.CVSGrab.main(CVSGrab.java:206)

""VM Thread"" prio=5 tid=0x009f76d0 nid=0x550 runnable

""VM Periodic Task Thread"" prio=10 tid=0x009f8208 nid=0x560 waiting on condition
""Suspend Checker Thread"" prio=10 tid=0x009bed88 nid=0xe84 runnable"
"HTTPCLIENT-441","BUG","BUG","Cookie.java hashCode method violates contract","org.apache.commons.httpclient.Cookie hashCode() does not meet object.hashCode
() contract.  Cookie.hashCode() returns different values even though data used 
in equals() comparison is the same.

Contract:**Whenever it is invoked on the same object more than once during an 
execution of a Java application, the hashCode method must consistently return 
the same integer, provided no information used in equals comparisons on the 
object is modified.**

Breaks use of cookie within collections such as when using contains().

Traced problem back to parent class NameValuePair.  Cookie.hashCode() calls 
NameValuePair.hashCode() which relies on name/value hashes.  Cookie does not 
rely on value to determine equality."
"HTTPCLIENT-405","BUG","BUG","HostConfiguration.setHost(String) causes NullPointerException","Calling setHost(String) on a HostConfiguration object causes a null pointer
exception.

As far as I can tell, this is due to it incorrectly calling the deprecated
setHost(String, String, int, Protocol) method, rather than setHost(String, int,
Protocol)

So:

public synchronized void setHost(final String host) {
  Protocol defaultProtocol = Protocol.getProtocol(""http""); 
  setHost(host, null, defaultProtocol.getDefaultPort(), defaultProtocol);
}

should become :

public synchronized void setHost(final String host) {
    Protocol defaultProtocol = Protocol.getProtocol(""http""); 
    setHost(host, defaultProtocol.getDefaultPort(), defaultProtocol);
}"
"HTTPCLIENT-15","BUG","BUG","redirect not handled correctly if location header doesn't have a protocol","Http redirect is not handled correctly if the location header doesn't have a 
protocol, e.g.:

Location: web/tbghome.nsf/pages/index

a java.net.MalformedURLException is throw in this case. The correct behavior is 
to inherit the protocol from current URL.

The relevant code is in HttpMethodBase.execute()"
"HTTPCLIENT-235","IMPROVEMENT","BUG","HttpMethodBase logger uses wrong class.","I just noticed a minor error in HttpMethodBase: it initializes its Log object
with HttpMethod.class instead of HttpMethodBase.class.  No big deal, but it
probably ought to be fixed at some point.  I'll attach the patch."
"HTTPCLIENT-936","BUG","BUG","NullPointerException in NegotiateScheme","- server is configured to allow client to authenticate with kerberos with principal foobar
- client, using httpclient with a registered authscheme SPNEGO set as a NegotiateSchemeFactory

- when the client authenticate with the (correct) principal foobar, it works !
- when the client authenticate with the (wrong) principal fooba, it fails with a NPE below.


Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.commons.codec.binary.Base64.encodeBase64(Base64.java:233)
	at org.apache.commons.codec.binary.Base64.encode(Base64.java:521)
	at org.apache.http.impl.auth.NegotiateScheme.authenticate(NegotiateScheme.java:240)
	at org.apache.http.client.protocol.RequestTargetAuthentication.process(RequestTargetAuthentication.java:99)
	at org.apache.http.protocol.ImmutableHttpProcessor.process(ImmutableHttpProcessor.java:108)
	at org.apache.http.protocol.HttpRequestExecutor.preProcess(HttpRequestExecutor.java:167)
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:460)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:689)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:624)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:602)
"
"HTTPCLIENT-1162","RFE","IMPROVEMENT","Header adding in org.apache.http.client.protocol.RequestAcceptEncoding should be conditional","org.apache.http.client.protocol.RequestAcceptEncoding adds a header in any case. Any chance to do it conditional (like in RequestClientConnControl)? The code would be something like
if (!request.containsHeader(""Accept-Encoding"")) {
    request.addHeader(""Accept-Encoding"", ""gzip,deflate"");
}

In our app this header may be added before request intercepting, so would be great if this fact is checked.
"
"HTTPCLIENT-584","TASK","TASK","Remove lib directory from SVN trunk","build.xml expects to find junit.jar in the lib directory for building and running tests.

The jar is not included in SVN, but nor is the jar ignored, so when it is downloaded it shows up as an unversioned file.

The file should be included in or excluded from SVN.

==

Note: In JMeter we use a lib/opt directory.
This is present in SVN - but all contents are ignored.

This can be used for extra jars that cannot be or are not included in SVN.

Could use the same approach for junit.jar..."
"HTTPCLIENT-8","BUG","BUG","LogSource.setLevel incorrectly uses entrySet","When I call LogSource.setLevel, I get the following exception:

java.lang.ClassCastException: java.util.HashMap$Entry
	at org.apache.commons.httpclient.log.LogSource.setLevel
(LogSource.java:158)

The calling code is :

    LogSource.setLevel (Log.OFF);

The error (I believe) is that you should get the value set from the map, not 
the entry set (in LogSource):

    static public void setLevel(int level) {
        Iterator it = _logs.entrySet().iterator(); <-- should be _logs.values()
        while(it.hasNext()) {
            Log log = (Log)(it.next());
            log.setLevel(level);
        }
    }"
"HTTPCLIENT-523","RFE","IMPROVEMENT","SPNEGO authentication scheme","Consider integrating the SPNEGO auth scheme from Commons HttpClient contrib package into HttpClient 4.0"
"HTTPCLIENT-995","BUG","BUG","cache returns cached responses even if validators not consistent with all conditional headers","This is a MUST-level requirement in the RFC, where if both ETags and Last-Modified dates are used as validators in a conditional request, a cache cannot return a cached response unless it is consistent with all the conditional headers in the request. There is a unit test for this already, but it is incorrect (it uses 'If-Unmodified-Since' instead of 'If-Modified-Since' in the test case).

"
"HTTPCLIENT-490","BUG","BUG","Can not set the ""Proxy-connection"" header","When using a proxy the HttpClient refuses to set the ""Proxy-connection"" header
to the value ""close"". The value will be converted to ""keep-alive"" when the final
request is sent to network.

The following code snippet can be used to replicate the defect. Method is GET:
...
method.removeRequestHeader(""Proxy-Connection"");
logger.debug(""Proxy-Connection header removed."");
method.addRequestHeader(""Proxy-Connection"", ""close"");
logger.debug(""Proxy-Connection header set to: "" +
method.getRequestHeader(""Proxy-Connection"") );
try {
  	int statusCode = httpclient.executeMethod( method );
...

Now if you look at the wire log, you will notice that the actual value will be
""keep-alive""."
"HTTPCLIENT-146","BUILD_SYSTEM","BUG","Error from maven when generating the task list","This message scrolls by when runing the site:generate goal.

tasklist:generate:
Non-fatal error while parsing file:
/home/jsdever/cvs-commit/jakarta-commons/httpclient/src/java/org/apache/commons/httpclient/HeaderElement.java
Non-fatal error while parsing file:
/home/jsdever/cvs-commit/jakarta-commons/httpclient/src/java/org/apache/commons/httpclient/URI.java"
"HTTPCLIENT-666","RFE","IMPROVEMENT","Replace HttpState with CredentialsProvier and CookieStore interfaces","Replace HttpState, which is a concrete class, with CredentialsProvier and CookieStore interfaces. Provide default impls of those interfaces."
"HTTPCLIENT-651","DOCUMENTATION","IMPROVEMENT","Inconsistent, order dependant behaviour in HttpMethodBase.getResponse*","`getReponseBodyAsString` is storing the body  and may therefore provide a valid result if the code is requesting the body as stream afterwards. If you switch the order and first call getResponseBodyAsStream and afterwards try to `getReponseBodyAsString`, the result will be `null`.

I wrote a unittest which hopefully describes the IMHO confusing behaviour:

    public void testHttpClientBodyVsStream() throws HttpException, IOException {
        final HttpClient httpClient = new HttpClient();
        final GetMethod getMethod = new GetMethod(""http://www.heise.de/"");
        final String bodyFromStream;
        final String body;
        try {
            httpClient.executeMethod(getMethod);
            body = getMethod.getResponseBodyAsString();
            bodyFromStream = IOUtils.toString(getMethod
                    .getResponseBodyAsStream());
        } finally {
            getMethod.releaseConnection();
        }
        assertEquals(body, bodyFromStream);
    }
    
    public void testHttpClientStreamVsBody() throws HttpException, IOException {
        final HttpClient httpClient = new HttpClient();
        final GetMethod getMethod = new GetMethod(""http://www.heise.de/"");
        final String bodyFromStream;
        final String body;
        try {
            httpClient.executeMethod(getMethod);
            bodyFromStream = IOUtils.toString(getMethod
                    .getResponseBodyAsStream());
            body = getMethod.getResponseBodyAsString();
        } finally {
            getMethod.releaseConnection();
        }
        // ** This will fail **
        assertEquals(body, bodyFromStream);
    }

Searching http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/java/org/apache/commons/httpclient/HttpMethodBase.java I understand the outcome, but this is confusing.

I would expect the body data to be gone after calling one of the getResponse*-Methods and calling them again not to return null but even to throw an IllegalStateException. I would not store the body at all in the method.
"
"HTTPCLIENT-953","BUG","BUG","ConnPoolByRoute driving RouteSpecificPool to IllegalState","Hi all,

I encountered an issue on ConnPoolByRoute / RouteSpecificPool on HTTPClient 4.0.1, akin to HTTPCLIENT-747 (it also leads to a java.lang.IllegalStateException: No entry created for this pool. HttpRoute[{}XXX] ), but it is not a concurrency issue (no race condition, just a logic error if I understood it correctly).

From my understanding, the error lies in ConnPoolByRoute#getEntryBlocking
Quoting from the code (line 309-314) :
RouteSpecificPool rospl = getRoutePool(route, true);
... 
} else if (hasCapacity && !freeConnections.isEmpty()) {

deleteLeastUsedEntry();
entry = createEntry(rospl, operator);

} else { ...

The short version of the issue is : under certain circumstances, #deleteLeastUsedEntry can remove rospl from the map of known RootSpecificPool. But as this code still holds on to the rospl instance, it will modify its state in a way the pool will never recover from later, not having any other way to access this instance when the connection gets released.

A Step by Step guide to what's going wrong.
0) You have to be in a condition that leads to the execution of said code extract (i.e. no free entry on the current route - but the route already is registered to the global pool -, current Route has capacity, max connections reached for the global pool, but there are free connections to destroy).
2) We arrive in deleteLeastUsedEntry(). We get the last entry from a queue. It can be that this entry is bound to the same (hashCode() wise) Route that the one we are getting a connection to (i.e. rospl instance held in the #getEntryBlocking context)
3) this entry can be the last of its pool, thus at this point, rospl.isUnused() == true
4) As a consequence, deleteEntry() will remove rospl from the routeToPool map
5) Back in the getEntryBlocking method, we do entry = createEntry(rospl, operator), which will do createdEntry() on the ""locally-scoped"" rospl instance that has just been removed from routeToPool 
6) When the connexion from this new entry is released at some point in the future, the rospl instance that got the createdEntry() does not exist anymore, and it is a new one that gets the freeEntry() call
7) App breaks : this newly created RouteSpecificPool throws IllegalStateException.

Step 0, though, is a rare condition that I only reached during stress tests, and on a SSL client-auth server. This is so because this is the only condition that I know of in HTTPClient, where there is a keep-alive connection in the RouteSpecificPool that can not be reused (when the State is set to the X500 principals of the client cert in the pool, but not in the request).

Possible fix (from what I understand) :
The rospl instance variable in the context of getEntryBlocking() should be protected against the consequences of #deleteLeastUsedEntry().
Not being confortable with all issues at hand, nor with the code base, the simplest thing I can think of would be to preemptively reset the rospl variable after deleteLeastUsedEntry(), thus writing the previous code extract as :

} else if (hasCapacity && !freeConnections.isEmpty()) {

deleteLeastUsedEntry();
// delete may have made deprecated the RouteSpecificPool instance
rospl = getRoutePool(route, true);
entry = createEntry(rospl, operator);

} else { ...


I have a test case that I will attach to this issue ASAP.
It is a simple example that triggers the above conditions with 3 HttpGet calls, in a serial fashion. As stated previsouly, these calls need nothing particular, except that one of these calls must go to a HTTPS server with client-side certificate authentication (I guess NTLM would be OK, anything that will place a non null state along with the route in BasicEntryPool).

I hope code is self-explainatory. I get 100% failure in my setup. Just configure your 2 URLS, configure classpath, set your keystores system properties, and launch.

Workaround :
Best workaround I found is : do not get to step 0.
The most robust way I found to do that (i.e. a way that does not involve things like setting max pool size to a gigantic number that can never be reached, ...) is to actively set the ClientContext.USER_TOKEN attribute in an exec context while submitting the request to the client.
Step 0 triggers when there is an idle connection that waits, and when this idle connection can not be reused, which can only happen if the request's ""USER_TOKEN"" does not match the BasicPoolEntry#getState(). As, in the SSL case, the state is the SSL Cert's X500PrincipalName, and I know it in advance, it's easy to set up front.

By the way, this taught me that I never could benefit from connection reuse strategies in this SSL case, as connections would always get into the pool with a USER_TOKEN that my requests never had. Don't know if it's mentionned somewhere in the documentation, but this is a noteworthy fact to me.

Please feel free to comment / correct any mistakes."
"HTTPCLIENT-1104","RFE","IMPROVEMENT","Add way to check for release of connections back into pool","As the documentation emphasizes, its important to clean up HttpEntities after use, so they don't tie up the default very small number of connections in the pool.

However, nothing is provided to HttpClient users with the default classes that allows them to unit test their code to help verify that they are in fact properly releasing the connections under all circumstances. One way this could be done is for the API to expose the number of current leased (taken) connections in the pool, which would be connManager.pool.leasedConnections.size() if not for the necessary fields being protected. If this statistic were published through the API, user unit tests could check that it is zero when they finish.

A workaround is for the user to subclass both the connection manager and ConnPoolByRoute and add getter methods. But its kind of a clunky solution, and I think the API should be written to encourage its users to perform this check."
"HTTPCLIENT-1129","BUG","","Redirect and Kerberos authentication in conflict","We are using the HttpClient to connect to a Website that uses Kerberos-Authentication.

Beware this trigger word: Kerberos! I think this is *not* the problem, but please read on.

Here is the sequence of events:

Client: GET /
Server: Unauthorized.
Client: GET / and includes authentication.
Server: 302 to /something on the same host (this shows that in principle authentication works)
Client: GET /something,  does not include authentication
Server: Unauthorized

Client quits with 401-Unauthorized.

I would have expected one of the following instead:

1) Client immediately sends authorization information with the redirected GET /something
2) Client re-requests the /something with authorization after 401-Unauthorized.

We could get around the problem by setting the ConnectionReuseStrategy to a constant false.

It would be great if someone could tell me if HttpClient works as expected or whether there is a bug or misconfiguration lurking.

Thanks,
Harald.
"
"HTTPCLIENT-606","BUG","BUG","HttpMethodDirector fails when redirecting to a encoded URL location","When HttpMethodDirector handles the case of redirecting the incoming connection to the location specified in the header of the http caller method, if this location has any ""special"" charset encoding (extended charsets like ISO 8859-1,etc.) the redirection fails this way:

dd-MMM-YYYY hh:mm:ss org.apache.commons.httpclient.HttpMethodDirector processRedirectResponse
WARNING: Redirected location 'http://www.anyCharsetEncodedUrl.ko' is malformed


You can test it using this class:


public class SimpleHttpTestNotWorking {

	public static int urlStatus(String pUrl) throws org.apache.commons.httpclient.HttpException,java.io.IOException{
		org.apache.commons.httpclient.HttpClient client = new org.apache.commons.httpclient.HttpClient();
		org.apache.commons.httpclient.HttpMethod method = new org.apache.commons.httpclient.methods.GetMethod(pUrl);
		return client.executeMethod(method);
	}
		
	public static void main(String[] args) {
		try{
			String url = ""http://www.dipualba.es/municipios/F%E9rez""; //known problematic URL
			System.out.println(""Return code for [""+url+""]: ""+SimpleHttpTestWorking.urlStatus(url));
		}catch(Exception e){
			e.printStackTrace();
		}
	}
}


What I've done to solve it for my particular case has been:


1) In the requester side, I've modified the calling:


public class SimpleHttpTestWorking {

	public static int urlStatus(String pUrl) throws org.apache.commons.httpclient.HttpException,java.io.IOException{
		org.apache.commons.httpclient.HttpClient client = new org.apache.commons.httpclient.HttpClient();
		org.apache.commons.httpclient.HttpMethod method;
	    String encoding = (String)client.getParams().getParameter(""http.protocol.content-charset"");
	    client.getParams().setParameter(""http.protocol.element-charset"", encoding);
	    try{
	    	method = new org.apache.commons.httpclient.methods.GetMethod(pUrl);
	    }catch(IllegalArgumentException iae){
		    try{
		    	org.apache.commons.httpclient.URI uri = new org.apache.commons.httpclient.URI(pUrl,true);
		    	method = new org.apache.commons.httpclient.methods.GetMethod(uri.getURI());
		    }catch(org.apache.commons.httpclient.URIException ue){
		    	org.apache.commons.httpclient.URI uri = new org.apache.commons.httpclient.URI(pUrl,false,encoding);
			    method = new org.apache.commons.httpclient.methods.GetMethod(uri.getEscapedURI());
		    }		    	
	    }		
		return client.executeMethod(method);
	}
			
	public static void main(String[] args) {
		try{
			String url = ""http://www.dipualba.es/municipios/Frez""; //the same problematic URL
			System.out.println(""Return code for [""+url+""]: ""+SimpleHttpTestWorking.urlStatus(url));
		}catch(Exception e){
			e.printStackTrace();
		}
	}
}


2) In org.apache.commons.httpclient.HttpMethodDirector.processRedirectResponse(HttpMethod method) , I've replaced


...
redirectUri = new URI(location, true);
...


for the following code:


...
/*
 * [2006-11-14] 
 * Handles redirections to encoded URI locations 
 * (only if URI and Connection encoding charset has been properly setted)
 * */ 
try{
	redirectUri = new URI(location, true);
}catch(URIException ue){
	Object encoding = this.conn.getParams().getParameter(""http.protocol.element-charset"");
	if(encoding != null){
		redirectUri = new URI(location, false, (String)encoding);
	}else{
		throw ue;
	}
}
...



Hope it helps!"
"HTTPCLIENT-823","RFE","IMPROVEMENT","Make it possible to adjust MaxTotalConnections parameter dynamicaly","Make it possible to adjust MaxTotalConnections parameter at run time. Document behaviour of MaxTotalConnections and MaxConnectionsPerRoute behaviour (latter cannot be changed for allocated pools)

Oleg"
"HTTPCLIENT-827","TEST","IMPROVEMENT","ServerTestBase, LocalTestServer should be redistributed","ServerTestBase and LocalTestServer should be redistributed, so that we can all benefit from these wonderful classes without having to copy / paste them.

For instance, I am currently creating a REST client for some web service, and I would totally benefit from your classes to check borderline cases (404, 500, etc..)

the simplest possible way to achieve this would be to add a maven-jar-plugin entry to the POM that executes the test-jar goal.

regards,
Sami Dalouche

"
"HTTPCLIENT-643","RFE","IMPROVEMENT","Provide fail-over for multi-home remote servers (if one server in a farm goes down)","The HTTP Client does not provide automatic fail-over for multi-home remote servers (web-farm) if one server in a farm goes down"
"HTTPCLIENT-161","BUG","BUG","MultipartPostMethod Holding File Stream Open?","From: ""Daniel Walsh"" <daniel.walsh13@verizon.net>
Date: Tue Feb 25, 2003  8:05:49 PM US/Eastern
To: ""Commons HttpClient Project"" <commons-httpclient-dev@jakarta.apache.org>
Subject: MultipartPostMethod Holding File Stream Open?
Reply-To: ""Commons HttpClient Project"" <commons-httpclient-dev@jakarta.apache.org>

I'm using a MultipartPostMethod to upload a file to a servlet:

File file = new File(strUrl);

HttpClient client = new HttpClient();
HostConfiguration hostConfig = new HostConfiguration();
MultipartPostMethod mpPost = new MultipartPostMethod();

 hostConfig.setHost(someURL.getHost(), someURL.getPort(), someURL.getProtocol());
client.setConnectionTimeout(30000);
client.setHostConfiguration(hostConfig);

mpPost.addParameter(""someName"", ""someValue"");
mpPost.addParameter(file.getName(), file);

mpPost.setPath(strPath);
client.executeMethod(mpPost);

String confirmUpload = tpPost.getResponseBodyAsString();
mpPost.releaseConnection();

file.delete();  // this is being blocked.

After the upload, I would like to delete the file off of my disk.  Using other
methods of uploading the file (in particular a PutMethod), I was able to then
delete the file after the upload.  Now that I am using the MultipartPostMethod
obj for the upload, I am unable to delete the file (the return value is false,
and there is no SecurityException being thrown - no SecurityManager even set as
of this point either).

So, I guess my question is whether there is a call to the MultipartPostMethod
obj that I'm overlooking that would release it's connection (I'm sure that it is
opening an InputStream of some sort to read the file contents, in order to form
the HTTP message) to the file - so that I can then have unimpeded access to it
for other operations?"
"HTTPCLIENT-690","RFE","IMPROVEMENT","Provide access to SSLSession in ManagedClientConnection","Provide access to the wrappedConnection in org.apache.http.impl.conn.AbstractClientConnAdapter via some interface in order to access the socket from within an HttpProcessor. Currently the org.apache.http.conn.OperatedClientConnection has a getSocket() method, but the connection implementation returned by

  context.getAttribute(ExecutionContext.HTTP_CONNECTION) 

(org.apache.http.impl.conn.tsccm.BasicPooledConnAdapter) does not provide access to the wrappedConnection."
"HTTPCLIENT-334","RFE","IMPROVEMENT","Per socket SOCKS proxies","HttpClient requires a way of allowing a SOCKS proxy to be used on some
connections without requiring that all created Sockets go through the proxy."
"HTTPCLIENT-986","BUG","BUG","cache module does not completely handle upstream Warning headers correctly","There are a couple of MUST requirements from the RFC for Warning headers that aren't correctly handled by the current implementation:

http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.46

1. ""However, if a cache successfully validates a cache entry, it SHOULD remove any Warning headers previously attached to that entry except as specified for specific Warning codes. It MUST then add any Warning headers received in the validating response.""

2. ""If an implementation receives a message with a warning-value that includes a warn-date, and that warn-date is different from the Date value in the response, then that warning-value MUST be deleted from the message before storing, forwarding, or using it. (This prevents bad consequences of naive caching of Warning header fields.) If all of the warning-values are deleted for this reason, the Warning header MUST be deleted as well."" "
"HTTPCLIENT-154","RFE","IMPROVEMENT","Allow redirects between hosts and ports","Redirects to different hosts, ports and protocols are currently prevented. 
Historicly, HttpMethodBase.checkValidRedirects() is used to prevent these types
of redirects due how state information was being managed in the connection.  

Much has changed since then.  We should relax the check and allow for redirects
 between hosts and ports. 

Redirects across protocols should not be considered at this time as there are
other issues related to security that is best left up to the user of HttpClient."
"HTTPCLIENT-932","BUG","BUG","SSLSocketFactory.connectSocket(...) possible NPE","    public Socket connectSocket(
            final Socket sock,
            final InetSocketAddress remoteAddress,
            final InetSocketAddress localAddress,
            final HttpParams params) throws IOException, UnknownHostException, ConnectTimeoutException {
...

        SSLSocket sslsock = (SSLSocket) (sock != null ? sock : createSocket()); // ==> sock may be null
        if (localAddress != null) {
            sock.setReuseAddress(HttpConnectionParams.getSoReuseaddr(params)); // ==> NPE if sock is null
            sslsock.bind(localAddress);
        }

Should sock.setReuseAddress be sslsock.setReuseAddress?
"
"HTTPCLIENT-274","IMPROVEMENT","IMPROVEMENT","default behaviour of useExpectHeader","I suggest to set the ExpectContinueMethod.setUseExpectHeader per default to
false or to arrange that per default it is not used. We lost an awfull lot of
time in a project in which we used MultipartPostMethod via a proxy. Everthing
worked fine in dev, however as soon as we started to use the proxy in production
or testing environment we had severe problems. We lost several manday looking
for the problem, including sniffing and logging op the proxy. It ended up to be
the useexpectheader which was true per default. Putting in on false ended our
problems...

In my opinion it is a bit hard to make something default behaviour if the
javadoc warns : <snip>
handshake should be used with caution, as it may cause problems with HTTP
servers and proxies that do not support HTTP/1.1 protocol.
</snip>

regards
dirkp"
"HTTPCLIENT-882","BUG","BUG","Auth state is not correctly maintained if a successful NTLM authentication results in a redirect","HttpClient fails to update the auth state correctly if a successful NTLM authentication results in a redirect response. Reported by Valentin Popov <valentin.po at gmail.com>"
"HTTPCLIENT-360","IMPROVEMENT","BUG","questionable default value for BufferedOutputStream size in HttpConnection","From the dev list

--

Hi Eric

Thanks for bringing this up. HttpClient 3.0 allows for parameterization
of SO_SNDBUF and SO_RCVBUF settings. For HttpClient 2.0 (as well as for
3.0 when falling back onto the system defaults), however, it would make
sense to set a cap on the size of the send and receive buffers.

Feel free to open a ticket for this issue with Bugzilla

Oleg


On Fri, 2004-07-02 at 18:39, Eric Bloch wrote:

>> Hi httpclient folks,
>> 
>> I've been looking at 2.0 source code and the default value for the 
>> BufferedOutputStream that is used in an HttpConnectionn is coming from 
>> socket.getSendBufferSize().  My hunch, is that, in general, this is 
>> bigger than you'd want.
>> 
>> Most HTTP ""sends"" are less than 1KByte ('cept for big POSTs).
>> The default value I get for socket.getSendBufferSize for this is 8192.
>> I would think a better default for this buffer would be 1K, no?
>> 
>> Also, fyi, if someone happens to dork the system send buffer size hi 
>> (say MB) and you are using the MultiThreadedConnectionManager in 2.0 
>> (dunno about 3.0), you will use up a lot of memory for each connection 
>> since the pool doesn't let idle connections (or their buffers) be gced. 
>>   I just got bit bad by that.
>> 
>> -Eric
>> 
>"
"HTTPCLIENT-313","DOCUMENTATION","BUG","Improper EOL for text files on Windows","version 2.0-rc3. Improper EOL for text files on Windows for README.txt and
LICENSE.txt, docs/*.txt. The files display as one loooong line in Notepad."
"HTTPCLIENT-743","IMPROVEMENT","BUG","Duplicate log of HTTP header","The HTTP header line:

""HTTP/1.1 200 OK[\r][\n]"" 

is duplicated in the wire logs. Seems to be because the line is logged at:

HttpParser [line: 131] - readLine(InputStream, String)

and at:

HttpMethodBase [line: 1980] - readStatusLine(HttpState, HttpConnection)

It looks like the latter log should be removed?"
"HTTPCLIENT-425","BUG","BUG","URI.getHost() generates IllegalArgumentException","Hi guys,

I don't know if I'm doing something wrong or not but the following code:

   URI uri = new URI(""mailto:eay@cryptsoft.com"", true);
   System.out.println(uri.getHost());

generates the following exception:

java.lang.IllegalArgumentException: Component array of chars may not be null
	at org.apache.commons.httpclient.URI.decode(URI.java:1722)
	at org.apache.commons.httpclient.URI.getHost(URI.java:2780)

Could you help?

Also, I'm sorry I put the report under version ""3.0 Final"" but I couldn't find 
an entry for ""3.0-RC1"" (which I'm using at the moment).

Thanks a lot!

Bisser"
"HTTPCLIENT-856","BUG","BUG","Proxy NTLM Authentication  Redirecting to different address fails saying Proxy Auth Required.","The issue has been discussed in,
http://www.nabble.com/redirect-fails-when-NTLM-authentication-is-used-for-proxy-tt23867531.html

This was found in http client 3.1 release,  where NTLM proxy authentication is must and the server ask the redirect to a new url, in this case, when redirecting, the earlier proxy auth status is not cleared, so, it does not do proxy authentication for the new URL and hence fails.

Target Host Authenticaiton NTLM authentication - redirect also had problem and fixed as said,
http://issues.apache.org/jira/browse/HTTPCLIENT-211
Proxy Authentication - redirect has to be fixed, 

The wire logs for the release https://repository.apache.org/content/repositories/snapshots/org/apache/httpcomponents/httpclient/4.0-beta3-SNAPSHOT/
is given below,

[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Negotiate[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Kerberos[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Basic realm=""lab1.""[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 4107  [EOL]""
[DEBUG] wire - << ""[EOL]""
[DEBUG] wire - << ""<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.0 Transitional//EN"">[\r][\n]""
[DEBUG] wire - << ""<HTML><HEAD><TITLE>Error Message</TITLE>[\r][\n]""
[DEBUG] wire - << ""<META http-equiv=Content-Type content=""text/html; charset=UTF-8"">[\r][\n]""
[DEBUG] wire - << ""<STYLE id=L_default_1>A {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #005a80; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""A:hover {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #0d3372; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-SIZE: 8pt; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD.titleBorder {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 0px solid; COLOR: #955319; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD.titleBorder_x {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 0px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 1px solid; COLOR: #978c79; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".TitleDescription {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 12pt; COLOR: black; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""SPAN.explain {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""SPAN.TryThings {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".TryList {[\r][\n]""
[DEBUG] wire - << ""[0x9]MARGIN-TOP: 5px; FONT-WEIGHT: normal; FONT-SIZE: 8pt; COLOR: black; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".X {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; FONT-WEIGHT: normal; FONT-SIZE: 12pt; BORDER-LEFT: #955319 1px solid; COLOR: #7b3807; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: verdana; BACKGROUND-COLOR: #d1c2b4[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".adminList {[\r][\n]""
[DEBUG] wire - << ""[0x9]MARGIN-TOP: 2px[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""</STYLE>[\r][\n]""
[DEBUG] wire - << ""<META content=""MSHTML 6.00.2800.1170"" name=GENERATOR></HEAD>[\r][\n]""
[DEBUG] wire - << ""<BODY bgColor=#f3f3ed>[\r][\n]""
[DEBUG] wire - << ""<TABLE cellSpacing=0 cellPadding=0 width=""100%"">[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD class=titleborder_x width=30>[\r][\n]""
[DEBUG] wire - << ""      <TABLE height=25 cellSpacing=2 cellPadding=0 width=25 bgColor=black>[\r][\n]""
[DEBUG] wire - << ""        <TBODY>[\r][\n]""
[DEBUG] wire - << ""        <TR>[\r][\n]""
[DEBUG] wire - << ""          <TD class=x vAlign=center alig""
[DEBUG] wire - << ""n=middle>X</TD>[\r][\n]""
[DEBUG] wire - << ""        </TR>[\r][\n]""
[DEBUG] wire - << ""        </TBODY>[\r][\n]""
[DEBUG] wire - << ""      </TABLE>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""    <TD class=titleBorder id=L_default_2>Network Access Message:<SPAN class=TitleDescription> The page cannot be displayed</SPAN> </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE id=spacer>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD height=10></TD></TR></TBODY></TABLE>[\r][\n]""
[DEBUG] wire - << ""<TABLE width=400>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD noWrap width=25></TD>[\r][\n]""
[DEBUG] wire - << ""    <TD width=400><SPAN class=explain><ID id=L_default_3><B>Explanation:</B></ID></SPAN><ID id=L_default_4> There is a problem with the page you are trying to reach and it cannot be displayed. </ID><BR><BR>[\r][\n]""
[DEBUG] wire - << ""    <B><SPAN class=tryThings><ID id=L_default_5><B>Try the following:</B></ID></SPAN></B> [\r][\n]""
[DEBUG] wire - << ""      <UL class=TryList>[\r][\n]""
[DEBUG] wire - << ""        <LI id=L_default_6><B>Refresh page:</B> Search for the page again by clicking the Refresh button. The timeout may have occurred due to Internet congestion.[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_7><B>Check spelling:</B> Check that you typed the Web page address correctly. The address may have been mistyped.[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_8><B>Access from a link:</B> If there is a link to the page you are looking for, try accessing the page from that link.[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""      </UL>[\r][\n]""
[DEBUG] wire - << ""<ID id=L_default_9>If you are still not able to view the requested page, try contacting your administrator or Helpdesk.</ID> <BR><BR>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE id=spacer><TBODY><TR><TD height=15></TD></TR></TBODY></TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE width=400>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD noWrap width=25></TD>[\r][\n]""
[DEBUG] wire - << ""    <TD width=400 id=L_default_10><B>Technical Information (for support personnel)</B> [\r][\n]""
[DEBUG] wire - << ""      <UL class=adminList>[\r][\n]""
[DEBUG] wire - << ""        <LI id=L_default_11>Error Code: 407 Proxy Authentication Required. The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied. (12209)[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_12>IP Address: x.x.x.x[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_13>Date: 6/29/2009 11:15:15 AM [GMT][\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_14>Server: lab1[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_15>Source: proxy[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""      </UL>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""</BODY>[\r][\n]""
[DEBUG] wire - << ""</HTML>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""Proxy-Authorization: NTLM TlRMTVNTUAABAAAAATIAAAgACAAgAAAADgAOACgAAABNWURPTUFJTkpDSUZTMjMwXzg2Xzkx[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( Access is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM TlRMTVNTUAACAAAAAAAAADgAAAABAgACqbXrIWnZ3i4AAAAAAAAAAAAAAAA4AAAABQLODgAAAA8=[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 0     [EOL]""
[DEBUG] wire - << ""[EOL]""
[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""Proxy-Authorization: NTLM TlRMTVNTUAADAAAAGAAYAEAAAAAwADAAWAAAABAAEACIAAAAGgAaAJgAAAAcABwAsgAAAAAAAAAAAAAAAQIAAAXLpW40q7jqh7E6FgFnJqy9529ANaSLqfTiwjyF2BrUP9F8ObYOyYsBAQAAAAAAACDgxRg9+skBRt4mUOFFCs0AAAAAAAAAAE0AWQBEAE8ATQBBAEkATgBBAGQAbQBpAG4AaQBzAHQAcgBhAHQAbwByAEoAQwBJAEYAUwAyADMAMABfADgANgBfADkAMQA=[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 301 Unknown reason[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Content-length: 0[EOL]""
[DEBUG] wire - << ""Date: Mon, 29 Jun 2009 11:16:50 GMT[EOL]""
[DEBUG] wire - << ""Location: http://www.verisign.com/[EOL]""
[DEBUG] wire - << ""Content-type: text/html[EOL]""
[DEBUG] wire - << ""Server: Netscape-Enterprise/4.1[EOL]""
[DEBUG] wire - << ""[EOL]""
[ERROR] RequestProxyAuthentication - Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED
[DEBUG] wire - >> ""GET http://www.verisign.com/ HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: www.verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Negotiate[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Kerberos[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Basic realm=""lab1.""[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 4107  [EOL]""
[DEBUG] wire - << ""[EOL]""
----------------------------------------
HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )

Thanks,
Raj





"
"HTTPCLIENT-144","DOCUMENTATION","BUG","Add a document describing the HttpClient release process","The commons release process (http://jakarta.apache.org/commons/releases.html) is
a good starting place, but is out of date.  When we do our own releases, there
are some other steps particular to maven, the test-local and the webapp tests
that must be documented."
"HTTPCLIENT-147","BUG","BUG","HttpClient enter 100% for endless time","I was working masively using HttpClient (I was testing it for usage within a 
server) and it got to 100% CPU for an endless time.

I was querying urls of the type 
http://search.barnesandnoble.com/booksearch/results.asp?WRD=<text>&sort=R&SAT=1

To reproduce it, run 100-200 urls with random words instead of <text> and 
you'll probably reproduce the problem."
"HTTPCLIENT-996","BUG","BUG","SSL does not seem to work at all","Whenever I try to request content via https I get this exception:


Exception in thread ""main"" javax.net.ssl.SSLException: hostname in certificate didn't match: <140.211.11.131> != <*.apache.org>
	at org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:220)
	at org.apache.http.conn.ssl.BrowserCompatHostnameVerifier.verify(BrowserCompatHostnameVerifier.java:54)
	at org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:149)
	at org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:130)
	at org.apache.http.conn.ssl.SSLSocketFactory.createSocket(SSLSocketFactory.java:399)
	at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:143)
	at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:149)
	at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:108)
	at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:415)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:641)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:576)
	at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:554)
	at HttpsTest.fails(HttpsTest.java:25)
	at HttpsTest.main(HttpsTest.java:12)


I can reproduce this whith the following code:


import org.apache.http.client.HttpClient;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.impl.client.DefaultHttpClient;

public class HttpsTest {

    public static void main(final String[] args) throws Exception {
        final HttpClient client = new DefaultHttpClient();
        final HttpGet req = new HttpGet(""https://www.apache.org"");
        client.execute(req);
    }

}
"
"HTTPCLIENT-9","BUG","BUG","Null paths break the compare method","The compare method cannot handle the path being null"
"HTTPCLIENT-271","BUG","BUG","PostMethod#setParameter","[HttpClient2.0-rc1]

-------- code fragment 1 -------------------------
PostMethod method = new PostMethod(uriString);
method.addParameter(""tel"", ""1111-1111"");
method.addParameter(""tel"", ""2222-2222"");
method.setParameter(""tel"", ""3333-3333"");

(post data sent)
tel=1111-1111&tel=2222-2222&tel=3333-3333

(post data i hope)
tel=3333-3333
-------------------------------------------------

---------------- code fragment 2 -----------------
PostMethod method = new PostMethod(uriString);
method.addParameter(""tel"", ""1111-1111"");
method.addParameter(""tel"", ""2222-2222"");
method.addParameter(""tel"", ""3333-3333"");

(post data sent)
tel=1111-1111&tel=2222-2222&tel=3333-3333
--------------------------------------------------

what difference between code 1 and code2 ?

sorry for my poor english."
"HTTPCLIENT-190","BUG","BUG","SetCookie / DateParser failing to parse non-standard date format","I'm receiving the following expiration date in SetCookie which DateParser 
doesn't handle:

expires=Sat,19-Apr-03 04:28:07 GMT

The lack of a space between ',' and '19' is causing the problem. Is it possible 
to add the following lines to DatePattern?

""EEE,dd-MMM-yy HH:mm:ss z""
""EEE,dd-MMM-yyyy HH:mm:ss z"""
"HTTPCLIENT-613","IMPROVEMENT","BUG","https should check CN of x509 cert","https should check CN of x509 cert

Since we're essentially rolling our own ""HttpsURLConnection"",  the checking provided by ""javax.net.ssl.HostnameVerifier"" is no longer in place.

I have a patch I'm about to attach which caused both createSocket() methods on o.a.h.conn.ssl.SSLSocketFactory to blowup:

test1: javax.net.ssl.SSLException: hostname in certificate didn't match: <vancity.com> != <www.vancity.com>
test2: javax.net.ssl.SSLException: hostname in certificate didn't match: <vancity.com> != <www.vancity.com>

Hopefully people agree that this is desirable.
"
"HTTPCLIENT-168","DOCUMENTATION","BUG","Include generated website in the distribution","A user should be able to build the non-api docs as well.

So it would be nice, to include xdocs in the source packages as well ..."
"HTTPCLIENT-933","DOCUMENTATION","BUG","All implementations of SchemeSocketFactory.createSocket(HttpParams params) ignore the params","Only TestTSCCMWithServer.StallingSocketFactory.createSocket(HttpParams params) ever uses the HttpParams parameter.

All non-test implementations of the method ignore the parameter.

Not sure why this version of the method exists if the parameter is never used - the parameterless method from SocketFactory could be used instead."
"HTTPCLIENT-321","BUG","BUG","wrong charset indication in HttpConstants.getContentString()","Around line 236 in HttpConstants.getConstentString() the charset is wrongly indicated as 
""DEFAULT_CONTENT_CHARSET"" where it should have been indicated as ""charset"" like in the 
getContentBytes function.

            if (LOG.isWarnEnabled()) {
                LOG.warn(""Unsupported encoding: "" 
                    + DEFAULT_CONTENT_CHARSET // <== should be the variable ""charset"" here
                    + "". Default HTTP encoding used"");
            }

Wrong copy/paste I guess :-)

ZC."
"HTTPCLIENT-77","RFE","BUG","Implement Connection Timeouts","I was writing test code to use the setSoTimeout(int millis) method to set a
timeout value when connecting to a URL.  It appears to me that no matter what I
set the timeout to be a HttpConnection will try to connect but uses some other
timeout value(I'm guessing the OS's default value).  I looked at the code for
HttpConnection and it uses the Socket(host,port) constructor which tries to
connect write away.  I'd like to suggest the following code below so the timeout
is set before first the connection is even made.

/* Compile the code as is and it should timeout within a sec.  If you
 * uncomment the first two lines after the try statement and comment
 * out the other socket connect statements and run the code again you will
 * notice write away that the timeout is something else because it connects
 * right away in the constructor.  Its like the timeout is worthless at this
 * point.  As a matter a fact the code should never get there.
 * This all assumes that 192.168.168.50 is not on your network.
 */

import java.io.*;
import java.net.*;

public class SocketTest {
    public static void main(String[] args) {
        long start = System.currentTimeMillis();

        try {
            //Socket socket = new Socket(""192.168.168.50"",80);
            //socket.setSoTimeout(1000);

            //Setting timeout before the connection is made.
            Socket socket = new Socket();
            InetSocketAddress sAddress =
                new InetSocketAddress(""192.168.168.50"",80);
            socket.connect(sAddress,1000);

        } catch (UnknownHostException e) {
            System.out.println(e);
        } catch (SocketException e) {
            System.out.println(e);
        } catch (IOException e) {
            System.out.println(e);
        }

        System.out.println(System.currentTimeMillis() - start);
    }
}"
"HTTPCLIENT-81","RFE","IMPROVEMENT","need getResponseContentLength in HttpMethod","We need a way to find out the response content length in HttpMethod"
"HTTPCLIENT-741","BUG","BUG","AbstractClientConnAdapter prone to concurrency issues","AbstractClientConnAdapter is currently prone to all sorts of concurrency issues. (1) Access to internal state is not properry synchronized making the class prone  to race conditions. Presently none of the instance variables is even declared volatile. (2) AbstractClientConnAdapter treats aborted connection as one in an illegal state, which is not quite right.

Oleg"
"HTTPCLIENT-870","OTHER","BUG","Incorrect Specification-Title headers in MANIFEST.MF","The Specification-Title headers in MANIFEST.MF should all include the full project name, i.e.

Apache HttpComponents ...

The ""HttpComponents"" qualifier is missing; at present the entries are:

Specification-Title: Apache HttpClient
Specification-Title: Apache HttpMime

If present, Implementation-Title should follow the same convention."
"HTTPCLIENT-63","RFE","IMPROVEMENT","Response handlers","Perhaps plugin handlers should be used to handle various ranges of http
responses.  Could be used to respond, auto-forward, resubmit ... Could solve the
difficulty in handling a 303 response."
"HTTPCLIENT-156","BUG","BUG","NullPointerException thrown when invalid header encountered","If a server returns a header with no name but with a value (ie: an invalid line in the headers), HttpClient throws a NullPointerException instead of just skipping that header line or perhaps treating it as a continuation of the previous header (need to consult the RFC to confirm this).

Problem reported by Eduardo Francos on the commons-user list.

A good test URL for this problem is:

http://www.pc.ibm.com/us/accessories/monitors/p_allmodelos.html

which should return a 404 error but throws the NullPointerException instead."
"HTTPCLIENT-83","RFE","IMPROVEMENT","handle multivalue headers correctly","Some times, web servers send back multiple headers with the same key. e.g.

WWW-Authenticate: Negotiate
WWW-Authenticate: NTLM
WWW-Authenticate: Basic realm=""kmdc5""

To handle this correctly, we should add a method 

public java.util.Iterator getResponseHeaders(java.lang.String name)

just as in javax.servlet.http.HttpServletRequest."
"HTTPCLIENT-112","BUG","BUG","HttpClient incorrectly handles Transfer-Encoding header","RFC2616, section 4.4 item 3 states:
     If a Content-Length header field (section 14.13) is present, its
     decimal value in OCTETs represents both the entity-length and the
     transfer-length. The Content-Length header field MUST NOT be sent
     if these two lengths are different (i.e., if a Transfer-Encoding
     header field is present). If a message is received with both a
     Transfer-Encoding header field and a Content-Length header field,
     the latter MUST be ignored.

This is not handled correctly in the case that a noncompliant HTTP server
returns both a Transfer-Encoding header and a Content-Length header.

I gave up on writing a TestCase for this as it would require a reliably
noncompliant HTTP Server."
"HTTPCLIENT-655","BUG","BUG","User-Agent string violates RFC","Our User-Agent says ""Jakarta Commons-HttpClient/3.1-rc1"". But space is a reserved character to separate individual *products* and comments according to RFC 2616, section 14.43. Jakarta is not a product. At the same time we may want to drop the Jakarta name altogether.

We should change this to something more standard like: 

""Apache-HttpClient/3.1-rc1 (""+ System.getProperty(""os.name"") +"";""+ System.getProperty(""os.arch"") +"") ""+
""Java/""+ System.getProperty(""java.vm.version"") +"" (""+ System.getProperty(""java.vm.vendor"") +"")""

which renders:

""Apache-HttpClient/3.1-rc1 (Windows XP 5.1;x86) Java/1.5.0_08 (Sun Microsystems Inc.)""

Sun's internal Http client uses something like ""Java/1.5.0_08"".

I am completely ignoring the fact that real-world user agents use almost arbitrary strings.
Some fine examples of misbehaviour from my private logs:

""Jakmpqes dihurxf wfyiupsc"" -- apparently somebody has to hide something...
""Missigua Locator 1.9""
""Poodle predictor 1.0""
""shelob v1.0""
""ISC Systems iRc Search 2.1""
""ping.blogug.ch aggregator 1.0""
""http://www.uni-koblenz.de/~flocke/robot-info.txt""  -- ...sigh

I am very tempted to write a User-Agent string validator that prevents misuse of this field in HttpClient."
"HTTPCLIENT-449","DOCUMENTATION","BUG","RequestEntity, EntityEnclosingMethod have inconsistent Javadocs, use deprecated variables","Robert Manning <Robert.Manning at collabraspace.com> reported a problem on the
httpclient-user list regarding inconsistencies in javadoc of RequestEntity
interface and EntityEnclosingMethod class. This prompted me to review the said
classes. I have discovered several issues that must be dealt with before 3.0
goes final. 

(1) There's virtually no test coverage for the EntityEnclosingMethod class
(2) The code in EntityEnclosingMethod class extensively uses deprecated methods
and variables beyond what is required to maintain backward compatibility with
2.0.x API
(3) Existing code cannot gracefully handle faulty RequestEntity implementations
if the getContentLength method returns a negative value < -2

I have committed additional test cases to cover the most fundamental
functionality of EntityEnclosingMethod:
http://svn.apache.org/repos/asf/jakarta/commons/proper/httpclient/trunk/src/test/org/apache/commons/httpclient/TestEntityEnclosingMethod.java

I will submit a patch addressing issues (2) and (3) shortly

Oleg"
"HTTPCLIENT-1028","DOCUMENTATION","IMPROVEMENT","HttpClient Manual Simplified Chinese","During Nov 2010, The Chinese user Nanlei translated the Apache HttpClient manual into Chinese and contribute it to HttpClient project freely. In the future, the Chinese translation of HttpCore manual will be finished and contribute to HttpCore project freely too. "
"HTTPCLIENT-177","IMPROVEMENT","BUG","reusing connections is unreliable","HttpConnection reuse is unreliable. Because of the following:

1) There is currently no way to determine if a connection is still open on the
server side.
2) If an IOException occurs while writing to a connection it cannot be reused."
"HTTPCLIENT-461","BUG","BUG","HttpClient does not correctly handle escaped characters in HTTP header elements","An excerpt from Microsoft's ""How Digest Authentication Works"":
http://www.microsoft.com/technet/prodtechnol/windowsserver2003/library/TechRef/717b450c-f4a0-4cc9-86f4-cc0633aae5f9.mspx

<quote>
* RFC 2617-compliant Digest Authentication challenges and responses must also
comply with RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1 quoted string
requirements. This requirement particularly affects the use of backslash (\) and
embedded double quotes. Both must be preceded (escaped) with a backslash.

* For example, domain\username according to RFC 2616 is read as domainusername.
This reading is important because if an application sends information in this
format rather than as domain\\username, authentication fails.

* However, because this is a known issue with domain\username , if
authenticating with backslash encoding fails, Digest SSP attempts to
authenticate the response and assumes that the backslash is part of the string.
This behavior can be turned off by setting the ServerCompat registry key.
</quote>

Review and fix the ParameterParser class and classes implemeting CookieSpec or
AuthScheme interfaces

See also PR #34909"
"HTTPCLIENT-359","BUG","BUG","StringRequestEntity.getContentLength wrong for multibyte chars","When setting up a PostMethod containing a StringRequestEntity with umlauts and
charset UTF-8 the content-length header is wrong. It should be the number
of bytes, but is the number of chars by now.

(e.g.
Content-Type: text/xml; charset=UTF-8
body='')

Bug-location: org.apache.commons.httpclient.methods.StringRequestEntity"
"HTTPCLIENT-1131","RFE","IMPROVEMENT","Support http URL inline authentication","If you try to execute a method with the httpClient using a valid url, conform to the schema http://username:password@host:port/ the authentication will fail, and you will get a 401 error."
"HTTPCLIENT-469","BUG","BUG","Stale connection check does not work with IBM JSSE/JRE","OS: Windows/AIX
JRE: IBM JRE 1.4.1
JSSE: IBM's implementation (SSLite?)
HttpClient Library: 2.0.2 release

My code enabled connection pooling feature to gain performance improvement in 
the SSL Handshake area. The code works perfectly on Sun JRE 1.4.2 with a think 
time of 60seconds between requests, but the same code fails on IBM JRE. On IBM 
JRE, the code fails to detech stale connections, thus causing down the stream 
setSoTimeout() call to fail.

Further debugging into the library code revealed difference in the way the 
HTTPConnection.isStale() behaves. With in that method, particularly, the 
inputStream.isAvailable() method returns 0 with Sun JRE but -1 with IBM JRE.

I made a small code change to HttpConnection.isStale() method by moving the try
{}finally{} block outside of the if(inputStream.isAvailable()==0) check in the 
following code and BINGO, everything started working on IBM JVMs. It did not 
break anything on Suns JVM.

============== CODE BEGIN
    protected boolean isStale() {
    	LOG.debug(""##SUBBA## HttpConnection.isStale() got called. soTimeout="" 
+ soTimeout);
        boolean isStale = true;
        if (isOpen) {
        	LOG.debug(""##SUBBA## HttpConnection.isStale() got called. 
isOpen="" + isOpen);        	
            // the connection is open, but now we have to see if we can read it
            // assume the connection is not stale.
            isStale = false;

                try {         
                    if (inputStream.available() == 0) {		// ALWAYS 
RETURNS -1 on IBM JVM  0 on SUN
                    	
		  // try {		// SUBBA  MOVED OUTSIDE IF
	                	socket.setSoTimeout(1);
	                  	LOG.debug(""##SUBBA## HttpConnection.isStale() 
got called. setSoTimeout(1)"");                    	
	                    
	                    inputStream.mark(1);
	                    int byteRead = inputStream.read();
	                	LOG.debug(""##SUBBA## HttpConnection.isStale() 
got called. bytesRead="" + byteRead);                    	
	                    
	                    if (byteRead == -1) {
	                    	LOG.debug(""##SUBBA## HttpConnection.isStale() 
got called. SETTING isStale to TRUE HERE"");                    	
	                    	
	                        // again - if the socket is reporting all data 
read,
	                        // probably stale
	                        isStale = true;
	                    } else {
	                        inputStream.reset();
	                    }
		    // SUBBA  MOVED OUTSIDE IF
                //} finally {
                //	LOG.debug(""##SUBBA## HttpConnection.isStale() got 
called. finally block - BEGIN "" + soTimeout);                    	
                //    socket.setSoTimeout(soTimeout);
                //	LOG.debug(""##SUBBA## HttpConnection.isStale() got 
called. finally block - DONE"");                        
               // }

	
                    }                        
                } finally {
                	LOG.debug(""##SUBBA## HttpConnection.isStale() got 
called. finally block - BEGIN "" + soTimeout);                    	
                    socket.setSoTimeout(soTimeout);
                	LOG.debug(""##SUBBA## HttpConnection.isStale() got 
called. finally block - DONE"");                        
                }
.....
.....
.....
========================== CODE END


I've attached logs captured before and after the change on both the JRE's for 
your review:

==================================
IBMs LOG (after change):
==================================
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting 
free connection, hostConfig=HostConfiguration
[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:492> <##SUBBA## 
HttpConnection.isStale() got called. soTimeout=0>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:495> <##SUBBA## 
HttpConnection.isStale() got called. isOpen=true>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:500> <##SUBBA## 
HttpConnection.isStale() got called. [class 
java.io.BufferedInputStream].available=-1>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:523> <##SUBBA## 
HttpConnection.isStale() got called. finally block - BEGIN 0>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:532> <An error occurred while 
reading from the socket, is appears to be stale>
java.net.SocketException: Socket is closed
	at java.net.Socket.setSoTimeout(Socket.java:927)
	at com.ibm.sslite.bf.setSoTimeout(Unknown Source)
	at com.ibm.jsse.bg.setSoTimeout(Unknown Source)
	at org.apache.commons.httpclient.HttpConnection.isStale
(HttpConnection.java:524)
	at org.apache.commons.httpclient.HttpConnection.isOpen
(HttpConnection.java:436)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.isOpen(MultiThreadedHttpConnectionManager.java:1122)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:626)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:540> <##SUBBA## 
HttpConnection.isStale() return=true>
<Jun 10, 2005 1:26:55 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:437> <Connection is stale, 
closing...>

==================================
IBMs LOG (before change):
==================================
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:666> <enter 
HttpConnectionManager.ConnectionPool.getHostPool(HostConfiguration)>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting 
free connection, hostConfig=HostConfiguration
[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:492> <##SUBBA## 
HttpConnection.isStale() got called.>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:495> <##SUBBA## 
HttpConnection.isStale() got called. isOpen=true>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:500> <##SUBBA## 
HttpConnection.isStale() got called. [class 
java.io.BufferedInputStream].available=-1>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:538> <##SUBBA## 
HttpConnection.isStale() return=false>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:599> <HttpConnection.setSoTimeout(0)>
<Jun 10, 2005 1:07:29 PM EDT> <WARN> 
<apache.commons.httpclient.HttpConnection:607> <##SUBBA## Socket Exception>
java.net.SocketException: Socket is closed
	at java.net.Socket.setSoTimeout(Socket.java:927)
	at com.ibm.sslite.bf.setSoTimeout(Unknown Source)
	at com.ibm.jsse.bg.setSoTimeout(Unknown Source)
	at org.apache.commons.httpclient.HttpConnection.setSoTimeout
(HttpConnection.java:603)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:633)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:1151> <enter 
HttpConnection.releaseConnection()>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:513> <enter 
HttpConnectionManager.releaseConnection(HttpConnection)>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:791> <Freeing 
connection, hostConfig=HostConfiguration[host=uatservices30.ilab.fnfismd.com, 
protocol=https:443, port=443]>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:666> <enter 
HttpConnectionManager.ConnectionPool.getHostPool(HostConfiguration)>
<Jun 10, 2005 1:07:29 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:774> <Notifying 
no-one, there are no waiting threads>
java.net.SocketException: Socket is closed
	at java.net.Socket.setSoTimeout(Socket.java:927)
	at com.ibm.sslite.bf.setSoTimeout(Unknown Source)
	at com.ibm.jsse.bg.setSoTimeout(Unknown Source)
	at org.apache.commons.httpclient.HttpConnection.setSoTimeout
(HttpConnection.java:603)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:633)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)
java.net.SocketException: Socket is closed
	at java.net.Socket.setSoTimeout(Socket.java:927)
	at com.ibm.sslite.bf.setSoTimeout(Unknown Source)
	at com.ibm.jsse.bg.setSoTimeout(Unknown Source)
	at org.apache.commons.httpclient.HttpConnection.setSoTimeout
(HttpConnection.java:603)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:633)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)
Exception in thread ""main"" java.net.SocketException: Socket is closed
	at java.net.Socket.setSoTimeout(Socket.java:927)
	at com.ibm.sslite.bf.setSoTimeout(Unknown Source)
	at com.ibm.jsse.bg.setSoTimeout(Unknown Source)
	at org.apache.commons.httpclient.HttpConnection.setSoTimeout
(HttpConnection.java:603)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.setSoTimeout(MultiThreadedHttpConnectionManager.java:1296)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:633)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)


============================================
**SUNs LOG (after change = before change):
============================================
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.MultiThreadedHttpConnectionManager:700> <Getting 
free connection, hostConfig=HostConfiguration
[host=uatservices30.ilab.fnfismd.com, protocol=https:443, port=443]>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:492> <##SUBBA## 
HttpConnection.isStale() got called. soTimeout=0>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:495> <##SUBBA## 
HttpConnection.isStale() got called. isOpen=true>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:500> <##SUBBA## 
HttpConnection.isStale() got called. [class 
java.io.BufferedInputStream].available=0>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:506> <##SUBBA## 
HttpConnection.isStale() got called. setSoTimeout(1)>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:510> <##SUBBA## 
HttpConnection.isStale() got called. bytesRead=-1>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:513> <##SUBBA## 
HttpConnection.isStale() got called. SETTING isStale to TRUE HERE>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:523> <##SUBBA## 
HttpConnection.isStale() got called. finally block - BEGIN 0>
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:532> <An error occurred while 
reading from the socket, is appears to be stale>
java.net.SocketException: Socket Closed
	at java.net.PlainSocketImpl.setOption(PlainSocketImpl.java:177)
	at java.net.Socket.setSoTimeout(Socket.java:924)
	at com.sun.net.ssl.internal.ssl.SSLSocketImpl.setSoTimeout(DashoA12275)
	at org.apache.commons.httpclient.HttpConnection.isStale
(HttpConnection.java:524)
	at org.apache.commons.httpclient.HttpConnection.isOpen
(HttpConnection.java:436)
	at 
org.apache.commons.httpclient.MultiThreadedHttpConnectionManager$HttpConnection
Adapter.isOpen(MultiThreadedHttpConnectionManager.java:1122)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:626)
	at org.apache.commons.httpclient.HttpClient.executeMethod
(HttpClient.java:497)
	at 
com.touchpoint.pia.services.transactions.msp.ApacheHttpClient.invokeRequest
(ApacheHttpClient.java:69)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequest
(MsWSManager.java:86)
	at 
com.touchpoint.pia.services.transactions.msp.MsWSManager.invokeRequestWithPaylo
ad(MsWSManager.java:114)
	at com.touchpoint.pia.services.transactions.msp.MsWSManager.main
(MsWSManager.java:179)
<Jun 10, 2005 1:25:12 PM EDT> <DEBUG> 
<apache.commons.httpclient.HttpConnection:540> <##SUBBA## 
HttpConnection.isStale() return=true>"
"HTTPCLIENT-424","RFE","BUG","setAuthPreemptive restricted to BASIC AuthScheme","Pre-emptive authentication is hardcoded to be restricted to the BASIC
authentication scheme.  To fully support custom authentication schemes,
pre-emptive authentication should be made configurable, either globally, or on a
per-scheme basis.  A potential compromise may be to require AuthSchemes to
report whether they support pre-emptive capability if we wish to explicitly
exclude certain schemes from pre-emptive authentication.

(reported against 3.0 RC 1)"
"HTTPCLIENT-669","RFE","IMPROVEMENT","introduce HttpRoutePlanner interface","Define an interface to determine a route for a given target host.
Create default implementation replacing DefaultHttpClient.determineRoute(...);
Implementations will need access to params and/or request.

The interface fits into HttpConn, but DHC.dR(...) uses client parameters.
Either move parameters to HttpConn, or keep default implementation in HttpClient.

Alternative implementations could evaluate Java system properties related to proxy settings.

"
